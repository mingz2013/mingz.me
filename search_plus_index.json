{"./":{"url":"./","title":"Introduction","keywords":"","body":" Title Date Modified Category Introduction 2019-06-06 12:00 2019-06-06 12:00 Introduction 之前的 blog项目实在不好用，以后的笔记都转移到这里来 本书地址 http://mingz.me/note/ 本书github https://github.com/mingz2013/note 本书讨论区 https://github.com/mingz2013/note/issues 看的书很多，但是本人实在健忘。 最近将一些学过的东西，系统整理出来，便于后续查阅复习。 还有就是，将所学到的东西整理出来，也是一个给外界展示自己的机会，否则知识永远躺在印象笔记里，别人也不知道。 "},"every-day-use/":{"url":"every-day-use/","title":"every day use","keywords":"","body":"1. every day use Title Date Modified Category every day use 2019-06-06 12:00 2019-06-06 12:00 every day use 1. every day use mongo redis docker k8s golang python nodejs adb git svn ctf wireshark nmap shell macos brew sublime vscode vim markdown jetbrains unity chrome "},"every-day-use/mongo.html":{"url":"every-day-use/mongo.html","title":"mongo","keywords":"","body":"1. mongo1.1. use in macos1.2. use in centos 71.2.1. 使用1.3. client1.4. tools Title Date Modified Category mongo 2019-06-06 12:00 2019-06-06 12:00 every day use 1. mongo 1.1. use in macos brew install mongo brew services start mongodb brew services stop mongodb mongod --config /usr/local/etc/mongod.conf 1.2. use in centos 7 vim /etc/yum.repos.d/mongodb-org-4.0.repo ```repo [mongodb-org-4.0] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.0/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-4.0.asc - `yum install mongodb-org` - `systemctl restart mongod.service` ## 开启验证 ### 配置 ```conf // /etc/mongod.conf # Run with/without security (without by default) #auth = true #noauth = true 1.2.1. 使用 use spider db.createUser({user:”spider\",pwd:\"spider2016\",roles:[{role:\"dbOwner\",db:\"spider\"}]}) db.auth(spider, spider2016) 1.3. client mongo show dbs use testDBName show collections db.dropDatabase() // 删除数据库 db.pUser.remove({'role':'admin'}) db.bankUser.drop() db.users.find({'id':1}, {'_id':0, 'name':1}) db.users.find({'_id':ObjectId('5cf65f785568e41dbaf66ee6')}) db.post.update({}, {$rename:{url:'site'}}) // 字段改名 db.collection.ensureIndex({a:1}) // 创建索引 db.collection.find({a:5, b:3,c:{$lt:2},d:{$gt:4}}).sort({c:1}) 1.4. tools mongodump -h dbhost -d dbname -o dbdir mongostore -h dbhost -d dbname --directoryerdb dbdir mongoexport --csv -f company_name,item_category,site -d dbName -c collectionName -q '{\"item_category_num\":102}' -o 102.csv mongoimport --db dbName --collection collectionName --file file.json "},"every-day-use/redis.html":{"url":"every-day-use/redis.html","title":"redis","keywords":"","body":"1. redis1.1. use in macos1.2. client Title Date Modified Category redis 2019-06-06 12:00 2019-06-06 12:00 every day use 1. redis 1.1. use in macos brew install redis brew services start redis redis-server /usr/local/etc/redis.conf 1.2. client redis-cli #连接redis服务器 select 1 # 选择数据库 keys * # 查看指定的key type gamedata # 查看指定key的类型 flushdb # 清空数据库 set event_id 1 set user_id 1 GET key hlen db "},"every-day-use/docker.html":{"url":"every-day-use/docker.html","title":"docker","keywords":"","body":"1. Docker1.1. cmd1.2. docker-compose Title Date Modified Category docker 2019-06-06 12:00 2019-06-06 12:00 every day use 1. Docker https://docs.docker.com/ 1.1. cmd docker help docker search 从镜像源搜索软件 docker pull 从镜像源拉取软件 docker images 显示镜像列表 docker ps 显示容器列表 docker run 运行镜像为容器 docker start 启动容器 docker stop 停止运行中的容器 docker rm 删除容器 docker rmi 删除镜像 docker login mingz2013 password # 这里是用户名，不是邮箱 docker run -d consul # -d 后台执行 docker run -d -i -t centos /bin/bash # -d 后台运行 docker exec -it containerID /bin/bash docker attach docker rm $(docker ps -a -q) # 删除容器 docker rmi -f $(docker images -q) # 删除镜像 --link 链接一个容器，起一个别名，在容器内部可用别名访问 1.2. docker-compose docker-compose 的 --links 参数也一样 docker-compose version docker-compose up docker-compose down docker-compose start docker-compose stop docker-compose restart docker-compose pause docker-compose unpause docker-compose build docker-compose create docker-compose images docker-compose pull docker-compose push docker-compose ps docker-compose logs docker-compose exec docker-compose config # 确认并展示compose file docker-compose events docker-compose kill docker-compose rm docker-compose run docker-compose scale #缩放服务个数 docker-compose scale todos-srv=2 WARNING: The scale command is deprecated. Use the up command with the --scale flag instead. docker-compose up -d --scale todos-api=3 docker-compose up -d --scale todos-srv=2;todos-api=3 "},"every-day-use/k8s.html":{"url":"every-day-use/k8s.html","title":"k8s","keywords":"","body":" Title Date Modified Category k8s 2019-06-06 12:00 2019-06-06 12:00 every day use kubectl run kubectl expose kubectl annotate kubectl autoscale kubectl convert kubectl create kubectl create clusterrole kubectl create clusterrolebinding kubectl create configmap kubectl create deployment kubectl create namespace kubectl create poddisruptionbudget kubectl create quota kubectl create role kubectl create rolebinding kubectl create service kubectl create secret kubectl delete kubectl edit kubectl label kubectl patch kubectl replace kubectl rolling-update kubectl rollout kubectl scale kubectl set "},"every-day-use/golang.html":{"url":"every-day-use/golang.html","title":"golang","keywords":"","body":" Title Date Modified Category golang 2019-06-06 12:00 2019-06-06 12:00 every day use go get github.com/xxx/xxx 安装包 go get -u github.com/xxx/xxx 更新 go doc http.ListenAndServe 查看doc go run xxx.go 直接编译执行go go build xxx.go 编译 go install CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build # 交叉编译 "},"every-day-use/python.html":{"url":"every-day-use/python.html","title":"python","keywords":"","body":" Title Date Modified Category 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/nodejs.html":{"url":"every-day-use/nodejs.html","title":"nodejs","keywords":"","body":" Title Date Modified Category nodejs 2019-06-06 12:00 2019-06-06 12:00 every day use node install -g gitbook 安装gitbook全局的 npm install -g gitbook-cli "},"every-day-use/adb.html":{"url":"every-day-use/adb.html","title":"adb","keywords":"","body":" Title Date Modified Category adb 2019-06-06 12:00 2019-06-06 12:00 every day use adb shell adb logcat adb install adb uninstall com.xiuxayo.numbers_blast adb install -r final.apk adb shell am start -n com.xiuxayo.numbers_blast/com.xiuxayo.numbers_blast.MainActivity https://apkpure.com/cn/ good way to download apk from google play app store. 拷贝文件 adb push adb pull "},"every-day-use/git.html":{"url":"every-day-use/git.html","title":"git","keywords":"","body":" Title Date Modified Category git 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/svn.html":{"url":"every-day-use/svn.html","title":"svn","keywords":"","body":" Title Date Modified Category 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/ctf.html":{"url":"every-day-use/ctf.html","title":"ctf","keywords":"","body":"1.1. python Title Date Modified Category ctf 2019-06-06 12:00 2019-06-06 12:00 every day use 1.1. python ord(c) # 参数是长度为1的字符串，简称字符。当参数为统一对象时（unicode object），返回能代表该字符的统一编码，当参数为8比特的字符串时，返回该字节的值。例如ord(‘a’) 返回整形数值97，ord(u’\\u2020’)返回8224. chr(i) # 返回一个字符，字符的asc2码等于参数中的整形数值。如chr(97)返回字符’a’ , 该方法是 ord 的反方法。参数必须是0-255的整形数值，否则会抛出valueError错误。 hex() # str() # "},"every-day-use/wireshark.html":{"url":"every-day-use/wireshark.html","title":"wireshark","keywords":"","body":" Title Date Modified Category wireshark 2019-06-06 12:00 2019-06-06 12:00 every day use ip.src==192.168.1.102 // 过滤源ip ip.src==192.168.1.102 and http // 过滤源ip和http协议 ip.src==192.168.1.100 or ip.dst==192.168.1.100 (ip.src==192.168.1.101 or ip.dst==192.168.1.101 or ip.src==192.168.1.100 or ip.dst==192.168.1.100 or ip.dst==192.168.1.107 or ip.src==192.168.1.107) wireshark抓取的pcapng文件 wireshark打开 File->export objects->http->save all 导出所有http请求到文件夹 过滤文件 读取文件 "},"every-day-use/nmap.html":{"url":"every-day-use/nmap.html","title":"nmap","keywords":"","body":" Title Date Modified Category nmap 2019-06-06 12:00 2019-06-06 12:00 every day use nmap -sS -Pn -A 192.168.20.1/24 80-8000 "},"every-day-use/shell.html":{"url":"every-day-use/shell.html","title":"shell","keywords":"","body":"1. 相关资料2. 帮助2.1. 安装man手册中文3. 文件目录操作3.1. 查找目录3.2. 展示目录3.3. du查看某个文件或目录占用磁盘空间的大小3.4. 分割文本文件，为多个小文件4. 按每个文件1000行来分割除5. 按照每个文件100K来分割6. 文本操作6.1. 查看文本文件 内容6.2. 操作命令6.3. 查询日志6.4. 根据每行的空格分割6.5. 去除重复行6.6. 查找非重复行6.7. 查找重复行6.8. 统计7. 后台执行8. 刻盘9. 压缩解压9.1. 压缩（compress）：9.2. 解压操作:10. tar -zxvf /usr/local/auto_bak/test.tar.gz11. where which12. 日期13. 时间14. 用户与权限14.1. 用户管理14.2. chmod 权限解读14.3. 进程管理14.4. 网络相关15. 网络抓包分析16. 系统信息查看17. 远程连接操作18. 拷贝本地文件(夹)到远程服务器，只需要将后面两个参数反过来就可以19. 两个网络命令20. telnet21. 跟踪系统调用22. purge23. 3个常用基于Linux系统命令行WEB网站浏览工具（w3m/Links/Lynx)24. 特殊问题24.1. jq24.2. sed Title Date Modified Category shell 2019-06-06 12:00 2019-06-06 12:00 every day use 1. 相关资料 http://linuxtools-rst.readthedocs.io/zh_CN/latest/index.html 2. 帮助 man # 手册 man ls ls --help 2.1. 安装man手册中文 yum list | grep man | grep page yum install man-pages yum install man-pages-zh-CNalias cman=‘man -M /usr//share/man/zh_CN'man poll cman poll 3. 文件目录操作 ln -s filename sy_file # 建立软连接 # rm -rf dir # 删除目录 3.1. 查找目录 find . -name “poker” find . -name xz find . -name \"*.[c|h]\" 3.2. 展示目录 ls -l ls -h # 转换kb -> MB 3.3. du查看某个文件或目录占用磁盘空间的大小 du -ah —max-depth=1 du -d 1 -h # mac 这个是我想要的结果a表示显示目录下所有的文件和文件夹（不含子目录）， h表示以人类能看懂的方式， max-depth表示目录的深度。 for i in *; do mv \"$i\" \"$i.txt\"; done # 批量加后缀 for i in qianlima_*; do mv “$i\" \"$i.csv\"; done ls | grep ping | grep log | while read line; do wc -l $line;done; 3.4. 分割文本文件，为多个小文件 split 参数： -b ：后面可接欲分割成的档案大小，可加单位，例如 b, k, m 等； -l ：以行数来进行分割； 4. 按每个文件1000行来分割除 split -l 1000 httperr8007.log http httpaa，httpab，httpac ........ 5. 按照每个文件100K来分割 split -b 100k httperr8007.log http httpaa，httpab，httpac ........ 6. 文本操作 6.1. 查看文本文件 内容 cat more less tail head tail -f server.log # 实时查看日志 6.2. 操作命令 grep awk sed Ack Ag grep -A 10 -B 10 ‘Traceback' log/log.log # 显示 traceback 和 前十行 和 后十行 grep -C 10 ’Traceback’ log/log.log # 等价于上一行， -A 10 -B 10 grep “ERROR” log/2016-05-06.log | awk -F '' '{print $1}' | awk '{print $2}' | grep 'jd' | grep 'list' grep python | wc -l 查看日志条数 grep -r ‘123’ . 查找当前目录下所有文件 包含 123 的 行 6.3. 查询日志 find . -name GT712*06_04 | xargs grep ‘Majiang2.saveRecord ok' | grep '440392' 6.4. 根据每行的空格分割 (cat 3.txt | awk ‘{print $1}' && cat 3.txt | awk '{print $2}' && cat 3.txt | awk '{print $3}' && cat 3.txt | awk '{print $4}' && cat 3.txt | awk '{print $5}' | cat 3.txt | awk '{print $6}' | cat 3.txt | awk '{print $7}') | sort | uniq | wc -l (cat 4.txt | awk '{print $2}' | sort | uniq && cat 4.txt | awk '{print $4}' | sort | uniq && cat 4.txt | awk '{print $6}' | sort | uniq && cat 4.txt | awk '{print $6}' | sort | uniq && cat 4.txt | awk '{print $8}' | sort | uniq && cat 4.txt | awk '{print $10}' | sort | uniq && cat 4.txt | awk '{print $12}' | sort | uniq && cat 4.txt | awk '{print $14}' | sort | uniq && cat 4.txt | awk '{print $16}' | sort | uniq && cat 4.txt | awk '{print $18}' | sort | uniq && cat 4.txt | awk '{print $20}' | sort | uniq) | sort | uniq grep 'comId' json.txt | awk -F '\"' '{print $4}' | sort | uniq -c | wc -l grep “MONGO\" 1.txt | awk -F '' '{print $2}' > 2.txt 6.5. 去除重复行 sort file |uniq6.6. 查找非重复行 sort file |uniq -u6.7. 查找重复行 sort file |uniq -d6.8. 统计 sort file | uniq -c cat 3.txt | sort | uniq 去除重复行 cat 1.txt | sort | uniq | wc -l 统计非重复行数量7. 后台执行 nohup pypy modify.py # 后台执行命令 pypy modify.py & # 后台运行命令 命令后加 & command & ： 后台运行，你关掉终端会停止运行 nohup command & ： 后台运行，你关掉终端也会继续运行 8. 刻盘 刻盘：dd if=./Windows10.iso of=/dev/sdc 9. 压缩解压 /usr/local/test tar -cvf /usr/local/auto_bak/test.tar /usr/local/test 仅打包，不压缩 tar -zcvf /usr/local/auto_bak/test.tar.gz /usr/local/test 打包后，以gzip压缩 在参数f后面的压缩文件名是自己取的，习惯上用tar来做，如果加z参数，则以tar.gz 或tgz来代表gzip压缩过的tar file文件 9.1. 压缩（compress）： tar -zcvf /usr/local/auto_bak/test.tar.gz /usr/local/test9.2. 解压操作: 10. tar -zxvf /usr/local/auto_bak/test.tar.gz tar zxvf demo.tar.gz -C demo-dir # 解压到指定目录，前提是目录事先存在 11. where which which pip # 查看pip路径位置 whereis python which pypy | xargs ls -l -G 12. 日期 date +“%Y-%m-%d %H:%M.%S\" date +”%Y%m%d\" --date='1 days ago' 13. 时间 time可统计命令运行时间 time pypy main.py 14. 用户与权限 那就是sudo su 或者sudo -sH 默认缺省为获取root 用户 14.1. 用户管理 useradd name userdel name cat /etc/passwd chown #更改文件所有者 chown tyhall-difang:tyhall-difang -R . chmod #更改文件权限 drwxr-xr-x 7 zhaojm staff 238 Jun 26 19:30 go/ chmod 777 filename 三个标志位， 所有者，用户组，其他用户 每个标志位三个二进制位 读，写，执行 14.2. chmod 权限解读 二、chmod整个命令的形式的用法如下： sudo chmod -（代表类型）×××（所有者）×××（组用户）×××（其他用户） 三位数的每一位都表示一个用户类型的权限设置。取值是0～7，即二进制的[000]~[111]。 这个三位的二进制数的每一位分别表示读、写、执行权限。 如000表示三项权限均无，而100表示只读。这样，我们就有了下面的对应： 0 [000] 无任何权限 4 [100] 只读权限 6 [110] 读写权限 7 [111] 读写执行权限 要求就是： 1、将当前目录中的所有“子目录”的权限设置为755； 2、将当前目录中的所有“文件”的权限设置为644。 解决方法： chmod 644 -R * chmod 755 find -type d 也可以用： 用find彻底些 find /path -type f -exec chmod 644 {} /; find /path -type d -exec chmod 755 {} /; 1060 chmod 664 -R log37 1061 chmod 775 find log37 -type d 14.3. 进程管理 kill -9 3719 # 杀死3719 PID 进程 ps -ef ps -aux | grep python ps -aux | grep phantomjs | awk '{print $2}' | while read line; do kill -9 $line; done ps -A | grep pypy | awk ‘{print $1}’ | xargs kill -9 14.4. 网络相关 netstat -ntlp -n 显示所有选项 -t 只显示tcp连接 -l 只显示listen -p 将program name 附加到 PID后面 lsof -i:80 查看80端口占用情况 netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' 查看网络负载 15. 网络抓包分析 tcpdump tshark 16. 系统信息查看 dmidecode # 查看系统信息 top 查看cpu利用率 iostat 查看io df -hl 查看磁盘 env # 查看当前环境变量 cat /etc/redhat-release 17. 远程连接操作 ssh root@192.168.2.22 #ssh 登录服务器 scp root@www.baidu.com:/home/root/test.txt ./#拷贝远程服务器文件到本地 scp -r root@www.baidu.com:/home/root/myfloder ./ # 拷贝远程服务器文件夹到本地18. 拷贝本地文件(夹)到远程服务器，只需要将后面两个参数反过来就可以 rsync -aupv root@192.168.1.11:/home/test.log /home # 相比scp稳定，速度快 rsync 用于拷贝数据 19. 两个网络命令 socat ,可用于绑定一个程序到一个端口 nc socat tcp-listen:8888, exec:ipython,pty,stderr # 将一个程序转发到一个端口 socat tcp-listen:8888,fork exec:ipython,pty,stderr # 支持并发 socat tcp-listen:8888,fork exec:bash,pty,stderr 20. telnet 退出 ^] ctrl+] 21. 跟踪系统调用 strace strace ls 22. purge 释放内存空间， 系统会自以为是的缓存一些应用，以为你会再次打开 23. 3个常用基于Linux系统命令行WEB网站浏览工具（w3m/Links/Lynx) 24. 特殊问题 我需要在 服务器上 通过 sudo su - tyhall-difang 切换到tyhall-difang 用户，怎么scp tyhall-difang用户下的文件到本地 1 tyhall-difang用户下，chmod 755 /home/tyhall-difang 改为其他人可读可进 2 tyhall-difang用户下拷贝文件到/tmp/目录下 dig DNS查询 adb install ..apk adb install -r 覆盖安装 adb logcat 看日志 压缩所有文件和目录，单独压缩 ls -l | awk '{print $9}' | awk -F '/' '{print $1}'| while read i; do tar -zcvf $i.tar.gz $i;done; 24.1. jq jq json处理工具,shell工具 https://stedolan.github.io/jq/ https://stedolan.github.io/jq/tutorial/ jq . 24.2. sed "},"every-day-use/macos.html":{"url":"every-day-use/macos.html","title":"macos","keywords":"","body":" Title Date Modified Category macos 2019-06-06 12:00 2019-06-06 12:00 every day use command + k 清空terminal屏幕消息 terminal中的复制粘贴 shift ctrl c shift ctrl v 退出telnet ctrl + ] "},"every-day-use/brew.html":{"url":"every-day-use/brew.html","title":"brew","keywords":"","body":"1. brew Title Date Modified Category brew 2019-06-06 12:00 2019-06-06 12:00 every day use 1. brew brew update brew outdated brew upgrade brew upgrade; brew cleanup brew services brew services list brew services start redis brew services stop mongodb brew install redis "},"every-day-use/sublime.html":{"url":"every-day-use/sublime.html","title":"sublime","keywords":"","body":" Title Date Modified Category sublime 2019-06-06 12:00 2019-06-06 12:00 every day use command + shift + p // 打开命令快捷键 set syntax:json // 设置json格式解析 format:javascript // 以js格式化 "},"every-day-use/vscode.html":{"url":"every-day-use/vscode.html","title":"vscode","keywords":"","body":" Title Date Modified Category vscode 2019-06-06 12:00 2019-06-06 12:00 every day use command + shift + p command + p command + shift + N 打开新窗口 command + N 新建文件 "},"every-day-use/vim.html":{"url":"every-day-use/vim.html","title":"vim","keywords":"","body":" Title Date Modified Category vim 2019-06-06 12:00 2019-06-06 12:00 every day use shell命令 :命令模式 :Sex! \"左右分割窗口，在左侧打开文件浏览器 :Sex “上下分割窗口，在上面打开文件浏览器 :vsplit, :new, :split \"分割窗口 :tab new \"打开新tab :/, :? “向前搜索，向后搜索 :e file “切换文件 :%!xxd ---->切换到十六进制显示 :%!xxd -r ---->切回文本方式显示 快捷键 g + t “切换tab ctrl + w \"切换分割窗口 ctrl + h, j, k, l “左下上右 切换窗口 ctrl + p “自动补全 折叠代码：zc 打开折叠：zo 　　 需要注意的是在1、2两种方法中，^V和^M指的是Ctrl+V和Ctrl+M.你必须要手工进行输入，而不是粘贴。 在vi中处理：首先使用vi打开文件，然后按ESC键，接着输入命令：%s/^V^M//. ：%s/^M$//g 　 1.在Vim中可以直接查看文件编码 :set fileencoding 1.在Vim中直接进行转换文件编码,比如将一个文件转换成utf-8格式 :set fileencoding=utf-8 按两下d，删除一行 "},"every-day-use/markdown.html":{"url":"every-day-use/markdown.html","title":"markdown","keywords":"","body":" Title Date Modified Category markdown 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/jetbrains.html":{"url":"every-day-use/jetbrains.html","title":"jetbrains","keywords":"","body":"1. 快捷键2. mark directory as -> sources root Title Date Modified Category jetbrains 2019-06-06 12:00 2019-06-06 12:00 every day use 1. 快捷键 Option+Command+l 格式化代码 command + / 注释 alt + / 提示 shift + command + k git push 2. mark directory as -> sources root inspect code， 分析代码 Diagrams ， UML类图 "},"every-day-use/unity.html":{"url":"every-day-use/unity.html","title":"unity","keywords":"","body":"1. 基本操作2. 基础经验 Title Date Modified Category unity 2019-06-06 12:00 2019-06-06 12:00 every day use 1. 基本操作 command + shit + F 先选中摄像机，将场景所见变成摄像机视角 q w e r t y 快捷键 alt + 滑动 改变视角 ctrl + 滑动 缩放场景 command + d 复制一个对象 按住command拖动，一米一米的拖动 2. 基础经验 空物体设坐标为000，子物体和世界坐标一致，便于操作 "},"every-day-use/chrome.html":{"url":"every-day-use/chrome.html","title":"chrome","keywords":"","body":"1. Console API1.1. 命令行 Title Date Modified Category chrome 2019-06-06 12:00 2019-06-06 12:00 every day use 1. Console API 当打开 firebug (也包括 Chrome 等浏览器的自带调试工具)，window 下面会注册一个叫做 console 的对象，它提供多种方法向控制台输出信息，供开发人员调试使用。下面是这些方法的一个简单介绍，适时地运用它们，对于提高开发效率很有帮助。 console.log(object[, object, ...]) 使用频率最高的一条语句：向控制台输出一条消息。支持 C 语言 printf 式的格式化输出。当然，也可以不使用格式化输出来达到同样的目的： var animal='frog', count=10; console.log(\"The %s jumped over %d tall buildings\", animal, count); console.log(\"The\", animal, \"jumped over\", count, \"tall buildings\"); console.debug(object[, object, ...]) 向控制台输出一条信息，它包括一个指向该行代码位置的超链接。 console.info(object[, object, ...]) 向控制台输出一条信息，该信息包含一个表示“信息”的图标，和指向该行代码位置的超链接。 console.warn(object[, object, ...]) 同 info。区别是图标与样式不同。 console.error(object[, object, ...]) 同 info。区别是图标与样式不同。error 实际上和 throw new Error() 产生的效果相同，使用该语句时会向浏览器抛出一个 js 异常。 console.assert(expression[, object, ...]) 断言，测试一条表达式是否为真，不为真时将抛出异常（断言失败）。 console.dir(object) 输出一个对象的全部属性（输出结果类似于 DOM 面板中的样式）。 console.dirxml(node) 输出一个 HTML 或者 XML 元素的结构树，点击结构树上面的节点进入到 HTML 面板。 console.trace() 输出 Javascript 执行时的堆栈追踪。 console.group(object[, object, ...]) 输出消息的同时打开一个嵌套块，用以缩进输出的内容。调用 console.groupEnd() 用以结束这个块的输出。 console.groupCollapsed() 同 console.group(); 区别在于嵌套块默认是收起的。 console.time(name) 计时器，当调用 console.timeEnd(name);并传递相同的 name 为参数时，计时停止，并输出执行两条语句之间代码所消耗的时间（毫秒）。 console.profile([title]) 与 profileEnd() 结合使用，用来做性能测试，与 console 面板上 profile 按钮的功能完全相同。 console.count([title]) 输出该行代码被执行的次数，参数 title 将在输出时作为输出结果的前缀使用。 console.clear() 清空控制台 1.1. 命令行 控制台的输出面板右边，是控制台的输入面板（Chrome 调试工具对应为下方），在这里除了可以运行常规的 javascript 代码，还内置了相当数量的命令行可以辅助我们的调试工作，下面是一些常用命令行的简单介绍。 $(id) 返回一个给定 id 的元素。 $$(selector) 返回给定的 css 选择器匹配到的一组元素。 $x(xpath) 返回给定的 XPath 表达式匹配到的一组元素。 $0 在 HTML 面板中选中的元素。 $1 上一次在 HTML 面板中选中的元素。 $n(index) 访问最近 5 个被选中过的元素，index 的范围： 0 – 4。 dir(object) 同 console.dir(object)。 dirxml(node) 同 console.dirxml(node)。 clear() 同 console.clear()。 inspect(object[, tabName])() 在合适的（或一个指定的） tab 中检视一个对象。 keys(object) 返回一个对象的所有属性的键。 values(object) 返回一个对象的所有属性的值。 debug(fn) 在函数第一行添加一个断点，使用 undebug(fn) 移除断点。 monitor(fn) 开启一个函数的调用日志，使用 unmonitor(fn) 关闭该功能。非常有用的一个命令，但是它似乎并没有很好地工作。 monitorEvents(object[, types]) 开启一个元素的某个事件（或所有事件）被触发时的日志记录。用例如下： monitorEvents($0,['click']) 上面的命令行被执行后，将开启当前在 HTML 面板中被选中元素的 click 事件监控，一旦这个元素的 click 事件被触发，事件对象将会在控制台输出。如果不指定第二个参数，将对所有事件进行记录。 profile([title]) 同 console.profile([title]) $x('//div[@id=\"float_icon\"]/div/img')[0].click() 直接操作元素 类似于selenium操作 "},"math/":{"url":"math/","title":"Math","keywords":"","body":" Title Date Modified Category math 2019-07-11 12:00 2019-07-11 12:00 math "},"algorithm/":{"url":"algorithm/","title":"algorithm","keywords":"","body":"1. 本部分对应源码2. 参考资料2.1. books Title Date Modified Category algorithm 2019-06-06 12:00 2019-07-08 12:00 algorithm 数据结构 算法 List stack queue string tree graph searching 顺序表查找 有序表查找 线性索引查找 二叉排序树查找 散列表查找 sort 冒泡排序（Bubble Sort） 简单选择排序（Simple Selection Sort） 直接插入排序（Straight Insertion Sort） 希尔排序（Shell Sort） 堆排序（Heap Sort） 归并排序（Merging Sort） 快速排序（Quick Sort） 1. 本部分对应源码 https://github.com/mingz2013/data-structures-c 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/data_structures.html":{"url":"algorithm/data_structures.html","title":"数据结构","keywords":"","body":"1. 数据结构1.1. 基本概念1.1.1. 数据1.1.2. 数据元素1.1.3. 数据项1.1.4. 数据对象1.1.5. 数据结构1.2. 逻辑结构与物理结构1.2.1. 逻辑结构：是指数据对象中数据元素之间的相互关系。1.2.2. 物理结构1.3. 抽象数据类型1.3.1. 数据类型1.3.2. 抽象数据类型1.4. 总结回顾2. 参考资料2.1. books Title Date Modified Category 数据结构 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. 数据结构 数据结构：是相互之间存在一种或多种特定关系的数据元素的集合。 1.1. 基本概念 1.1.1. 数据 数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合。 1.1.2. 数据元素 数据元素：是组成数据的，有一定意义的基本单位，在计算机中通常作为整体处理，也被称为记录。 1.1.3. 数据项 数据项：一个数据元素可以由若干个数据项组成。 数据项是数据不可分割的最小单位。 1.1.4. 数据对象 数据对象：是性质相同的数据元素的集合，是数据的子集。 1.1.5. 数据结构 数据结构：是相互之间存在一种或多种特定关系的数据元素的集合。 1.2. 逻辑结构与物理结构 我们在用示意图表示数据的逻辑结构时，要注意两点： 将每一个元素看做一个节点，用圆圈表示。 元素之间的逻辑关系用节点之间的连线表示，如果这个关系是有方向的，那么用带箭头的连线表示。 1.2.1. 逻辑结构：是指数据对象中数据元素之间的相互关系。 逻辑结构是针对具体问题的，是为了解决某个问题，在对问题理解的基础上，选择一个合适的数据结构表示数据元素之间的逻辑关系。 集合结构 集合结构：集合结构中的数据元素除了同属于一个集合外，它们之间没有其他关系。 线性结构 线性结构：线性结构中的数据元素之间是一对一的关系。 树形结构 树形结构：树形结构中的数据元素之间存在一种一对多的层次关系。 图形结构 图形结构：图形结构的数据元素是多对多的关系。 1.2.2. 物理结构 物理结构：是指数据的逻辑结构在计算机中的存储形式。 逻辑结构是面向问题的，而物理结构就是面向计算机的，其基本的目标就是将数据及其逻辑关系存储到计算机的内存中。 数据元素的存储结构形式有两种：顺序存储和链式存储 顺序存储结构 顺序存储结构：是把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系是一致的。 链式存储结构 链式存储结构：是把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的。 1.3. 抽象数据类型 1.3.1. 数据类型 数据类型：是指一组性质相同的值的集合及定义在此集合上的一些操作的总称。 在C语言中，按照取值的不同，数据类型可以分为两类： 原子类型：是不可以再分解的基本类型，包括整型，实型，字符型等。 结构类型：由若干个类型组合而成，是可以再分解的。例如，整型数组是由若干整型数据组成的。 抽象是指抽取出事物具有的普遍性的本质。 1.3.2. 抽象数据类型 抽象数据类型（Abstract Data Type，ADT）：是指一个数学模型及定义在该模型上的一组操作。 ”抽象“的意义在于数据类型的数学抽象特性。 抽象数据类型体现了程序设计中问题分解，抽象和信息隐藏的特性。 为了便于在之后的讲解中对抽象数据类型进行规范的描述，我们给出了描述抽象数据类型的标准格式： ADT 抽象数据类型名 Data 数据元素之间逻辑关系的定义 Operation 操作1 初始条件 操作结果描述 操作2 ... 操作n ... endADT 1.4. 总结回顾 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/algorithm.html":{"url":"algorithm/algorithm.html","title":"算法","keywords":"","body":"1. 算法1.1. 算法的特性1.2. 算法设计的要求1.3. 算法效率的度量方法1.4. 函数的渐进增长1.5. 算法时间复杂度1.5.1. 推导大O阶方法1.5.2. 常数阶1.5.3. 线性阶1.5.4. 对数阶1.5.5. 平方阶1.5.6. 常见的时间复杂度1.5.7. 最坏情况与平均情况1.5.8. 算法空间复杂度1.6. 总结2. 参考资料2.1. books Title Date Modified Category algorithm 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. 算法 算法（Algorithm）是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作。 1.1. 算法的特性 算法具有五个基本特性：输入，输出，有穷性，明确性，可行性。 输入输出：算法具有零个或多个输入。算法至少有一个或多个输出。 有穷性：算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且每一个步骤在可接受的时间内完成。 确定性：算法的每一步骤都具有确定的含义，不会出现二义性。 可行性：算法的每一步都必须是可行的，也就是说，每一步都能够通过执行有限次数完成。 1.2. 算法设计的要求 正确性：算法的正确性是指算法至少应该具有输入，输出和加工处理无歧义性，能正确反映问题的需求，能够得到问题的正确答案， 可读性：算法设计的另一目的是为了便于阅读，理解和交流。 健壮性：当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名其妙的结果。 时间效率高和存储量低：设计算法应该尽量满足时间效率高和存储量低的需求。 时间效率：指的是算法的执行时间，对于同一个问题，如果有多个算法能够解决，执行时间短的算法效率高，执行时间长的效率低。 存储量需求：指的是算法在执行过程中需要的最大存储空间，主要指算法程序运行时所占用的内存或外部硬盘存储空间。 1.3. 算法效率的度量方法 事后统计方法：这种方法主要是通过设计好的测试程序和数据，利用计算机计时器对不同算法编制的程序的运行时间进行比较，从而确定算法效率的高低。 事前分析估算法：在计算机程序编制前，依据统计方法对算法进行估算。 1.4. 函数的渐进增长 函数的渐进增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n>N,f(n)总是比g(n)大，那么，我们说f(n)的增长渐近快于g(n)。 判断一个算法的效率时，函数中的常数和其他次要项常常可以忽略，而更应该关注主项（最高阶项）的阶数。 某个算法，随着n的增大，它会越来越优于另一算法，或者越来越差于另一算法。 这其实就是事前估算方法的理论依据，通过算法时间复杂度来估算算法时间效率。 1.5. 算法时间复杂度 在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，记作：T(n) = O(f(n))。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。 这样用大写O()来体现算法时间复杂度的记法，我们称之为 大O记法。 一般情况下，随着n的增大，T(n)增长最慢的算法为最优算法。 显然，由此算法时间复杂度的定义可知，我们的三个求和算法的时间复杂度分别为O(n), O(1), O(n^2)。我们分别给它们取了非官方的名称，O(1)叫常数阶，O(n)叫线性阶，O(n^2)叫平方阶，当然，还有其他的一些阶，我们之后会介绍。 1.5.1. 推导大O阶方法 推导大O阶： 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中，只保留最高阶项。 如果最高阶项存在且不是1，则去除与这个项相乘的常数。 得到的结果就是大O阶。 1.5.2. 常数阶 首先顺序结构的时间复杂度。下面的算法，也就是刚才的第二种算法（高斯算法），为什么时间复杂度不是O（3）而是O（1）。 int sum = 0, n = 100; /* 执行一次 */ sum = (1 + n) * n / 2; /* 执行一次 */ printf(\"%d\", sum); /* 执行一次 */ 这个算法的运行次数函数是f(n)=3。根据我们推导大O阶的方法，第一步就是把常数项3改为1。在保留最高阶项时发现，它根本没有最高阶项，所以这个算法的时间复杂度为O(1)。 另外，我们试想一下，如果这个算法当中的语句sum=(1+n)*n/2有10句，即： int sum = 0, n = 100; /* 执行一次 */ sum = (1 + n) * n / 2; /* 执行第1次 */ sum = (1 + n) * n / 2; /* 执行第2次 */ sum = (1 + n) * n / 2; /* 执行第3次 */ sum = (1 + n) * n / 2; /* 执行第4次 */ sum = (1 + n) * n / 2; /* 执行第5次 */ sum = (1 + n) * n / 2; /* 执行第6次 */ sum = (1 + n) * n / 2; /* 执行第7次 */ sum = (1 + n) * n / 2; /* 执行第8次 */ sum = (1 + n) * n / 2; /* 执行第9次 */ sum = (1 + n) * n / 2; /* 执行第10次 */ printf(\"%d\", sum); /* 执行一次 */ 事实上无论n为多少，上面的两段代码就是3次和12次执行的差异。这种与问题的大小无关（n的多少），执行时间恒定的算法，我们称之为具有O（1）的时间复杂度，又叫常数阶。 注意：不管这个常数是多少，我们都记作O（1），而不能是O（3），O（12）等其他任何数字，这是初学者常常犯的错误。 对于分支结构而言，无论是真，还是假，执行的次数都是恒定的，不会随着n的变大而发生变化，所以单纯的分支结构（不包含在循环结构中），其时间复杂度也是O(1)。 1.5.3. 线性阶 线性阶的循环结构会复杂很多。要确定某个算法的阶次，我们常常需要确定某个特定语句或某个语句集运行的次数。 因此，我们要分析算法的复杂度，关键就是要分析循环结构的运行情况。 下面这段代码，它的循环的时间复杂度为O(n), 因为循环体中的代码须要执行n次。 int i; for (i = 0; i 1.5.4. 对数阶 下面的这段代码，时间复杂度又是多少呢？ int count = 1; while (count 由于每次count乘以2之后，就距离n更近了一分。也就是说，有多少个2相乘后大于n，就会退出循环。由2^x=n得到x=log2n. 所以这个循环的时间复杂度为O(logn)。 1.5.5. 平方阶 下面例子是一个循环嵌套，它的内循环刚才我们已经分析过，时间复杂度为O(n)。 int i,j; for (i = 0; i 而对于外层的循环，不过是内部这个时间复杂度为O(n)的语句，再循环n次。所以这段代码的时间复杂度为O(n^2)。 如果外循环的循环次数改为了m，时间复杂度就变为O(m*n)。 int i,j; for (i = 0; i 所以我们可以总结得出，循环的时间复杂度等于循环体的复杂度乘以该循环运行的次数。 那么下面这个循环嵌套，它的时间复杂度是多少呢？ int i,j; for (i = 0; i 由于当i=0时，内循环执行了n次，当i=1时，执行了n-1次，…当i=n-1时，执行了1次。所以总的执行次数为： n + (n - 1) + (n - 2) + ...+ 1 = n(n + 1) / 2 = n^2/2 + n/2 用我们推导大O阶的方法，第一条，没有加法常数不予考虑；第二条，只保留最高阶项，因此保留n^2/2;第三条，去除这个项相乘的常数，也就是去除1/2,最终这段代码的时间复杂度为O(n^2)。 从这个例子，我们也可以得到一个经验，其实理解大O推导不算难，难的是对数列的一些相关运算，这更多的是考察你的数学知识和能力。 我们继续看例子，对于方法调用的时间复杂度又如何分析。 int i,j; for (i = 0; i 函数体是打印这个参数。其实这很好理解，function函数的时间复杂度是O(1)。所以整体的时间复杂度为O(n)。 加入function是下面这样的： void function(int count) { int j; for (j = count; j 事实上，这和刚才举的例子是一样的，只不过把嵌套内循环放到了函数中，所以最终的时间复杂度为O(n^2)。 下面这段相对复杂的语句： n++; /* 执行次数为1 */ function(n); /* 执行次数为n */ int i,j; for (i = 0; i 它的执行次数f(n) = 1 + n + n^2 + n(n+1)/2 = 3/2 n^2 + 3/2 n + 1, 根据推导大O阶的方法，最终这段代码的时间复杂度也是O(n^2)。 1.5.6. 常见的时间复杂度 常见的时间复杂度如表2-10-1所示。 常用的时间复杂度所耗费的时间从大到小依次是： 1.5.7. 最坏情况与平均情况 算法的分析也是类似，我们查找一个有n个随机数字数组中的某个数字，最好的情况是第一个数字就是，那么算法的时间复杂度为O(1)，但也有可能这个数字就在最后一个位置上待着，那么算法的时间复杂度就是O(n), 这是最坏的一种情况了。 最坏情况运行时间是一种保证，那就是运行时间将不会再坏了。在应用中，这是一种最重要的需求，通常，除非特别指定，我们提到的运行时间都是最坏情况的运行时间。 而平均运行时间也就是从概率的角度看，这个数字在每一个位置的可能性是相同的，所以平均的查找时间为n/2次后发现这个目标元素。 平均运行时间是所有情况中最有意义的，因为它是期望的运行时间。 对算法的分析， 一种方法是计算所有情况的平均值，这种时间复杂度的计算方法称为平均时间复杂度。 另一种方法是计算最坏情况下的时间复杂度，这种方法称为最坏时间复杂度。 一般在没有特殊说明的情况下，都是指最坏时间复杂度。 1.5.8. 算法空间复杂度 我们在写代码时，完全可以用空间来换时间。 算法的空间复杂度通过计算算法所需的存储空间实现，算法空间复杂度的计算公式记作：S(n)=O(f(n))，其中，n为问题的规模，f(n)为语句关于n所占存储空间的函数。 一般情况下，一个程序在机器上执行时，除了需要存储程序本身的指令，常数，变量和输入数据外，还需要存储对数据操作的存储单元。 若输入数据所占空间只取决于问题本身，和算法无关，这样只需要分析该算法在实现时所需的辅助单元即可。 若算法执行时所需的辅助空间相对于输入数据量而言是个常数，则称此算法为原地工作，空间复杂度为O(1)。 通常，我们都是用”时间复杂度“来指运行时间的需求，使用”空间复杂度“指空间需求。 当不用限定词的使用”复杂度“时，通常都是指时间复杂度。显然我们这本书重点要讲的还是算啊发的时间复杂度问题。 1.6. 总结 主要谈了算法的一些基本概念。谈到了数据结构与算法的关系是相互依赖不可分割的。 算法的定义：算法是解决特定问题求解步骤的描述，在计算机中为指令的有限序列，并且每条指令表示一个或多个操作。 算法的特性：有穷性，确定性，可行性，输入，输出。 算法的设计的要求：正确性，可读性，健壮性，高效率和低存储量需求。 算法特性与算法设计的要求 容易混， 需要对比记忆。 算法的度量方法：事后统计方法（不科学，不准确），事前分析估算方法。 函数的渐近增长：给定两个函数f(n)和g(n), 如果存在一个整数N，使得对于所有的n>N，f(n)总是比g(n)大，那么，我们说f(n)的增长渐近快于g(n)。于是我们可以得出一个结论，判断一个算法好不好，我们只通过少量的数据是不能做出准确判断的，如果我们可以对比算法的关键执行次数函数的渐近增长性，基本就可以分析出：某个算法，随着n的变大，它会越来越优于另一算法，或者越来越差于另一算法。 然后给出了算法时间复杂度的定义和推导大O阶的步骤。 推导大O阶： 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中，只保留最高阶项 如果最高阶项存在且不是1，则去除与这个项相乘的常数。 得到的结果就是大O阶。 通过这个步骤，我们可以在得到算法的运行次数表达式后，很快得到它的时间复杂度，即大O阶。同时也提醒了大家，其实推导大O阶很容易，但如何得到运行次数的表达式却是需要数学功底的。 接着我们给出了常见的时间复杂度所消耗时间的大小排列： 最后，我们给出了关于算法最坏情况和平均情况的概念，以及空间复杂度的概念。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/list.html":{"url":"algorithm/list.html","title":"List","keywords":"","body":"1. 线性表1.1. 线性表的抽象数据类型1.2. 线性表的顺序存储结构1.2.1. 数据长度与线性表长度区别1.2.2. 地址计算方法1.2.3. 顺序存储结构的插入与删除1.2.4. 线性表顺序存储结构的优缺点1.3. 线性表的链式存储结构1.3.1. 头指针与头结点的异同1.3.2. 线性表链式存储结构代码描述1.3.3. 单链表的读取1.3.4. 单链表的插入和删除1.3.5. 单链表的整表创建和整表删除1.4. 单链表结构和顺序存储结构优缺点1.5. 静态链表1.5.1. 静态链表的插入删除操作1.5.2. 静态链表优缺点1.6. 循环链表1.7. 双向链表2. 总结3. 参考资料3.1. books Title Date Modified Category 线性表 2019-07-01 12:00 2019-07-05 12:00 algorithm 1. 线性表 线性表（List）：零个或多个数据元素的有限序列。 若将线性表记为（a1,…,ai-1,ai,ai+1,…,an）,则表中ai-1领先于ai, ai领先于ai+1，称ai-1是ai的直接前驱元素，ai+1是ai的直接后继元素。当i=1,2…,n-1时，ai有且仅有一个直接后继，当i=2,3,…n时，ai有且仅有一个直接前驱。如图3-2-1所示。 线性表元素的个数n（n>=0）定义为线性表的长度，当n=0时，称为空表。 在较复杂的线性表中，一个数据元素可以由若干个数据项组成。 1.1. 线性表的抽象数据类型 ADT 线性表(List) Data 线性表的数据对象集合为{a1, a2, ..., an}, 每个元素的类型均为DataType。其中，除第一个元素a1外，每一个元素有且只有一个直接前驱元素，除了最后一个元素an外，每一个元素有且只有一个直接后继元素。数据元素之间的关系是一对一的关系。 Operation InitList(*L): 初始化操作，建立一个空的线性表L。 ListEmpty(L): 若线性表为空，返回true，否则返回false。 ClearList(*L): 将线性表清空。 GetElem(L, i, *e): 将线性表L中的第i个位置元素值返回给e。 LocateElem(L, e): 在线性表L中查找与给定值e相等的元素，如果查找成功，返回该元素在表中序号表示成功；否则，返回0表示失败。 ListInsert(*L, i, e): 在线性表L中的第i个位置插入新元素e。 ListDelete(*L, i, *e): 删除线性表L中第i个位置元素，并用e返回其值。 ListLength(L): 返回线性表L的元素个数。 endADT 对于不同的应用，线性表的基本操作是不同的，上述操作是最基本的，对于实际问题中涉及的关于线性表的更复杂操作，完全可以用这些基本操作的组合来实现。 1.2. 线性表的顺序存储结构 线性表的顺序存储结构，指的是用一段地址连续的存储单元依次存储线性表中的数据元素。 线性表（a1,a2,…an）的顺序存储示意图如下： 既然线性表的每个数据元素的类型都相同，所以可以用C语言（其他语言也相同）的一维数组来实现顺序存储结构，即把第一个数据元素存到数组下标为0的位置中，接着把线性表相邻的元素存储在数组中相邻的位置。 #define MAXSIZE 20 /* 存储空间初始分配量 */ typedef int ElemType; /* ElemType类型根据实际情况而定，这里假设为int */ typedef struct { ElemType data[MAXSIZE]; /* 数组存储数据元素，最大值为MAXSIZE */ int length; /* 线性表当前长度 */ } SqList; 我们发现描述顺序存储结构需要三个属性： 存储空间的起始位置：数组data，它的存储位置就是存储空间的存储位置。 线性表的最大存储容量：数组长度MaxSize。 线性表的当前长度：length。 1.2.1. 数据长度与线性表长度区别 数组的长度，线性表的长度，两个概念需要区分一下。 数组的长度是存放线性表的存储空间的长度，存储分配后这个量是一般是不变的。 线性表的长度是线性表中数据元素的个数，随着线性表插入和删除操作的进行，这个量是变化的。 在任意时刻，线性表的长度应该小于等于数组的长度。 1.2.2. 地址计算方法 用数组存储顺序表意味着要分配固定长度的数组空间，由于线性表中可以进行插入和删除操作，因此分配的数组空间要大于等于当前线性表的长度。 存储器中的每个存储单元都有自己的编号，这个编号称为地址。 假设每个数据元素占用的是C个存储单元，那么线性表中第i+1个数据元素的存储位置和第i个数据元素的存储位置满足下列关系（LOC表示获得存储位置的函数）。 所以对于第i个数据元素ai的存储位置可以由a1推算得出： 从图3-4-4来理解： 通过这个公式，你可以随时算出线性表中任意位置的地址，不管它是第一个还是最后一个，都是相同的时间。那么我们对每个线性表位置的存入或者取出数据，对于计算机来说都是相等的时间，也就是一个常数，因此用我们算法中学到的时间复杂度的概念来说，它的存取时间性能为O(1)。我们通常把具有这一特点的存储结构称为随机存取结构。 1.2.3. 顺序存储结构的插入与删除 现在我们来分析一下，插入和删除的时间复杂度。 最好情况O(1), 最坏情况O(n)。平均时间复杂度还是O(n)。 这说明，线性表的顺序存储结构，在存，读数据时，不管是哪个位置，时间复杂度都是O(1)，而插入或删除时，时间复杂度都是O(n)。 这说明，它比较适合元素个数不太变化，而更多是存取数据的应用。 1.2.4. 线性表顺序存储结构的优缺点 1.3. 线性表的链式存储结构 为了表示每个数据元素ai与其直接后继数据元素ai+1之间的逻辑关系，对数据元素ai来说，除了存储其本身的信息之外，还需存储一个指示其直接后继的信息（即直接后继的存储位置）。我们把存储数据元素信息的域称为数据域，把存储直接后继位置的域称为指针域。指针域中存储的信息称作指针或链。这两部分信息组成数据元素ai的存储映像，称为节点（Node）。 n个节点（ai的存储映像）链接成一个链表，即为线性表（a1,a2,…an）的链式存储结构，因为此链表的每个节点中只包含一个指针域，所以叫做单链表。 我们把链表中第一个节点的存储位置叫做头指针。 为了更加方便对链表进行操作，会在单链表的第一个节点前附设一个节点，称为头结点。 1.3.1. 头指针与头结点的异同 1.3.2. 线性表链式存储结构代码描述 /* 线性表的单链表存储结构 */ typedef struct Node { ElemType data; struct Node * next; } Node; typedef struct Node * LinkList; /* 定义LinkList */ 从这个结构定义中，我们知道，节点由存放数据元素的数据域存放后继结点地址的指针域组成。 1.3.3. 单链表的读取 最坏情况的时间复杂度是O(n) 1.3.4. 单链表的插入和删除 从整个算法来说，我们很容易推导出：它们时间复杂度都是O(n). 如果在我们不知道第i个元素的指针位置，单链表数据结构在插入和删除操作上，与线性表的顺序存储结构是没有太大优势的。 但如果，我们希望从第i个位置，插入10个元素，对于顺序存储结构意味着，每一次插入都需要移动n-i个元素，每次都是O(n).而单链表，我们只需要在第一次时，找到第i个位置的指针，此时为O(n)。接下来只是简单地通过赋值移动指针而已，时间复杂度都是O(1)。 显然，对于插入或删除数据越频繁的操作，单链表的效率优势就越是明显。 1.3.5. 单链表的整表创建和整表删除 1.4. 单链表结构和顺序存储结构优缺点 若线性表需要频繁查找，很少进行插入和删除操作时，宜采用顺序存储结构。 若需要频繁插入和删除时，宜采用单链表结构。 当线性表中的元素个数变化较大或者根本不知道有多大时，最好采用单链表结构，这样可以不需要考虑存储空间的大小问题。 而如果事先知道线性表的大致长度，比如一年12个月，一周就是七天，这种用顺序存储结构效率会高很多。 1.5. 静态链表 用数组描述的链表叫做静态链表，这种描述方法还有起名叫做游标实现法。 /* 线性表的静态链表存储结构 */ #define MAXSIZE 1000 /* 假设链表的最大长度是1000 */ typedef struct { ElemType data; int cur; /* 游标(Cursor), 为0时表示无指向 */ } Component, StaticLinkList[MAXSIZE]; 1.5.1. 静态链表的插入删除操作 1.5.2. 静态链表优缺点 1.6. 循环链表 将单链表中终端节点的指针端由空指针改为指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称循环链表（circular linked list）。 1.7. 双向链表 双向链表（double linked list）是在单链表的每个节点中，再设置一个指向其前驱节点的指针域。 typedef struct DulNode { ElemType data; struct DulNode * prior; /* 直接前驱指针 */ struct DulNode * next; /* 直接后继指针 */ } DulNode, *DuLinkList; 2. 总结 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/stack.html":{"url":"algorithm/stack.html","title":"stack","keywords":"","body":"1. stack1.1. 栈的顺序存储结构及实现1.1.1. 顺序存储结构的 进栈 出栈 操作1.1.2. 两栈共享空间1.2. 栈的链式存储结构及实现1.2.1. 栈的链式存储结构 进栈 出栈 操作1.3. 栈的作用2. 总结3. 参考资料3.1. books Title Date Modified Category stack 2019-07-01 12:00 2019-07-05 12:00 algorithm 1. stack 栈（stack）是限定仅在表尾进行插入和删除操作的线性表。 我们把允许插入和删除的一端称为栈顶（top），另一端称为栈底（bottom），不含任何数据元素的栈称为空栈。栈又称为后进先出（Last In First Out）的线性表，简称LIFO结构。 栈的插入操作，叫作进栈，也称压栈，入栈。 栈的删除操作，叫作出栈，也有的叫作弹栈。 ADT 栈(stack) Data 同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。 Operation InitStack(*S): 初始化操作，建立一个空栈S。 DestroyStack(*s): 若栈存在，则销毁它。 ClearStack(s): 将栈清空。 StackEmpty(S): 若栈为空，返回true，否则返回false。 GetTop(S, *e): 若栈存在且非空，用e返回S的栈顶元素。 Push(*S, e): 若栈S存在，插入新元素e到栈S中并成为栈顶元素。 Pop(*S, e): 删除栈S中栈顶元素，并用e返回其值。 StackLength(S): 返回栈S的元素个数。 endADT 由于栈本身就是一个线性表，那么上一章我们讨论了线性表的顺序存储和链式存储，对于栈来说，也是同样适用的。 1.1. 栈的顺序存储结构及实现 typedef int SElemType; /* SElemType 类型根据实际情况而定，这里假设为int */ typedef struct { SElemType data[MAXSIZE]; int top; /* 用于栈顶指针 */ }SqStack; 1.1.1. 顺序存储结构的 进栈 出栈 操作 1.1.2. 两栈共享空间 如果我们有两个相同类型的栈，我们为它们各自开辟了数组空间，极有可能是第一个栈已经满了，再进栈就溢出了，而另一个栈还有很多存储空间空闲。 /* 两栈共享空间结构 */ typedef struct { SElemType data[MAXSIZE]; int top1; /* 栈1栈顶指针 */ int top2; /* 栈2栈顶指针 */ } SqDoubleStack; 1.2. 栈的链式存储结构及实现 栈的链式存储结构，简称为链栈。 typedef struct StackNode { SElemType data; struct StackNode * next; } StackNode, *LinkStackPtr; typedef struct LinkStack { LinkStackPtr top; int count; }LinkStack; 1.2.1. 栈的链式存储结构 进栈 出栈 操作 1.3. 栈的作用 栈的引入简化了程序设计的问题，划分了不同关注层次，使得思考范围缩小，更加聚焦于我们要解决的问题核心。 反之，像数组等，因为要分散精力去考虑数组的下标增减等细节问题，反而掩盖了问题的本质。 2. 总结 顺序栈 两栈共享空间 链栈 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/queue.html":{"url":"algorithm/queue.html","title":"queue","keywords":"","body":"1. queue1.1. 循环队列1.2. 队列顺序存储的不足1.3. 队列的链式存储结构及实现1.3.1. 队列的链式存储结构 入队 出队 操作2. 总结3. 参考资料3.1. books Title Date Modified Category queue 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. queue 队列（Queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。 队列式一种先进先出（First In First Out）的线性表，简称FIFO。允许插入的一端称为队尾，允许删除的一端称为队头。 ADT 队列(Queue) Data 同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。 Operation InitQueue(*Q): 初始化操作，建立一个空队列Q。 DestroyQueue(*Q): 若队列Q存在，则销毁它。 ClearQueue(*Q): 将队列Q清空。 QueueEmpty(Q): 若队列Q为空，返回true，否则返回false。 GetHead(Q, *e): 若队列Q存在且非空，用e返回队列Q的队头元素。 EnQueue(*Q, e): 若队列存在，插入新元素e到队列Q中并成为队尾元素。 DeQueue(*Q, *e): 删除队列Q中队头元素，并用e返回其值。 QueueLength(Q): 返回队列Q的元素个数。 endADT 1.1. 循环队列 所以解决假溢出的办法就是后面满了，就再重头开始，也就是头尾相接的循环。 我们把队列的这种头尾相接的顺序存储结构称为循环队列。 1.2. 队列顺序存储的不足 1.3. 队列的链式存储结构及实现 队列的链式存储结构，其实就是线性表的单链表，只不过它只能尾进头出而已，我们把它简称为链队列。 typedef int QElemType; /* QElemType类型根据实际情况而定，这里假设为int */ typedef struct QNode /* 节点结构 */ { QElemType data; struct QNode *next; }QNode, *QueuePtr; typedef struct /* 队列的链表结构 */ { QueuePtr front, rear; /* 队头，队尾指针 */ }LinkQueue; 1.3.1. 队列的链式存储结构 入队 出队 操作 2. 总结 顺序队列 循环队列 链队列 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/string.html":{"url":"algorithm/string.html","title":"string","keywords":"","body":"1. string1.1. 串的比较1.2. 串的抽象数据类型1.3. 串的存储结构1.3.1. 串的顺序存储结构1.3.2. 串的链式存储结构1.4. 朴素的模式匹配算法1.5. KMP模式匹配算法1.6. 总结回顾2. 参考资料2.1. books Title Date Modified Category string 2019-07-01 12:00 2019-07-08 12:00 algorithm 1. string 串（string）是由零个或多个字符组成的有限序列，又名叫字符串。 1.1. 串的比较 事实上，串的比较是通过组成串的字符之间的编码来进行的，而字符的编码指的是字符在对应字符集中的符号。 计算机中的常用字符是使用标准的ASCii编码，更准确一点，由7位二进制数表示一个字符，总共可以表示128个字符。 后来发现一些特殊符号的出现，128个不够用，于是扩展ASCii码由8位二进制数表示一个字符，总共可以表示256个字符，这已经足够满足以英文为主的语言和特殊符号进行输入，存储，输出等操作的字符需要了。 可是，全世界估计要有成百上千种语言与文字，显然这256个字符是不够的，因此后来就有了Unicode编码，比较常用的是由16位的二进制数表示一个字符，这样总共就可以表示216个字符，约是65万多个字符，足够表示世界上所有语言的所有字符了。当然，为了和ASCii码兼容，Unicode的前256个字符与ASCii码完全相同。 所以如果我们要在C语言中比较两个串是否相等，必须是它们串的长度以及它们各个对应位置的字符都相等时，才算是相等。即给定两个串：s=“a1,a2,a3…an”,t=“b1,b2…bm”, 当且仅当n=m,且a1=b1,a2=b2,…an=bm时，我们认为s=t。 那么对于两个串不相等时，如何判定它们的大小呢。我们这样定义： 给定两个串：s=“a1,a2…an”, t=“b1,b2…bm”, 当满足以下条件之一时，s n 存在某个k 1.2. 串的抽象数据类型 ADT 串（string） Data 串中元素仅由一个字符组成，相邻元素具有前驱和后继关系。 Operation StrAssign(T, *chars): 生成一个其值等于字符串常量chars的串T。 StrCopy(T, S): 串S存在，由串S复制得串T。 ClearString(S): 串S存在，将串清空。 StringEmpty(S): 若串S为空，返回true，否则返回false。 StrLength(S): 返回串S的元素个数，即串的长度。 StrCompare(S, T): 若S>T, 返回值>0, 若S=T, 返回0，若S1.3. 串的存储结构 1.3.1. 串的顺序存储结构 串的顺序存储结构是用一组地址连续的存储单元来存储串中的字符序列的。按照预定义的大小，为每个定义的串变量分配一个固定长度的存储区。一般是用定长数组来定义。 1.3.2. 串的链式存储结构 对于串的链式存储结构，与线性表是相似的，但由于串结构的特殊性，结构中的每个元素数据是一个字符，如果也简单的应用链表存储串值，一个节点对应一个字符，就会存在很大的空间浪费。因此，一个节点可以存放一个字符，也可以考虑存放多个字符，最后一个节点若是未被沾满时，可以用”#”或其他非串值字符补全。 当然，这里一个节点存多少个字符才合适就变得很重要，这会直接影响着串处理的效率，需要根据实际情况作出选择。 但串的链式存储结构除了在连接串与传操作时有一定方便之外，总的来说不如顺序存储灵活，性能也不如顺序存储结构好。 1.4. 朴素的模式匹配算法 子串的定位操作通常称作串的模式匹配。应该算是串中最重要的操作之一。 简单地说，就是对主串的每一个字符作为子串开头，与要匹配的字符串进行匹配。对主串做大循环，每个字符开头做T的长度的小循环，直到匹配成功或全部遍历完成为止。 最好的情况O(1), 最坏的情况，O((n-m+1)*m) 太低效。 1.5. KMP模式匹配算法 模式匹配算法，可以大大避免重复遍历的情况，我们把它称之为克努特-莫里斯-普拉特算法，简称KMP算法。 KMP是对朴素匹配算法的优化, O(n+m) TODO 1.6. 总结回顾 这一章节我们重点讲了“串”这样的数据结构，串（string）是由零个或多个字符组成的有限序列，又名叫字符串。 本质上，它是一种线性表的扩展，但相对于线性表关注一个个元素来说，我们对串这种结构更多的是关注它子串的应用问题，如查找，替换等操作。 现在的高级语言都有针对串的函数可以调用。我们在使用这些函数的时候，同时也应该要理解它当中的原理，以便于在碰到复杂的问题时，可以更加灵活的使用，比如KMP模式匹配算法的学习，就是更有效地去理解index函数当中的实现细节。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/tree.html":{"url":"algorithm/tree.html","title":"tree","keywords":"","body":"1. tree1.1. 树的定义1.1.1. 节点分类1.1.2. 节点间关系1.1.3. 树的其他相关概念1.2. 树的抽象数据类型1.3. 树的存储结构1.3.1. 双亲表示法1.3.2. 孩子表示法1.3.3. 孩子兄弟表示法1.4. 二叉树的定义1.4.1. 二叉树的特点1.4.2. 特殊二叉树1.4.3. 二叉树的性质1.4.4. 二叉树的存储结构1.4.5. 遍历二叉树1.4.6. 线索二叉树1.4.7. 树，森林与二叉树的转换1.4.8. 赫夫曼树及其应用1.5. 总结回顾2. 参考资料2.1. books Title Date Modified Category tree 2019-07-01 12:00 2019-07-08 12:00 algorithm 1. tree 1.1. 树的定义 树(Tree)是n(n>=0)个节点的有限集。n=0时称为空树， 在任意一棵非空树中： 有且仅有一个特定的称为根（Root）的节点； 当n>1时，其余节点可分为m(m>0)个互不相交的有限集T1,T2,…Tn，其中每一个集合本身又是一棵树，并且称为根的子树（SubTree）。 树的定义其实就是我们在讲解栈时提到的递归的方法。也就是在树的定义之中还用到了树的概念，这是一种比较新的定义方法。 1.1.1. 节点分类 树的节点包含一个数据元素及若干指向其子树的分支。 节点拥有的子树数称为节点的度（Degree）。度为0的节点称为叶节点（Leaf）或终端节点；度不为0的节点称为非终端节点或分支节点。除根节点之外，分支节点也称为内部节点。树的度是树内各节点的度的最大值。 1.1.2. 节点间关系 节点的子树的根称为该节点的孩子（Child），相应的，该节点称为孩子的双亲（Parent）。 同一个双亲的孩子之间互称兄弟（Sibling）。 节点的祖先是从根到该节点所经分支上的所有节点。 以某节点为根的子树中的任一节点都称为该节点的子孙。 1.1.3. 树的其他相关概念 如果将树中节点的各子树看成从左至右是有次序的，不能互换的，则称该树为有序树，否则称为无序树。 森林（Forest）是m(m>=0)棵互不相交的树的集合。 1.2. 树的抽象数据类型 ADT 树（tree） Data 树是由一个根节点和若干棵子树构成。树中节点具有相同数据类型及层次关系。 Operation InitTree(*T): 构造空树T。 DestroyTree(*T): 销毁树T。 CreateTree(*T, definition): 按definition中给出树的定义来构造树。 ClearTree(*T): 若树T存在，则将树T清为空树。 TreeEmpty(T): 若T为空树，返回true，否则返回false。 TreeDepth(T): 返回T的深度。 Root(T): 返回T的根节点。 Value(T, cur_e): cur_e是树T中一个节点，返回此节点的值。 Assign(T, cur_e, value): 给树T的节点cur_e赋值为value。 Parent(T, cur_e): 若cur_e是树T的非根节点，则返回它的双亲，否则返回空。 LeftChild(T, cur_e): 若cur_e是树T的非叶节点，则返回它的右兄弟，否则返回空。 RightSibling(T, cur_e): 若cur_e有右兄弟，则返回它的右兄弟，否则返回空。 InsertChild(*T, *p, i, c): 其中p指向树T的某个节点，i为所指节点p的度加上1，非空树c与T不相交，操作结果为插入c为树T中p指节点的第i棵子树。 DeleteChild(*T, *p, i): 其中p指向树T的某个节点，i为所指节点p的度，操作结果为删除T中p所指节点的第i棵子树。 endADT 1.3. 树的存储结构 三种不同的表示方法： 双亲表示法 孩子表示法 孩子兄弟表示法 1.3.1. 双亲表示法 我们假设以一组连续空间存储树的节点，同时在每个节点中，附设一个指示器指示其双亲节点到链表中的位置。 其中data是数据域，存储节点的数据信息。而parent是指针域，存储该节点的双亲在数组中的下标。 /* 树的双亲表示法节点结构定义 */ #define MAX_TREE_SIZE 100 typedef int TElemType; /* 树节点的数据类型，目前暂定为整型 */ typedef struct PTNode /* 节点结构 */ { TElemType data; /* 节点数据 */ int parent; /* 双亲位置 */ }PTNode; typedef struct /* 树结构 */ { PTNode nodes[MAX_TREE_SIZE]; /* 节点数组 */ int r, n; /* 根的位置和节点数 */ } PTree; 存储结构的设计是一个非常灵活的过程。一个存储结构设计的是否合理，取决于基于该存储结构的运算是否适合，是否方便，时间复杂度好不好等。 1.3.2. 孩子表示法 每个节点有多个指针域，其中每个指针指向一棵子树的根节点，我们把这种方法叫做多重链表表示法。 1.3.3. 孩子兄弟表示法 任意一棵树，它的节点的第一个孩子如果存在就是唯一的，它的右兄弟如果存在也是唯一的。因此，我们设置两个指针，分别指向该节点的第一个孩子和此节点的右兄弟。 1.4. 二叉树的定义 二叉树（Binary Tree）是n(n>=0)个节点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根节点和两棵互不相交的，分别称为根节点的左子树和右子树的二叉树组成。 1.4.1. 二叉树的特点 二叉树的特点有： 每个节点最多有两棵子树，所以二叉树中不存在度大于2的节点。注意不是只有两棵子树，而是最多有。没有子树或者有一棵子树都是可以的。 左子树和右子树是有顺序的，次序不能任意颠倒。 即使树中某节点只有一棵子树，也要区分它是左子树还是右子树。 二叉树具有五种基本形态： 空二叉树 只有一个根结点 根节点只有左子树 根节点只有右子树 根节点既有左子树又有右子树 1.4.2. 特殊二叉树 斜树 所有的节点都只有左子树的二叉树叫左斜树。所有节点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。 满二叉树 在一棵二叉树中，如果所有分支节点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 满二叉树的特点有： 叶子只能出现在最下一层。出现在其他层就不可能达成平衡 非叶子节点的度一定是2.否则就是“缺胳膊少腿”了。 在同样深度的二叉树中，满二叉树的节点个数最多，叶子数最多。 完全二叉树 对一棵具有n个节点的二叉树按层序编号，如果编号为i（1 这是一种有些理解难度的特殊二叉树。 首先从字面上要区分，“完全”和“满”的差异，满二叉树一定是一棵完全二叉树，但完全二叉树不一定是满的。 完全二叉树的特点： 叶子节点只能出现在最下两层 最下层的叶子一定集中在左部连续位置 倒数二层，若有叶子节点，一定都在右部连续位置 如果节点度为1，则该节点只有左孩子，则不存在只有右子树的情况 同样节点数的二叉树，完全二叉树的深度最小。 1.4.3. 二叉树的性质 性质1：在二叉树的第i层上至多有2^(i-1)个节点(i>=1) 性质2：深度为k的二叉树至多有2^k-1个节点(k>=1) 性质3：对任何一棵二叉树T，如果其终端节点数为n0, 度为2的节点数为n2,则n0=n2+1。 性质4：具有n个节点的完全二叉树的深度为[log2n] +1（[x]表示不大于x的最大整数） 性质5：如果对一棵有n个节点的完全二叉树（其深度为[logxn]+1）的节点按层序编号（从第1层到第[log2n]+1层，每层从左到右），对任一节点i(11，则其双亲是节点[i/2]。 2）如果2i>n，则节点i无左孩子（节点i为叶子节点）；否则其左孩子是节点2i。 3）如果2i+1>n, 则节点i无右孩子；否则其右孩子是节点2i+1。 1.4.4. 二叉树的存储结构 二叉树顺序存储结构 二叉链表 二叉树每个节点最多有两个孩子，所以为它设计一个数据域和两个指针域是比较自然的想法，我们称这样的链表叫做二叉链表。 /* 二叉树的二叉链表节点结构定义 */ typedef struct BiTNode /* 节点结构 */ { TElemType data; /* 节点数据 */ struct BiTNode *lchild, *rchild; /* 左右孩子指针 */ } BiTNode, *BiTree; 1.4.5. 遍历二叉树 二叉树的遍历（traversing binary tree）是指从根节点触发，按照某种次序依次访问二叉树中所有节点，使得每个节点被访问一次且仅被访问一次。 两个关键词：访问 ，次序。 二叉树遍历方法 前序遍历 规则是若二叉树为空，则空操作返回，否则先访问根节点，然后前序遍历左子树，再前序遍历右子树。 中序遍历 规则是若树为空，则空操作返回，否则从根节点开始（注意并不是县访问根节点），中序遍历根节点的左子树，然后是访问根节点，最后中序遍历右子树。 后序遍历 规则是若树为空，则空操作返回，否则从左到右先叶子后节点的方式遍历访问左右子树，最后是访问根节点。 层序遍历 规则是若树为空，则空操作返回，否则从树的第一层，也就是根节点开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对节点逐个访问。 推导遍历结果 已知前序和后序遍历，是不能确定一棵二叉树的。 1.4.6. 线索二叉树 1.4.7. 树，森林与二叉树的转换 1.4.8. 赫夫曼树及其应用 1.5. 总结回顾 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/graph.html":{"url":"algorithm/graph.html","title":"graph","keywords":"","body":"1. graph1.1. 图的定义2. 参考资料2.1. books Title Date Modified Category graph 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. graph 1.1. 图的定义 图（Graph）是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：G（V.E），其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/searching/":{"url":"algorithm/searching/","title":"searching","keywords":"","body":"1. searching1.1. 查找概论1.2. 查找方法2. 总结回顾3. 参考资料3.1. books Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. searching 查找（Searching）就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。 1.1. 查找概论 查找表（Search Table）是由同一类型的数据元素（或记录）构成的集合。 关键字（Key）是数据元素中某个数据项的值，又称为键值，用它可以标识一个数据元素。 若此关键字可以唯一的标识一个记录，则称此关键字为主关键字（Primary Key）。 对于那些可以识别多个数据元素（或记录）的关键字，我们称为次关键字（Secondary Key）。 查找（Searching）就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。 查找表按照操作方式来分有两大种：静态查找表和动态查找表。 静态查找表（Static Search Table）：只作查找操作的查找表。它的主要操作有： 查询某个“特定的”数据元素是否在查找表中 检索某个“特定的”数据元素和各种属性。 动态查找表（Dynamic Search Table）：在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素。显然动态查找表的操作就是两个： 查找时插入数据元素 查找时删除数据元素 为了提高查找的效率，我们需要专门为查找操作设置数据结构，这种面向查找操作的数据结构称为查找结构。 1.2. 查找方法 顺序表查找 有序表查找 线性索引查找 二叉排序树查找 散列表查找 2. 总结回顾 首先，介绍了，查找表，记录，关键字，主关键字，静态查找表，动态查找表，等，这些概念。 然后，对于顺序表查找来说，尽管很土（简单），但它却是后面很多查找的基础， 注意设置“哨兵”的技巧，可以使得本已经很难提升的简单算法里还是提高了性能。 有序查找 折半查找， 插值查找， 斐波那契查找。 线性索引查找， 稠密索引， 分块索引， 倒排索引。 二叉排序树，是动态查找最重要的数据结构。 平衡二叉树（AVL树） B树（2-3树），2-3-4树，B+树。 散列表 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/searching/sequential_search.html":{"url":"algorithm/searching/sequential_search.html","title":"顺序表查找","keywords":"","body":"1.1. 顺序表查找 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 顺序表查找 顺序查找（Sequential Search）又叫线性查找，是最基本的查找技术，它的查找过程是：从表中第一个（或最后一个）记录开始，逐个进行记录的关键字和给定值比较，若某个记录的关键字和给定值相等，则查找成功，找到所查的记录；如果直到最后一个（或第一个）记录，其关键字和给定值比较都不等时，则表中没有所查的记录，查找不成功。 对于这种顺序查找算法来说， 查找成功最好的情况就是第一个位置就找到了，算法时间复杂度为O(1), 最坏的情况是在最后一位置才找到，需要n次比较，时间复杂度为O(n)， 当查找不成功时，需要n+1次比较，时间复杂度为O(n)。 我们之前推导过，关键字在任何一位置的概率是相同的，所以平均查找次数为(n+1)/2, 所以最终时间复杂度还是O(n)。 "},"algorithm/searching/sorted_search.html":{"url":"algorithm/searching/sorted_search.html","title":"有序表查找","keywords":"","body":"1.1. 有序表查找1.1.1. 折半查找1.1.2. 插值查找1.1.3. 斐波那契查找 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 有序表查找 1.1.1. 折半查找 折半查找（Binary Search）技术，又称为二分查找。 它的前提是线性表中的记录必须是关键码有序（通常从小到大有序），线性表必须采用顺序存储。 折半查找的基本思想是：在有序表中，取中间记录作为比较对象，若给定值与中间记录的关键字相等，则查找成功；若给定值小于中间记录的关键字，则在中间记录的左半区继续查找；若给定值大于中间记录的关键字，则在中间记录的右半区继续查找。不断重复上述过程，直到查找成功，或所有查找区域无记录，查找失败为止。 最坏情况是查找到关键字或查找失败的次数为[log2n]+1. 最好情况1次。 因此最终我们折半算法的时间复杂度为O(logn), 它显然远远好于顺序查找的O(n)时间复杂度了。 折半查找的前提条件是需要有序表顺序存储，对于静态查找表，一次排序后不再变化，这样的算法已经比较好了。但对于需要频繁执行插入或删除操作的数据集来说，维护有序的排序会带来不小的工作量，那就不建议使用。 1.1.2. 插值查找 插值查找（Interpolation Search）是根据要查找的关键字key与查找表中最大最小记录的关键字比较后的查找方法，其核心就在于插值的计算公式 (key - a[low]) / (a[high] - a[low]) 1.1.3. 斐波那契查找 "},"algorithm/searching/index_search.html":{"url":"algorithm/searching/index_search.html","title":"线性索引查找","keywords":"","body":"1.1. 线性索引查找1.1.1. 稠密索引1.1.2. 分块索引1.1.3. 倒排索引 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 线性索引查找 数据结构的最终目的是提高数据的处理速度，索引是为了加快查找速度而设计的一种数据结构。 索引就是把一个关键字与它对应的记录相关联的过程，一个索引由若干个索引项构成，每个索引项至少应包含关键字和其对应的记录在存储器中的位置等信息。 索引技术是组织大型数据库以及磁盘文件的一种重要技术。 索引按照结构可以分为线性索引，树形索引和多级索引。 我们这里就只介绍线性索引技术。 所谓线性索引就是将索引项集合组织为线性结构，也称为索引表。 我们重点介绍三种线性索引：稠密索引，分块索引和倒排索引。 1.1.1. 稠密索引 稠密索引是指在线性索引中，将数据集中的每个记录对应一个索引项，如图8-5-2所示。 对于稠密索引这个索引表来说，索引项一定是按照关键码有序的排列。 索引项有序也就意味着，我们要查找关键字时，可以用到折半，插值，斐波那契等有序查找算法，大大提高了效率。 这显然是稠密索引优点，但是如果数据集非常大，比如上亿，那也就意味着索引也得同样的数据集长度规模，对于内存有限的计算机来说，可能就需要反复去访问磁盘，查找性能反而大大下降了。 1.1.2. 分块索引 稠密索引因为索引项与数据集的记录个数相同，所以空间代价很大。为了减少索引项个数，我们可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数。 分块有序，是把数据集的记录分成了若干块，并且这些块需要满足两个条件： 块内无序，即每一块内的记录不要求有序。 块间有序，例如第二块所有记录的关键字均要大于第一块中所有记录的关键字。 对于分块有序的数据集，将每块对应一个索引项，这种索引方法叫做分块索引。 如图8-5-4所示，我们定义的分块索引的索引项结构分三个数据项： 最大关键码， 存储了块中的记录个数，以便于循环时使用 用于指向块首数据元素的指针。 在分块索引表中查找，就是分两步进行： 在分块索引表中查找关键字所在的块。由于分块索引表是块间有序的，因此很容易利用折半，插值等算法得到结果。 根据块首指针找到相应的块，并在块中顺序查找关键码。因为块中可以是无序的，因此只能顺序查找。 分析一下分块索引的平均查找长度。 可见，分块索引的效率比之顺序查找的O(n)是高了不少，不过显然它与折半查找的O(logn)相比还有不少的差距。因此在确定所在块的过程中，由于块间有序，所以可以应用折半，插值等手段来提高效率。 总的来说，分块索引在兼顾了对细分快不需要有序的情况下，大大增加了整体查找的速度，所以普遍被用于数据库表查找等技术的应用当中。 1.1.3. 倒排索引 在这里这张单词表就是索引表，索引项的通用结构是： 次关键码， 记录号表 其中记录号表存储具有相同次关键字的所有记录的记录号（可以是指向记录的指针或是该记录的主关键字）。这样的索引方法就是倒排索引（inverted index）。 "},"algorithm/searching/binary_sort_tree_search.html":{"url":"algorithm/searching/binary_sort_tree_search.html","title":"二叉排序树查找","keywords":"","body":"1.1. 二叉排序树1.1.1. 二叉排序树查找操作1.1.2. 二叉排序树插入操作1.1.3. 二叉排序树删除操作1.1.4. 二叉排序树总结1.2. 平衡二叉树（AVL树）1.3. 多路查找树（B树） Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 二叉排序树 有没有一种既可以使得插入和删除效率不错，又可以比较高效率的实现查找的算法呢？ 也就是说，若我们现在需要对集合{62,88,58,47,35,73,51,99,37,93}做查找，在我们打算创建此集合时就考虑用二叉树结构，而且是排好序的二叉树来创建。 这样我们就得到了一棵二叉树，并且当我们对它进行中序遍历时，就可以得到一个有序的序列{35,37,47,51,58,62,73,88,93,99}, 所以我们通常称它为二叉排序树。 二叉排序树（Binary Sort Tree），又称为二叉查找树。它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有节点的值均小于它的根结构的值 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值 它的左，右子树也分别为二叉排序树 1.1.1. 二叉排序树查找操作 1.1.2. 二叉排序树插入操作 1.1.3. 二叉排序树删除操作 1.1.4. 二叉排序树总结 总之，二叉排序树是以链接的方式存储，保持了链接存储结构在执行插入或删除操作时不用移动元素的优点，只要找到合适的插入和删除位置后，仅需修改链接指针即可。插入删除的时间性能比较好。 而对于二叉排序树的查找，走的就是从根节点到要查找的节点的路径，其比较次数等于给定值的节点在二叉排序树中的层数。 极端情况，最少为1次，即根节点就是要找的节点，最多也不会超过树的深度。 也就是说，二叉排序树的查找性能取决于二叉排序树的形状。 可问题就在于，二叉排序树的形状是不确定的。 也就是说，我们希望二叉排序树是比较平衡的，即其深度与完全二叉树相同，均为[log2n]+1,那么查找的时间复杂度也就为O(logn)，近似于折半查找，事实上，图8-6-18的左图也不够平衡，明显的左重右轻。 不平衡的最坏情况就是像图8-6-18右图的斜树，查找时间复杂度为O(n), 这等同于顺序查找。 因此，如果我们希望对一个集合按二叉排序树查找，最好是把它构建成一颗平衡的二叉排序树。 这样我们就引申出另一个问题，如何让二叉排序树平衡的问题。 1.2. 平衡二叉树（AVL树） 1.3. 多路查找树（B树） "},"algorithm/searching/hash_search.html":{"url":"algorithm/searching/hash_search.html","title":"散列表查找","keywords":"","body":"1.1. 散列表查找（哈希表）概述 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 散列表查找（哈希表）概述 "},"algorithm/sort/":{"url":"algorithm/sort/","title":"sort","keywords":"","body":"1. sort1.1. 排序的稳定性1.2. 内排序与外排序1.3. 排序用到的结构与函数1.4. 七种排序算法1.5. 总结回顾2. 参考资料2.1. books Title Date Modified Category sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. sort 我们在排序问题中，通常将数据元素称为记录。显然我们输入的是一个记录集合，输出的也是一个记录集合，所以说，可以将排序看成是线性表的一种操作。 排序的依据是关键字之间的大小关系，那么，对同一个记录集合，针对不同的关键字进行排序，可以得到不同序列。 1.1. 排序的稳定性 也正是由于排序不仅是针对主关键字，那么对于次关键字，因为待排序的记录序列中可能存在两个或两个以上的关键字相等的记录，排序结果可能会存在不唯一的情况，我们给出了稳定与不稳定排序的定义。 假设ki=kj（1 1.2. 内排序与外排序 根据在排序过程中待排序的记录是否全部被放置在内存中，排序分为：内排序和外排序。 内排序是在排序整个过程中，待排序的所有记录全部被放置在内存中。 外排序是由于排序的记录个数太多，不能同时放置在内存，整个排序过程需要在内外存之间多次交换数据才能进行。 对于内排序来说，排序算法的性能主要是受3个方面影响： 时间性能 辅助空间 算法复杂性 根据排序过程中借助的主要操作，我们把内排序分为： 插入排序， 交换排序， 选择排序， 归并排序。 本章一共要讲解七种排序的算法，按照算法的复杂度分为两大类， 冒泡排序，简单选择排序，直接插入排序属于简单算法。 希尔排序，堆排序，归并排序，快速排序属于改进算法。 1.3. 排序用到的结构与函数 为了讲清楚排序算法的代码，我先提供一个用于排序用的顺序表结构，此结构也将用于之后我们要讲的所有排序算法。 #define MAXSIZE 10 /* 用于要排序数组个数最大值，可根据需要修改 */ typedef struct { int r[MAXSIZE+1]; /* 用于存储要排序数组，r[0]用作哨兵或临时变量 */ int length; /* 用于记录顺序表的长度 */ }SqList; 另外，由于排序最最常用到的操作是数组两元素的交换，我们将它写成函数，在之后的讲解中会大量的用到。 /* 交换L中数组r的下标为i和j的值 */ void swap(SqList *L, int i, int j) { int temp = L->r[i]; L->r[i] = L->r[j]; L->r[j] = temp; } 1.4. 七种排序算法 冒泡排序（Bubble Sort） 简单选择排序（Simple Selection Sort） 直接插入排序（Straight Insertion Sort） 希尔排序（Shell Sort） 堆排序（Heap Sort） 归并排序（Merging Sort） 快速排序（Quick Sort） 1.5. 总结回顾 首先，我们讲了排序的定义，并提到了排序的稳定性， 排序稳定对于某些特殊需求来说是至关重要的，因此在排序算法中，我们需要关注此算法的稳定性如何。 我们根据将排序记录是否全部被放置在内存中，将排序分为 内排序 与 外排序 两种。 外排序需要在内外存之间多次交换数据才能进行。 我们本章主要讲的是内排序的算法。 根据排序过程中借助的主要操作，我们将内排序分为： 插入排序 交换排序 选择排序 归并排序。 之后介绍的7种排序法，就分别是各种分类的代表算法， 事实上，目前还没有十全十美的排序算法，有优点就会有缺点，即使是快速排序法，也只是在整体性能上优越，它也存在排序不稳定，需要大量辅助空间，对少量数据排序无优势等不足。 因此我们就来从多个角度来剖析一下提到的各种排序的长与短。 我们将7种算法的各种指标进行对比。 从算法的简单性来看，我们将7种算法分为两类： 简单算法：冒泡，简单选择，直接插入 改进算法：希尔，堆，归并，快速 从平均情况来看，显然最后3种改进算法要胜过希尔排序，并远远胜过前3种简单算法。 从最好情况看，反而冒泡和直接插入排序要更胜一筹，也就是说，如果你的待排序序列总是基本有序，反而不应该考虑4种复杂的改进算法。 从最坏情况看，堆排序与归并排序又强过快速排序以及其他简单排序。 从空间复杂度来说，归并排序，快速排序，对空间有要求，反而堆排序等对空间要求是O(1)。 从稳定性来看，归并排序最好，对于非常在乎排序稳定性的应用中，归并排序是个好算法。 从待排序记录的个数上来说，待排序的个数n越小，采用简单排序方法越合适。反之，n越大，采用改进排序方法越合适。 3种简单排序算法的移动次数比较，此时简单选择排序就变得非常有优势，原因在于，它通过大量比较后选择明确记录进行移动，有的放矢。因此对于数据量不是很大而记录的关键字信息量较大的排序要求，简单排序算法是占优的。 总之，从综合各项指标来说，经过优化的快速排序是性能最好的排序算法，但是不同的场合我们也应该考虑使用不同的算法来应对它。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/bubble_sort.html":{"url":"algorithm/sort/bubble_sort.html","title":"冒泡排序（Bubble Sort）","keywords":"","body":"1. bubble sort1.1. 最简单排序实现1.2. 冒泡排序算法1.3. 冒泡排序优化1.4. 冒泡排序复杂度分析2. 参考资料2.1. books Title Date Modified Category bubble sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. bubble sort 冒泡排序（Bubble Sort）是一种交换排序，它的基本思想是：两两比较相邻记录的关键字，如果反序则交换，直到没有反序的记录为止。 1.1. 最简单排序实现 冒泡的实现在细节上可以有很多种变化，我们将分别就3种不同的冒泡实现代码，来讲解冒泡排序的思想。这里，我们就先来看看比较容易理解的一段。 /* 对顺序表L作交换排序（冒泡排序初级版） */ void BubbleSort0(SqList *L) { int i, j; for (i = 1; i length; i++) { for (j = i + 1; j length; j++) { if (L->r[i] > L->r[j]) { swap(L, i, j); /* 交换L->r[i] 与 L->r[j]的值 */ } } } } 这段代码严格意义上说，不算是标准的冒泡排序算法，因为它不满足“两两比较相邻记录”的冒泡排序思想，它更应该是最最简单的交换排序而已。 它的思路就是让每一个关键字，都和它后面的每一个关键字比较，如果大则交换，这样第一位置的关键字在一次循环后一定变成最小值。 它应该算是最最容易写出的排序代码了，不过这个简单易懂的代码，却是有缺陷的。观察后发现，在排序好1和2的位置后，对其余关键字的排序没有什么帮助（数字3反而还被换到了最后一位）。也就是说，这个算法的效率是非常低的。 1.2. 冒泡排序算法 我们来看看正宗的冒泡算法，有没有什么改进的地方。 /* 对顺序表L作冒泡排序 */ void BubbleSort(SqList *L) { int i, j; for (i = 1; i length; i++) { for (j = L->length-1; j >= i; j--) /* 注意j是从后往前循环 */ { if (L->r[j] > L->r[j+1]) /* 若前者大于后者（注意这里与上一算法差异） */ { swap(L, j, j+1); /* 交换L->r[j] 与 L->r[j+1] 的值 */ } } } } 图中较小的数字如同气泡般慢慢浮到上面，因此就将此算法命名为冒泡算法。 1.3. 冒泡排序优化 这样的冒泡程序是否还可以优化呢？答案是肯定的。 增加一个标记变量flag来实现这一算法的改进。 void BubbleSort2(SqList *L) { int i, j; Status flag = TRUE; /* flag用来作为标记 */ for (i = 1; i length && flag; i++) /* 若flag为false则退出循环 */ { flag = FALSE; /* 初始化为false */ for (j = L->length - 1; j >= i; j--) { if (L->r[j] > L->r[j+1]) { swap(L, j, j+1); /* 交换L->r[j] 与 L->r[j+1] 的值 */ flag = TRUE; /* 如果有数据交换，则flag为true */ } } } } 1.4. 冒泡排序复杂度分析 时间复杂度。 最好的情况，也就是要排序的表本身就是有序的，那么我们比较次数，根据最后改进的代码，可以推断出就是n-1次的比较，没有数据交换，时间复杂度为O(n)。 最坏的情况，即待排序表是逆序的情况，此时需要比较1+2+3+…+(n-1) = n(n-1)/2 次，并作等数量级的记录移动。因此，总的时间复杂度为O(n^2)。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/select_sort.html":{"url":"algorithm/sort/select_sort.html","title":"简单选择排序（Simple Selection Sort）","keywords":"","body":"1. select sort1.1. 简单选择排序复杂度分析2. 参考资料2.1. books Title Date Modified Category select sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. select sort 简单选择排序法（Simple Selection Sort）就是通过n-1次关键字间的比较，从n-i+1个记录中选出关键字最小的记录，并和第i(1 /* 对顺序表L作简单选择排序 */ void SelectSort(SqList *L) { int i, j, min; for (i = 1; i length; i++) { min = i; /* 将当前下标定义为最小值下标 */ for (j = i + 1; j length; j++) /* 循环之后的数据 */ { if (L->r[min] > L->r[j]) /* 如果有小于当前最小值的关键字 */ { min = j; /* 将此关键字的下标赋值给min */ } } if (i != min) /* 若min不等于i，说明找到最小值，交换 */ { swap(L, i, min); /* 交换L->r[i] 与 L->r[min]的值 */ } } } 1.1. 简单选择排序复杂度分析 从简单选择排序的过程来看，它最大的特点就是交换移动数据次数相当少，这样也就节约了相应的时间。 分析它的时间复杂度发现， 无论最好最差的情况，其比较次数都是一样的多，第i趟排序需要进行n-i次关键字的比较，此时需要比较n-1 + n-2 + …+ 1 = n(n-1)/2 次。 而对于交换次数而言，当最好的时候，交换为0次，最差的时候，也就是初始降序时，交换次数为n-1次， 基于最终的排序时间是比较与交换的次数总和，因此，总的时间复杂度依然是O(n^2)。 应该说，尽管与冒泡排序同为O(n^2)，但简单选择排序的性能上还是要略优于冒泡排序。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/insert_sort.html":{"url":"algorithm/sort/insert_sort.html","title":"直接插入排序（Straight Insertion Sort）","keywords":"","body":"1. insert sort1.1. 直接插入排序复杂度分析2. 参考资料2.1. books Title Date Modified Category insert sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. insert sort 直接插入排序（Straight Insertion Sort）的基本操作是将一个记录插入到已经排好序的有序表中，从而得到一个新的，记录数增1的有序表。 /* 对顺序表L作直接插入排序 */ void InsertSort(SqList *L) { int i, j; for (i = 2; i length; i++) { if (L->r[i] r[i - 1]) /* 需将L->r[i]插入有序子表 */ { L->r[0] = L->r[i]; /* 设置哨兵 */ for (j = i-1; L->r[j] > L->r[0]; j--) { L->r[j+1] = L->r[j]; /* 记录后移 */ } L->r[j+1] = L->r[0]; /* 插入到正确位置 */ } } } 1.1. 直接插入排序复杂度分析 从空间上来看，它只需要一个记录的辅助空间，因此关键是看它的时间复杂度。 当最好的情况，O(n)。 最坏的情况. 平均情况n^2/4。 直接插入排序法的时间复杂度为O(n^2). 同样的O(n^2)时间复杂度，直接插入排序法比冒泡和简单选择排序的性能要好一些。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/shell_sort.html":{"url":"algorithm/sort/shell_sort.html","title":"希尔排序（Shell Sort）","keywords":"","body":"1. shell sort1.1. 希尔排序复杂度分析2. 参考资料2.1. books Title Date Modified Category shell sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. shell sort 希尔排序（Shell Sort）。希尔排序是D.L.Shell于1959年提出来的一种排序算法，在这之前排序算法的时间复杂度基本都是O(n^2)的，希尔排序算法是突破这个时间复杂度的第一批算法之一。 所谓的 基本有序，就是小的关键字基本在前面，大的基本在后面，不大不小的基本在中间，像{2,1,3,6,4,7,5,8,9}这样可以称为基本有序了。 将相距某个“增量”的记录组成一个子序列，这样才能保证在子序列内分别进行直接插入排序后得到的结果是基本有序而不是局部有序。 /* 对顺序表L作希尔排序 */ void ShellSort(SQList *L) { int i, j; int increment = L->length; do { increment = increment / 3 + 1; /* 增量序列 */ for (i = increment + 1; i length; i++) { if (L->r[i] r[i - increment]) { /* 需将L->r[i] 插入有序增量子表 */ L->r[0] = L->r[i]; /* 暂存在L->r[0] */ for (j = i - increment; j > 0 && L->r[0] r[j + increment] = L->r[j]; /* 记录后移，查找插入位置 */ } L->r[j + increment] = L->r[0]; /* 插入 */ } } } while (increment > 1); } 1.1. 希尔排序复杂度分析 希尔排序的关键并不是随便分组后各自排序，而是将相隔某个“增量”的记录组成一个子序列，实现跳跃式的移动，使得排序的效率提高。 增量序列的最后一个增量值必须等于1才行。 不管怎么说，希尔排序算法的发明，使得我们终于突破了慢速排序的时代（超越了时间复杂度为O(n^2)），之后，相应的更为高效的排序算法也就相继出现了。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/heap_sort.html":{"url":"algorithm/sort/heap_sort.html","title":"堆排序（Heap Sort）","keywords":"","body":"1. heap sort1.1. 堆1.2. 堆排序算法1.3. 堆排序复杂度分析2. 参考资料2.1. books Title Date Modified Category heap sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. heap sort 1.1. 堆 堆是具有下列性质的完全二叉树： 每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆（例如图9-7-2左图所示）； 或者每个节点的值都小于或等于其左右孩子节点的值，称为小顶堆（例如图9-7-2右图所示）。 如果将图9-7-2的大顶堆和小顶堆用层序遍历存入数组，则一定满足上面的关系表达，如图9-7-3所示。 我们现在讲这个堆结构，其目的就是为了堆排序用的。 1.2. 堆排序算法 堆排序（Heap Sort）就是利用堆（假设利用大顶堆）进行排序的方法。 它的基本思想是， 将待排序的序列构造成一个大顶堆。此时，整个序列的最大值就是堆顶的根节点。将它移走（其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值），然后将剩余的n-1个序列重新构造成一个堆，这样就会得到n个元素中的次小值。如此反复执行，便能得到一个有序序列了。 相信大家有些明白堆排序的基本思想了，不过要实现它还需要解决两个问题： 如何由一个无序序列构建成一个堆？ 如何在输出堆顶元素后，调整剩余元素成为一个新的堆？ 要解释清楚它们，让我们来看代码。 /* 对顺序表L进行堆排序 */ void HeapSort(SqList *L) { int i; for (i = L->length / 2; i > 0; i--) /* 把L中的r构建成一个大顶堆 */ { HeapAdjust(L, i, L->length); } for (i = L->length; i > 1; i--) { swap(L, 1, i); /* 将堆顶记录和当前未经排序子序列的最后一个记录交换 */ HeapAdjust(L, 1, i-1); /* 将L->r[1...i-1]重新调整为大顶堆 */ } } 从代码中也可以看出，整个排序过程分为两个for循环。 第一个循环要完成的就是将现在的待排序序列构建成一个大顶堆。 第二个循环要完成的就是逐步将每个最大值的根节点与末尾元素交换，并且再调整其成为大顶堆。 既然已经弄清楚i的变化是在调整哪些元素了，现在我们来看关键的HeapAdjust（堆调整）函数是如何实现的。 /* 已知L->r[s..m]中记录的关键字除L->r[s]之外均满足堆的定义 */ /* 本函数调整L->r[s]的关键字，使L->r[s..m]成为一个大顶堆 */ void HeapAdjust(SqList *L, int s, int m) { int twmp, j; temp = L->r[s]; for (j = 2 * s; j r[j] r[j+1]) { ++j; /* j为关键字中较大的记录的下标 */ } if (temp >= L->r[j]) { break; /* rc应插入在位置s上 */ } L->r[s] = L->r[j]; s = j; } L->r[s] = temp; /* 插入 */ } 1.3. 堆排序复杂度分析 整个构建堆的时间复杂度为O(n)。 在正式排序时，第i次取堆顶记录重建堆需要用O(logi)的时间（完全二叉树的某个节点到根节点的距离为[log2i] + 1）, 并且需要取n-1次堆顶记录，因此，重建堆的时间复杂度为O(nlogn)。 所以总体来说，堆排序的时间复杂度为O(nlogn)。由于堆排序对原始记录的排序状态并不敏感，因此它无论是最好，最坏和平均时间复杂度均为O(nlogn)。这在性能上要远远好于冒泡，简单选择，直接插入的O(n^2)的时间复杂度了。 空间复杂度上，它只有一个用来交换的暂存单元，也非常不错。不过由于记录的比较与交换是跳跃式进行，因此堆排序也是一种不稳定的排序方法。 另外，由于初始构建堆所需的比较次数较多，因此，它并不适合待排序序列个数较少的情况。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/merging_sort.html":{"url":"algorithm/sort/merging_sort.html","title":"归并排序（Merging Sort）","keywords":"","body":"1. merging sort2. 参考资料2.1. books Title Date Modified Category merging sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. merging sort 归并排序（Merging Sort）就是利用归并的思想实现的排序方法。 它的原理是 假设初始序列含有n个记录，则可以看成是n个有序的子序列，每个子序列的长度为1，然后两两归并，得到[n/2]（[x]表示不小于x的最小整数）个长度为2或1的有序子序列；再两两归并，…, 如此重复，直至得到一个长度为n的有序序列为止，这种排序方法称为2路归并排序。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/quick_sort.html":{"url":"algorithm/sort/quick_sort.html","title":"快速排序（Quick Sort）","keywords":"","body":"1. quick sort2. 参考资料2.1. books Title Date Modified Category quick sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. quick sort 快速排序（Quick Sort）的基本思想是：通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序的目的。 2. 参考资料 2.1. books 《大话数据结构》 "},"compiler/":{"url":"compiler/","title":"compiler","keywords":"","body":" Title Date Modified Category compiler 2019-06-06 12:00 2019-05-29 12:00 compiler compiler llvm ollvm python源码分析 golang源码分析 "},"compiler/compiler.html":{"url":"compiler/compiler.html","title":"编程语言泛讲","keywords":"","body":"1. 编程语言的分类1.1. 解释型与编译型之分1.1.1. 解释型1.1.2. 编译型1.2. 动态类型与静态类型之分1.2.1. 动态1.2.2. 静态1.3. 强类型与弱类型之分1.3.1. 强类型1.3.2. 弱类型2. 编译器前端与编译器后端2.1. 编译器前端(Front End)2.2. 编译器后端(Back End)3. 编程语言的开发方法3.1. 工具生成3.2. 手工构造4. 编程语言的开发过程4.1. 编程语言的设计4.1.1. bnf, ebnf定义文法4.1.2. 地铁图描述文法4.1.3. 少许理论知识4.2. 词法分析4.3. 语法分析4.4. 抽象语法树4.5. 语义分析4.6. 符号管理4.7. 生成中间代码4.8. 生成汇编代码4.9. 二进制格式4.10. 二进制生成，汇编器4.11. 可执行文件生成，链接器4.12. 错误处理4.13. 优化5. CPU架构6. 虚拟机的设计6.1. 字节码文件的解析6.2. 运行时数据区6.2.1. 栈(stack)的设计6.2.2. 堆(heap)的设计6.2.3. 局部变量6.2.4. 全局变量6.3. 汇编指令与机器码的设计6.4. 解释器的设计6.5. GC垃圾回收7. JIT8. 编程语言分类漫谈9. 编程语言开发示例demo10. 参考资料10.1. books Title Date Modified Category compiler 2019-06-06 12:00 2019-05-29 12:00 compiler 禁止转载 一些图文 出自参考书籍中的截图，如有侵权，请联系删除 1. 编程语言的分类 1.1. 解释型与编译型之分 编程语言可分为解释型和编译型。 1.1.1. 解释型 源代码转换为某种中间状态，如语法树，语法树直接执行 源代码，词法分析，生成token串，语法分析，生成分析树，语法分析树，或语法树，抽象语法树，执行 纯粹的解释型，读一句，解释执行一句，执行到有语法错误的时候才会报错 字节码，解释器运行字节码, 也可称为虚拟机 将抽象语法树转换成字节码，字节码可在虚拟机里执行 也有编译的一个过程 1.1.2. 编译型 编译过程 词法分析, 生成token串，语法分析，生成抽象语法树，生成中间代码，生成各个CPU架构的汇编代码，生成各个平台的二进制， 二进制：真实CPU架构下的二进制，或虚拟机下的二进制（操作码或字节码） 链接过程 链接器，链接成可执行文件 1.2. 动态类型与静态类型之分 1.2.1. 动态 1.2.2. 静态 1.3. 强类型与弱类型之分 1.3.1. 强类型 1.3.2. 弱类型 2. 编译器前端与编译器后端 2.1. 编译器前端(Front End) 从源代码到抽象语法树的过程 2.2. 编译器后端(Back End) 从抽象语法树到二进制的过程 3. 编程语言的开发方法 工具型 手工型 3.1. 工具生成 用一些工具，定义一些文法，通过工具输入文法，自动生成编译器代码。 或者 用正则表达式解析源代码 yacc,lex Javacc 3.2. 手工构造 自顶向下的分析，编写代码 4. 编程语言的开发过程 首先进行编程语言的设计，然后是词法分析，语法分析，语义分析，生成抽象语法树，生成中间代码，生成操作码， 4.1. 编程语言的设计 编程语言的设计，有两种文法表示 4.1.1. bnf, ebnf定义文法 BNF（巴科斯范式，Backus Normal Form） EBNF(扩展巴克斯范式，Extend BNF) 示例： 4.1.2. 地铁图描述文法 4.1.3. 少许理论知识 消除左递归（LL（1）） LL(1) LALR(1) 理解 i++ + ++i 怎么执行的 TODO 4.2. 词法分析 将源代码分割成若干个记号（token）的过程。 首先定义token(记号)，用ebnf文法定义词法 每个token有相应的有限自动机 顺序读取源代码文件每个字符，用token的有限自动机来选择生成不同的token 4.3. 语法分析 即从记号构建分析树（parse tree）的过程。分析树也叫作语法树（syntax tree）或抽象语法树（abstract syntax tree，AST）。 用ebnf定义文法，根据文法写不同的解析代码 4.4. 抽象语法树 终结符与非终结符 可直接编写eval方法，执行每个节点 4.5. 语义分析 检查AST中，是否有语义错误，比如不能除0等 4.6. 符号管理 需要将各个级别的变量，保存到环境变量中，并标记好级别， 在eval的时候，如果生成变量，就new Var，并记录到环境变量中， 如果计算用到了变量，就从环境变量中取出Var用于计算 如果推出当前级别的空间，就释放当前级别的空间内的变量,作用域管理 4.7. 生成中间代码 符号表，语义分析，中间代码优化等。 4.8. 生成汇编代码 了解不同CPU架构的汇编语言，或自定义虚拟机的汇编语法 汇编代码优化 4.9. 二进制格式 4.10. 二进制生成，汇编器 了解各个平台的可执行文件结构，格式，编写汇编器，生成二进制 4.11. 可执行文件生成，链接器 链接成可执行文件 4.12. 错误处理 伴随着每个过程，都需要有错误处理，和友好的错误提示 4.13. 优化 中间代码优化，汇编代码优化，等，每一部分都有优化部分 5. CPU架构 intel x86 ARM Power TODO 6. 虚拟机的设计 模拟真实CPU架构 定义栈空间，定义堆空间，定义寄存器，等数据结构 6.1. 字节码文件的解析 读取文件，读取一个个指令，巨大的switch case结构 6.2. 运行时数据区 6.2.1. 栈(stack)的设计 栈帧 6.2.2. 堆(heap)的设计 6.2.3. 局部变量 6.2.4. 全局变量 6.3. 汇编指令与机器码的设计 6.4. 解释器的设计 6.5. GC垃圾回收 7. JIT java，.NET Framework都具备在运行的同时将字节码转换为机器码的功能，这叫做JIT，Just-In-Time编译技术。 8. 编程语言分类漫谈 JVM虚拟机，Java，Groovy，Scala，Clojure，Jython，JRuby等。 CPython Pypy go js 9. 编程语言开发示例demo py.calc解释型语言 10. 参考资料 10.1. books 《Lua设计与实现》 《Lua 源码欣赏》 《Go 1.5 源码剖析》 《Python源码剖析--深度探索动态语言核心技术》 《编译器构造（Java语言版）》 《自己动手写Java虚拟机》 《揭秘Java虚拟机-JVM设计原理与实现》 《自制编程语言》 《两周自制脚本语言》 《自制编译器》 《自己动手构造编译系统 编译、汇编与链接》 《自己动手写编译器、链接器》 《C编译器剖析》 《可变目标C编译器：设计与实现》 《深入分析GCC》 《高级编译器设计与实现》 《编译系统透视 图解编译原理》 《编译原理》 《现代编译原理：c语言描述》 《程序是怎样跑起来的》 《计算的本质：深入剖析程序和计算机》 "},"compiler/llvm.html":{"url":"compiler/llvm.html","title":"llvm","keywords":"","body":"1. llvm2. 参考2.1. books1. llvm 2. 参考 2.1. books 《LLVM Cookbook中文版》 "},"compiler/ollvm.html":{"url":"compiler/ollvm.html","title":"ollvm","keywords":"","body":"1. 做的事情2. 名词介绍2.1. gcc2.2. llvm2.3. clang2.4. ollvm3. llvm相关架构与原理4. ollvm扩展内容5. demo6. 攻与防7. github8. 参考书籍9. links Title Date Modified Category compiler 2019-06-06 12:00 2019-05-29 12:00 compiler 1. 做的事情 之前已经做的东西，资源加密，符号混淆 本次做的事情，代码膨胀，变形 2. 名词介绍 2.1. gcc GNU编译器套件（GNU Compiler Collection）包括C、C++、Objective-C、Fortran、Java、Ada和Go语言的前端，也包括了这些语言的库（如libstdc++、libgcj等等）。GCC的初衷是为GNU操作系统专门编写的一款编译器。GNU系统是彻底的自由软件。此处，“自由”的含义是它尊重用户的自由。 2.2. llvm LLVM是构架编译器(compiler)的框架系统，以C++编写而成，用于优化以任意程序语言编写的程序的编译时间(compile-time)、链接时间(link-time)、运行时间(run-time)以及空闲时间(idle-time)，对开发者保持开放，并兼容已有脚本。 2.3. clang Clang是一个C语言、C++、Objective-C语言的轻量级编译器。源代码发布于BSD协议下。Clang将支持其普通lambda表达式、返回类型的简化处理以及更好的处理constexpr关键字。 2.4. ollvm OLLVM（Obfuscator-LLVM）是瑞士西北应用科技大学安全实验室于2010年6月份发起的一个项目，这个项目的目标是提供一个LLVM编译套件的开源分支，能够通过代码混淆和防篡改，增加对逆向工程的难度，提供更高的软件安全性。目前，OLLVM已经支持LLVM-4.0.1版本。OLLVM的混淆操作就是在中间表示IR层，通过编写Pass来混淆IR，然后后端依据IR来生成的目标代码也就被混淆了。得益于LLVM的设计，OLLVM适用LLVM支持的所有语言（C, C++, Objective-C, Ada 和 Fortran）和目标平台（x86, x86-64, PowerPC, PowerPC-64, ARM, Thumb, SPARC, Alpha, CellSPU,MIPS, MSP430, SystemZ, 和 XCore） 3. llvm相关架构与原理 https://llvm.org/docs/ http://www.aosabook.org/en/llvm.html https://llvm.org/docs/WritingAnLLVMPass.html 4. ollvm扩展内容 https://github.com/obfuscator-llvm/obfuscator/wiki -fla 控制流扁平化的PASS参数 -sub指令替换的PASS参数 -bcf虚假控制流的PASS参数 https://blog.csdn.net/chrisnotfound/article/details/79026449 5. demo 用Armariris演示编译一个简单的C源码，试用各种参数。 对编译出的二进制进行分析，查看文件大小，用ida分析二进制，展示流图。 6. 攻与防 https://bbs.pediy.com/thread-217727.htm http://www.freebuf.com/articles/terminal/130142.html 7. github llvm ollvm Hikari Armariris mcsema 8. 参考书籍 《iOS应用逆向与安全》 《编译与反编译技术实战》 《LLVM Cookbook中文版》 9. links gcc clang LLVM和GCC的区别 "},"compiler/python源码分析.html":{"url":"compiler/python源码分析.html","title":"python源码分析","keywords":"","body":"1. python源码分析1.1. python中的对象1.1.1. PyObject1.1.2. PyTypeObject1.1.3. PyIntObject1.1.4. PyStringObject1.1.5. PyListObject1.1.6. PyDictObject1.1.7. PyCodeObject1.2. python vm1.2.1. PyFrameObject1.2.2. PyFunctionObject1.3. gc1.4. 参考1.4.1. sites1.4.2. books1. python源码分析 1.1. python中的对象 1.1.1. PyObject 1.1.2. PyTypeObject 1.1.3. PyIntObject PyIntObject对象是不可变对象。 小整数对象 使用对象池技术。集合范围[-5, 257) 大整数对象 PyIntBlock。 python运行环境提供一块内存空间，这些内存空间由这些大整数轮流使用。 1.1.4. PyStringObject 字符串对象。 PyStringObject是一个拥有可变长度内存的对象。 同时，PyStringObject又是一个不变对象。 1.1.5. PyListObject 变长对象。 1.1.6. PyDictObject 1.1.7. PyCodeObject .pyc文件。 dis标准库，反编译 反编译pyc https://github.com/wibiti/uncompyle2 python字节码 https://docs.python.org/2.4/lib/bytecodes.html 1.2. python vm 对x86平台的模拟 1.2.1. PyFrameObject 1.2.2. PyFunctionObject 1.3. gc 引用计数 标记清除 1.4. 参考 1.4.1. sites http://www.python.org python docs python 语言参考 1.4.2. books 《Python源码分析》 "},"compiler/golang源码分析.html":{"url":"compiler/golang源码分析.html","title":"golang源码分析","keywords":"","body":"1. golang1.1. 参考1.1.1. sites1. golang 1.1. 参考 1.1.1. sites https://golang.org/ref/spec "},"lang/":{"url":"lang/","title":"lang","keywords":"","body":" Title Date Modified Category lang 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/golang/":{"url":"lang/golang/","title":"Golang","keywords":"","body":" Title Date Modified Category golang 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/html/":{"url":"lang/html/","title":"HTML","keywords":"","body":" Title Date Modified Category html 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/js/":{"url":"lang/js/","title":"JS","keywords":"","body":" Title Date Modified Category js 2019-06-14 12:00 2019-06-14 12:00 lang "},"lang/python/":{"url":"lang/python/","title":"Python","keywords":"","body":" Title Date Modified Category python 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/c/":{"url":"lang/c/","title":"C","keywords":"","body":" Title Date Modified Category c 2019-07-16 12:00 2019-07-16 12:00 lang OO "},"lang/assembly/":{"url":"lang/assembly/","title":"Assembly","keywords":"","body":" Title Date Modified Category assembly 2019-07-09 12:00 2019-07-09 12:00 lang "},"design/":{"url":"design/","title":"design","keywords":"","body":"1. 程序设计1.1. 参考资料1.1.1. books Title Date Modified Category design 2019-11-20 12:00 2019-11-20 12:00 design 1. 程序设计 design oo design patterns design-patterns 创建型（creational） Abstract Factory 抽象工厂 Builder 生成器 Factory Method 工厂方法 Prototype 原型 Singleton 单件 结构型（structural） Adapter 适配器 Bridge 桥接 Composite 组成 Decorator 装饰 Facade 外观 Flyweight 享元 Proxy 代理 行为型（behavioral） Chain of Responsibility 职责链 Command 命令 Interpreter 解释器 Iterator 迭代器 Mediator 中介者 Memento 备忘录 Observer 观察者 State 状态 Strategy 策略 Template Method 模板方法 Visitor 访问者 关于设计模式的探讨(演讲稿) 1.1. 参考资料 1.1.1. books 《人月神话》 《软件工程》第9版 《系统架构师》第2版 《软件框架设计的艺术》 《软件工程：面向对象和传统的方法（原书第8版）》 《软件建模与设计：UML、用例、模式和软件体系结构》 《面向对象葵花宝典：思想、技巧与实践》 《Java编程思想(第4版)》 《敏捷软件开发 原则，模式与实战》 《代码整洁之道》 《设计模式：可复用面向对象软件的基础》 《软件设计精要与模式》第2版 《大话设计模式》 《head first设计模式》 《Python编程实战 运用设计模式、并发和程序库创建高质量程序》 《精通Python设计模式》 《JavaScript设计模式》 《C现代编程》 "},"design/design.html":{"url":"design/design.html","title":"design","keywords":"","body":"1. 设计1.1. 原点 - 程序设计。1.1.1. 程序1.1.2. 设计1.2. 来自《人月神话》一书中的观点1.3. 程序设计思想进化史1.3.1. 史前时代：面向机器1.3.2. 脱离机器第一步：面向过程1.3.3. 第一次软件危机：结构化程序设计1.3.4. 第二次软件危机：面向对象程序设计1.4. 计划的设计与演进的设计1.4.1. 计划的设计1.4.2. 演进的设计1.4.3. 计划的设计 vs 演进的设计1.5. 敏捷开发1.5.1. 过度设计，还是简单设计1.5.2. 代码中的坏味道1.5.3. 原则1.5.4. 臭味与原则1.5.5. 需要设计模式吗1.6. 变化1.7. 重构是必然的1.8. 关于几个编程语言1.8.1. 不同语言1.8.2. python1.8.3. C1.8.4. Go1.8.5. Java1.8.6. C++1.9. 架构设计1.9.1. 是什么1.9.2. 为什么做架构设计1.9.3. 架构的标准1.9.4. 架构设计原则1.9.5. 架构设计屠龙刀1.9.6. 优秀架构设计品质 Title Date Modified Category design 2019-11-20 12:00 2019-11-20 12:00 design 1. 设计 设计没有标准，只有目标。如果硬要指定一个标准，那么标准就是快捷，适用与优雅。 1.1. 原点 - 程序设计。 不弄清楚本质怎么行呢？ 1.1.1. 程序 关于我对程序的看法 程序，静态的时候是躺在磁盘里的可执行文件。动态的时候是运行着的进程。内核里对应的是个内核线程。 程序，本质，就是数据加逻辑的组合。是数据+算法。 逻辑可以用来改变数据。 逻辑可以用数据做参数，通过计算产生新的数据 数据可以用来控制逻辑的走向。 看不清本质，就会被眼花缭乱的各种思想，规则所迷惑。 1.1.2. 设计 设计的目的是如何驾驭复杂的程序逻辑。 所有的思想，规则，都是想要以一种思路去驾驭复杂的运行流程。设计算法的手段。 1.2. 来自《人月神话》一书中的观点 所有软件活动包括 根本任务：打造由抽象软件实体构成的复杂概念结构， 次要任务：使用编程语言表达这些抽象实体，在空间和时间限制内将它们映射成机器语言。 面向对象主要是在解决次要任务上面有作用。 而根本性问题依旧复杂，没有银弹。 1.3. 程序设计思想进化史 1.3.1. 史前时代：面向机器 起初，人们写01串，输入机器。 然后，创建了汇编语言做标记。 1.3.2. 脱离机器第一步：面向过程 COBOL, FORTRAN, BASIC, C语言等。 面向过程是一种以“过程”作为中心的编程思想，其中过程的含义就是“完成一件事情的步骤”。 即使我们使用面向对象的语言进行开发，最后转换为CPU能执行的指令，也还是面向过程的。所以说，面向过程无处不在，是计算机的基石。 1.3.3. 第一次软件危机：结构化程序设计 结构化程序设计的主要特点是抛弃goto语句，采取“自顶向下，逐步细化，模块化”的指导思想。 结构化程序设计本质上还是一种面向过程的设计思想，但通过“自顶向下，逐步细化，模块化”的方法，将软件的复杂度控制在一定范围内，从而从整体上降低了软件开发的复杂度。 科学研究证明，人脑存在人类短期记忆，一般一次只能记住5~9个事物，这就是著名的7+-2原理。 1.3.4. 第二次软件危机：面向对象程序设计 面向对象开始时也被当作解决软件危机的银弹，但事实证明，和软件工程一样，面向对象也不是银弹，而只是一种新的软件方法而已。 虽然面向对象并不是解决软件危机的银弹，但和面向过程相比，面向对象的思想更加贴近人类思维的特点，更加脱离机器思维，也是软件设计思想上的一次巨大的飞跃。 1.4. 计划的设计与演进的设计 1.4.1. 计划的设计 提前设计好，再进行开发。 要求我们首要考虑的不是编码，而是整个系统的架构。了解客户的需求。把握开发的进度。遵循统一的设计规范与原则，并对可能存在的技术难点进行预研。确定每一个模块的功能，以及模块间的关系和系统分布的层次。 计划的设计则需要全面地把控系统的整体需求，衡量所有设计要素与约束，以求满足系统所有的功能性需求与非功能性需求。 计划的设计会充分地考虑系统的可扩展性，将未来的变化纳入到一个可控的范围内。这种前瞻式设计需要软件架构师的匠心独运，然而一不小心，就会导致设计过度。 设计阶段需要花费大量的时间精力. 如果需求有变动，又要重新进行设计。 1.4.2. 演进的设计 写代码吧，有新的需求，重构。 是一个渐进的过程。不要求前期的设计有多么的完美，实现的需求有多么的完整，仅需要把现阶段考虑的问题通过编码实现就可以了。随着演进的深入，对需求更加准确的理解，编码也会随之而修正，整个设计会逐渐丰满起来，经过逐步地演化，最后趋于完美。 演进的设计更接近敏捷的开发理念，提倡简单设计与设计重构，从而应对快速开发的要求，满足可能的需求变化。 演进的设计可以有效地避免这种设计上的浪费，但我们却不可忽视它可能带来的重构成本。 1.4.3. 计划的设计 vs 演进的设计 计划的设计，从一开始就全盘考虑，仔细设计。也有可能导致过度设计。 演进的设计，类似于敏捷开发。是一个渐进的过程。提倡简单设计与设计重构。可以有效避免设计上的浪费。却不能忽视重构成本。 两者并非水火不容，应当取长补短，配合使用。 无论采用何种设计方式，最关键的还是在于客户的需求。 软件开发中，唯一不变的就是变化。变化是常态，我们无法规避。 1.5. 敏捷开发 敏捷开发告诉我们，为当下功能进行设计，不要假设未知的变化。否则会导致过度设计。 当变化真正来临的时候，重构当前设计，以满足变化的需求。 1.5.1. 过度设计，还是简单设计 Kent Beck在《解析极限编程-拥抱变化》中为简单系统制定了4个评价标准，依次为（最重要的排在最前面）： 通过所有测试 体现所有意图 避免重复 类或者方法数量最少 1.5.2. 代码中的坏味道 僵化性（Rigidity）：设计难以改变。 脆弱性（Fragility）：设计易于遭到破坏。 牢固性（Immobility）：设计难以重用。 粘滞性（Viscosity）：难以做正确的事情。 不必要的复杂性（Needless Complexity）：过分设计。 不必要的重复（Needless Repetition）：滥用鼠标。 晦涩性（Opacity）：混乱的表达。 1.5.3. 原则 单一职责原则（The Single Responsibility Principle，简称SRP） 开放-封闭原则（The Open-Close Principle，简称OCP） Liskov替换原则（The Liskov Substitution Principle，简称LSP） 依赖倒置原则（The Dependency Inversion Principle，简称DIP） 接口隔离原则（The Interface Segregation Interface，简称ISP） 1.5.4. 臭味与原则 设计中的臭味是一种症状，是可以主观（如果不能客观的话）进行度量的。这些臭味常常是出于违反了这些原则中的一个或者多个而导致的。 敏捷团队应用这些原则来除去臭味。当没有臭味时，他们不会应用这些原则。仅仅因为是一个原则就无条件的去遵循它的做法是错误的。这些原则不是可以随意在系统中到处喷洒的香水。过分遵循这些原则会导致不必要的复杂性（Needless Complexity）的设计臭味。 敏捷开发人员不会对一个庞大的预先设计应用那些原则和模式。相反，这些原则和模式被应用在一次次的迭代中，力图使代码以及代码所表达的设计保持干净。 1.5.5. 需要设计模式吗 如果仅考虑实现当前的功能需求，还需要设计模式吗？坦白的说，我并不认为设计模式与过度设计有关。过度设计的导火索是设计模式的滥用。很多时候，合理的利用设计模式反而能使程序结构简单化，特别是，它能够让开发过程更简单。 需要设计模式吗？答案看来是不言而喻。关键一点是需要确定模式的应用是否过度？ 世界上很多天才横溢的程序员，可以在一段代码中包含6种设计模式，也可以不利用模式就能把设计做得很好。 我们需要的是有效的设计。学习设计模式，不是为了炫耀，吹嘘，不是为了故作艰深，而是为了改善我们的设计，它可以为某种功能实现提供参考模型，设计方法以及应用范例。 我们不需要奉GoF的设计模式为圭（gui）臬（nie），盲目地膜拜它，合理地运用设计模式，才是明智的抉择。 1.6. 变化 软件开发中，唯一不变的就是变化。 1.7. 重构是必然的 适时地重构不仅能改善系统的整个架构，也能为今后的设计提供指引。甚至在数度重构之后，因为设计的合理性，会成为今后项目开发的框架平台或者公共类库。 如果从纯技术的角度来看，重构非但必然，而且重要。重构是必然的。重构是不可避免的。 引入重构技术，完全符合简单设计的原则。重构让设计变得简单直接 的 表达需求。 对于系统架构师而言，重构技术能够降低糟糕的设计给软件开发带来的风险。 软件设计难以一蹴而就，演进的设计证明了这一点。 即使采用计划的设计，同样需要在设计过程中对架构完成重构。 任何的设计都不可能hold住所有的变化，即使是计划的设计。 软件开发唯一不变的就是变化。 以设计模式作参考，可以很好地组织。 1.8. 关于几个编程语言 1.8.1. 不同语言 高级语言及其分类 过程式语言 函数式语言 逻辑程序设计语言 面向对象的语言 结构化查询语言 其他面向特定应用领域的语言 1.8.2. python 我认为，Python是一门更加高级的语言。很多设计模式已经隐藏其中。 Python的动态性是优点也是缺点。 鸭子类型，看起来是，那就是. 面向对象理论中的“类”和“对象”这两个概念在Python中都是通过Python内的对象来实现的。 python是由C实现的。 python是一种简单、灵活的动态语言，python简化了面向对象语法的复杂性，但却没有降低面向对象的特性。 使用python同样可以实现各种设计模式，而且实现过程比较简单。 python的动态性有时候也是一种灾难，尤其是构建大型复杂的系统的时候 1.8.3. C C一般人叫做面向过程的语言。但其实C也是可以面向对象的思想。 kobject与面向对象编程语言（像C++或Java）中的对象概念的相似性决不是巧合。 kobject抽象实际上提供了在内核使用面向对象技术的可能性，而无需C++的所有额外机制（以及二进制代码大小的膨胀和额外开销）。 1.8.4. Go 没有继承的概念。没有类的概念。 Go以一种不同寻常的方式来诠释面向对象程序设计。 它没有类继承，甚至没有类。 较复杂的对象行为是通过较简单的对象组合（而非继承）完成的。 方法可以关联到任何用户定义的类型，而不一定是结构体。 具体类型和抽象类型（即接口）之间的关系是隐式的，所以一个具体类型可能会实现该类型设计者没有意识到其存在的接口。 1.8.5. Java 语言本身就存在着过度设计。更何况使用其设计的程序呢 1.8.6. C++ 即使是C++的设计者也不能hold住所有的特性。一般用C++，找一个子集功能就好了。 1.9. 架构设计 软件架构的地位举足轻重，甚至在很多时候，它是项目成败与否的关键。 1.9.1. 是什么 架构设计就是设计系统的顶层结构。 1.9.2. 为什么做架构设计 架构设计是为了隔离关注点，降低复杂度。 架构设计是为了分工合作。 架构设计就是“面向对象”思想的一个具体应用而已。 也就是说，“面向对象”的思想既可以指导程序设计，也可以指导架构设计； 而且在架构设计领域，可以说只有“面向对象”这一种指导思想，因为架构设计必须划分出模块并设计好模块的交互方式。 更进一步分析： 面向对象程序设计通过封装“类”来降低复杂度， 面向对象架构设计通过封装为“模块”来降低复杂度； 面向对象程序设计通过“类交互”来完成分工合作， 面向对象架构设计通过“模块交互”来完成分工合作。 1.9.3. 架构的标准 根据IEEE的定义，软件架构（Architecture）是以组件，组件之间的关系，组件与环境之间的关系为内容的某一系统的基本组织结构，以及指导上述内容设计与演化的原理。 而Martin Fowler则认为，架构是系统核心而又稳定的组成部分，是系统构建的基础。作为软件设计的高层部分，架构从整体到部分对软件系统进行了最高层次的划分，它是支撑更细节设计的框架。因而，我们有时候也将软件架构称为高层设计（High-level Design）或顶层设计（Top-level Design）。 一般而言，架构需要关注如下内容。 程序组织（Program Organization） 数据设计（Data Design） 安全性（Security） 性能（Performance） 可扩展性（Scalability） 可靠性（Reliability） 可用性（Usability） 1.9.4. 架构设计原则 客户需求优先原则 适当超前原则 唯一不变的是变化！ 首先要满足客户需求，然后再超越客户需求。 关键在于“适当”二字。 1.9.5. 架构设计屠龙刀 \"拆\"与\"合\" 拆的常用手段 拆硬件 拆地点 拆功能 至于逻辑的拆分。 分层，可分为网络接口层，数据库接口层，配置接口层，model层。中间的是核心逻辑。 大部分程序这样拆开后，最后的核心逻辑少得可怜，根本不需要什么设计。 如果中间逻辑还是很复杂，接着拆，横向拆，竖着拆，拆成不同的函数组的模块。终究能够将核心逻辑摘出来。 怎么拆？核心思想就是，从外层一层一层的拆，这样可以保证模块的依赖关系是单向无环的图状结构。最完美的情况下应该是一个树状结构。 大部分功能，这样干都能解决了，甚至可以将逻辑拆的很细的模块，函数可以很小，看起来也很好了。 简单实例 合的常见手段 客户端合 网络合 中间件合 子系统合 1.9.6. 优秀架构设计品质 创新 "},"design/oo/":{"url":"design/oo/","title":"oo","keywords":"","body":"1. 面向对象1.1. 对象1.1.1. 属性和方法1.2. 什么是面向对象？1.3. 为什么要面向对象？1.4. 面向对象的应用范围1.4.1. 能做什么1.4.2. 不能做什么1.5. 面向对象迷思1.5.1. 面向对象会导致性能降低？1.5.2. 面向对象语言=面向对象编程？1.6. 面向对象核心要素，特征1.6.1. 封装1.6.2. 继承1.6.3. 多态1.7. 内聚与耦合1.7.1. 内聚1.7.2. 耦合1.7.3. 高内聚低耦合1.8. 面向对象设计原则1.8.1. 面向对象设计原则1.8.2. NOP Title Date Modified Category oo 2019-11-20 12:00 2019-11-20 12:00 oo 1. 面向对象 面向对象思想为软件设计与开发赋予了哲学的意义。 1.1. 对象 面向对象思想的精要，在于“一切皆为对象”的本质。 那么，什么是对象呢？一般认为，对象是一个真实的或抽象的元素，它包含了描述信息的属性以及处理对象信息的行为。行为在对象定义时，又表现为方法。 在进行面向对象设计时，开发者就是造物主，是抟（tuan）土造人的女娲，对象的一切要素均掌握在开发者手中。 然而，一个好的开发者却不能随心所欲地“创造”对象，他们应该是系统需求的忠实执行者，对象的属性与行为，特别是对象的粒度都必须由系统需求决定。 1.1.1. 属性和方法 从词义学的角度来看，属性偏向于名词的范畴，行为则具有动词的词性。 虽然说对象是由属性和行为组成的，但并不代表它们必须被对象同时拥有，仅仅拥有属性或者行为的对象在系统设计中比比皆是。之所以如此定义，或者是由对象的自身特质所决定的，也可能根据设计的要求而定。 对象的属性与行为并非一成不变，根据实际情况，同一种对象具有的属性和行为可能会发生变化。 1.2. 什么是面向对象？ 以一种我们可以理解的抽象，去构造。 对于面向对象思想的理解，就是将这个对象看做一个整体。看成一个物体。是一种抽象思维。全靠想象。想象力有多丰富，程序里对象的世界就有多精彩。 大部分人的想象力都没有太丰富，大部分都是在用我们能理解的东西做类比。 在面向过程中有“程序=算法+数据结构”的经典总结，面向对象也有类似的总结：“程序=对象+交互”。其中对象就是具体存在的事物，而交互则是事物之间的相互作用，互动等。 1.3. 为什么要面向对象？ 面向对象思想的核心是“可扩展性”！有了面向对象，我们可以将变化带来的影响控制在有限的范围内，避免产生全流程或者大范围的影响，从而降低风险。 面向对象是一种以“对象”作为中心的编程思想，其中对象的含义可以理解为“存在的东西”。 面向对象这种对现实世界的模拟的思想，其本质上就是“人的思想”，这是一个质的飞跃，意味着程序员可以按照人的思想来观察，分析，设计系统。 人大部分的时间都是按照面向对象的方式进行思考的，而且人类世界主要也是按照面向对象的方式进行运转的，所以说，“面向对象”其实更加符合人的思维习惯。 1.4. 面向对象的应用范围 1.4.1. 能做什么 经常变化的地方就是面向对象应用的地方。 1.4.2. 不能做什么 图1-3所示的是软件质量属性的全图。 可以看到，“可扩展性”只是软件质量属性中很小的一部分，其他的属性都不是面向对象能够解决的。 明白了面向对象的特点和适用范围，是面向对象的关键。 经过前面的分析，我们知道，面向对象不是瑞士军刀，而只是一个普通的锤子而已，千万不要拿着锤子到处敲！ 1.5. 面向对象迷思 1.5.1. 面向对象会导致性能降低？ 如果纯粹考虑CPU，那么肯定是要有些影响的，编译器再怎么优化，也还是会有一些影响的。可执行文件也会变大。 但是，如果是在一个系统中，有网络，有IO，那么面向对象的CPU消耗可能就显得微不足道了。 看设计。 1.5.2. 面向对象语言=面向对象编程？ 其实，不管是“面向过程”还是“面向对象”，都是一种思维方式，一种思考问题的方式，而和具体的语言没有关系。 用C语言一样可以写出面向对象的程序，用Java也可以写出面向过程的程序。 1.6. 面向对象核心要素，特征 面向对象思想包括三个核心要素，特征，即封装（Encapsulation），继承（Inheritance）与多态（Polymorphism），它将面向对象技术推到了思想的境界。 一言以蔽之，对象的封装，继承，多态，保证了对象的高内聚与低耦合，有利于软件模块的可复用，保证了程序的可扩展，这正是面向对象思想体现在软件设计中的最大优势。 1.6.1. 封装 封装，就是合理的隐藏与公开。 一个物体需要只需要暴露外界需要的功能和属性。其他的操作封装到内部自己去处理，不需要告诉外界。这里就介绍了封装。 1.6.2. 继承 在面向对象思想中，继承往往不是被低估，而是被过分地滥用，尤其对于初学者，总是错误地估计继承的威力，从而导致子类的泛滥，或者营造出如森林一般的继承体系。这是很可怕的。 GOF认为，我们应该优先使用合成/聚合，而不是使用继承，这就是所谓的“合成/聚合复用原则”。 继承一般是为了复用代码，但是一般都用不好。使设计变得复杂。 一般推荐用组合。 继承，所有用继承的地方，好像目的都是要复用代码。 但是好像只要用了继承，就写不好代码的样子。根本不会用继承。 好像需要用继承的地方，其实只是想要用接口的。 想用继承的时候，要想一想是不是换成定义接口试试。 1.6.3. 多态 多态（Polymorphism），是指对象在不同时刻体现为不同类型的能力，它与对象的抽象与继承相关。 抽象的类型，可以因为实现的不同体现为不同的类型，从而执行不同的功能。 多态保证了程序的灵活性，因为它将对象形态的决定权交给了调用者。 定义接口。 多态，大概是关于公共接口相关的，一组对象拥有同一组相同的接口，然后可以在同一个地方调用这些对象的相同的接口。实际上会导致每个对象做自己对应的事情。这就是多态。 但是在python中，鸭子类型，看起来像，那就是。不需要显式的定义接口。 而在Go中，需要定义接口，但是不需要显式的继承接口。 1.7. 内聚与耦合 1.7.1. 内聚 内聚是什么 内聚指一个模块内部元素彼此结合的紧密程度。 你可以用“内聚”来判断一个函数设计是否合理，一个类设计是否合理，一个接口设计是否合理，一个包设计是否合理，一个模块/子系统设计是否合理。 “凝聚力”就是“内聚”的核心思想。 内聚的分类 内聚共有7种，以下各种形式内聚的内聚性越来越高。 偶然内聚（Coincidental cohesion） 逻辑内聚（Logical cohesion） 时间内聚（Temporal cohesion） 过程内聚（Procedural cohesion） 信息内聚（Informational/Communicational cohesion） 顺序内聚（Sequential cohesion） 功能内聚（Functional cohesion） 1.7.2. 耦合 耦合是什么 耦合（或者称依赖）是程序模块相互之间的依赖程度。 从定义来看，耦合和内聚是相反地：内聚关注模块内部的元素结合程度；耦合关注模块之间的依赖程度。 模块和内聚里面提到的模块一样，耦合中的模块其实也是可大可小的。常见的模块有：函数，类，包，子模块，子系统等 耦合的分类 无耦合（No coupling） 消息耦合（Message coupling） 数据耦合（Data coupling） 数据结构耦合（Data-structured coupling） 控制耦合（Control coupling） 外部耦合（External coupling） 全局耦合（Globaling coupling） 内容耦合（Content coupling） 1.7.3. 高内聚低耦合 为什么要高内聚低耦合？ 降低复杂性。 1.8. 面向对象设计原则 概括地讲，面向对象设计原则仍然是面向对象思想的体现。是核心要素的解释。 面向对象设计的原则是对面向对象思想的提炼，它比面向对象思想的核心要素更具可操作性，但与设计模式相比，却又更加的抽象，是设计精神要义的抽象概括。 形象的讲，面向对象思想就像是法理的精神，设计原则则相当于基本宪法，而设计模式就好比是各式各样的成文法了。 面向对象经过数十年的发展，不同的人在不同的时期都提出了言简意赅的设计原则，它们为我们的面向对象设计树立了正确的方向，提供了设计的依据和基本准则。 封装变化。找出应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。 针对接口编程，而不是针对实现编程。 多用组合，少用继承。 为了交互对象之间的松耦合设计而努力。 要依赖抽象，不要依赖具体类。 最少知识原则：只和你的密友谈话。 好莱坞原则：别调用（打电话给）我们，我们会调用（打电话给）你。 1.8.1. 面向对象设计原则 其中，开发人员广泛接受的设计原则包含五大原则，分别为单一职责原则，开放封闭原则，Liskov替换原则，依赖倒置原则，接口隔离原则。 五个。单一职责原则，开放封闭原则，Liskov替换原则。依赖倒置原则，接口隔离原则。 单一职责原则(SRP) 单一职责原则 就一个类而言，应该仅有一个引起它变化的原因。 就一个类而言，应该只专注于做一件事和仅有一个引起变化的原因。 职责 在SRP中，我们把职责定义为 '变化的原因'（a reason for change）。如果你能够想到多于一个的动机去改变一个类，那么这个类具有多于一个的职责。有时，我们很难注意到这一点。我们习惯于以组的形式去考虑职责。 变化的轴线仅当变化实际发生时才具有真正的意义。如果没有征兆，那么去应用SRP，或者任何其他原则都是不明智的。 假如程序中的一处改动就会发生连锁反应，导致一系列相关模块的改动，那么设计就具有僵化性的臭味。OOP建议我们应该对系统进行重构，这样以后对系统再进行那样的改动时，就不会导致更多的修改。如果正确地应用OCP，那么以后再进行同样的改动时，就只需要添加新的代码，而不必改动已经正确运行的代码。 也许，这看起来像是众所周知的可望而不可即的美好理想——然而，事实上却有一些相对简单并且有效的策略可以帮助接近这个理想。 描述 遵循开放-封闭原则设计出的模块具有两个主要的特征。它们是： 1 “对于扩展是开放的”（Open for extension）。 这意味着模块的行为是可以扩展的。当应用的需求改变时，我们可以对模块进行扩展，使其具有满足那些改变的新行为。换句话说，我们可以改变模块的功能。 2 “对于更改是封闭的”（Closed for modification） 对模块行为进行扩展时，不必改动模块的源代码或者二进制代码。模块的二进制可执行版本，无论是可链接的库，DLL或者Java的.jar文件，都无需改动。 这两个特征好像是互相矛盾的。扩展模块行为的通常方式就是修改该模块的源代码。不允许修改的模块常常都被认为是具有固定的行为。 怎么可能在不改动模块源代码的情况下去改变它的行为呢？怎样才能在无需对模块进行改动的情况下就改变它的功能呢？ 关键是抽象 预测变化和\"贴切的\"结构 一般而言，无论模块是多么的“封闭”，都会存在一些无法对之封闭的变化。没有对于所有的情况都贴切的模型。 既然不可能完全封闭，那么就必须有策略的对待这个问题。也就是说，设计人员必须对于他设计的模块应该对哪种变化封闭做出选择。他必须先猜测出最有可能发生的变化种类，然后构造抽象来隔离那些变化。 根据经验猜测那些应用程序在生长历程中有可能遭受的变化。如果开发人员猜测正确，他们就获得成功。如果他们猜测错误，他们会遭受失败。并且在大多数情况下，他们都会猜测错误。 同时，遵循OCP的代价也是昂贵的。创建正确的抽象是要花费开发时间和精力的。同时，那些抽象也增加了软件设计的复杂性。开发人员有能力处理的抽象的数量也是有限的。显然，我们希望把OCP的应用限定在可能会发生的变化上。 我们如何知道哪个变化有可能发生呢？我们进行适当的调查，提出正确的问题，并且使用我们的经验和一般常识。最终，我们会一直等到变化发生时才采取行动。 结论 在许多方面，OCP都是面向对象设计的核心所在。遵循这个原则可以带来面向对象技术所声称的巨大好处（也就是，灵活性，可重用性以及可维护性）。然而，并不是说只要使用一种面向对象语言就是遵循了这个原则。 对于应用程序的每个部分都肆意地进行抽象同样不是一个好主意。正确的做法是，开发人员应该不仅仅对程序中呈现出频繁变化的那些部分作出抽象。拒绝不成熟的抽象和抽象本身一样重要。 开放-封闭原则(OCP) 开闭原则 软件实体（类，模块，函数等等）应该是可扩展的，但是不可修改的。 Liskov替换原则(LSP) 里氏替换原则 对于LSP可以做如下解释： 子类型（subtype）必须能够替换掉它们的基类型（base type）。 Barbara Liskov首次写下这个原则是在1988年。她说道， 这里需要如下替换性质：若对每个类型S的对象o1，都存在一个类型T的对象o2, 使得在所有针对T编写的程序P中，用o1替换o2后，程序P行为功能不变，则S是T的子类型。 依赖倒置原则(DIP) 依赖反转原则 a. 高层模块不应该依赖于低层模块。二者都应该依赖于抽象。 b. 抽象不应该依赖于细节。细节应该依赖于抽象。 接口隔离原则(ISP) 接口隔离原则 不应该强迫客户依赖于它们不用的方法。 这个原则用来处理“胖（fat）”接口所具有的缺点。如果类的接口不是内聚的（cohesive），就表示该类具有“胖”的接口。 换句话说，类的“胖”接口可以分解成多组方法。每一组方法都服务于一组不同的客户程序。 这样，一些客户程序可以使用一组成员函数，而其他客户程序可以使用其他组的成员函数。 胖类（fat class）会导致它们的客户程序之间产生不正常的并且有害的耦合关系。 当一个客户程序要求该胖类进行一个改动时，会影响到所有其他的客户程序。因此，客户程序应该仅仅依赖于它们实际调用的方法。 通过把胖类的接口分解为多个特定于客户程序的接口，可以实现这个目标。 每个特定于客户程序的接口仅仅声明它的特定客户或者客户组调用的那些函数。 接着，该胖类就可以继承所有特定于客户程序的接口，并实现它们。 这就解除了客户程序和它们没有调用的方法间的依赖关系，并使客户程序之间互不依赖。 1.8.2. NOP 不要过度设计原则 "},"design/design-patterns/":{"url":"design/design-patterns/","title":"design patterns","keywords":"","body":"1. 设计模式 Title Date Modified Category design patterns 2019-07-16 12:00 2019-11-20 12:00 design patterns 1. 设计模式 design-patterns 创建型（creational） Abstract Factory 抽象工厂 Builder 生成器 Factory Method 工厂方法 Prototype 原型 Singleton 单件 结构型（structural） Adapter 适配器 Bridge 桥接 Composite 组成 Decorator 装饰 Facade 外观 Flyweight 享元 Proxy 代理 行为型（behavioral） Chain of Responsibility 职责链 Command 命令 Interpreter 解释器 Iterator 迭代器 Mediator 中介者 Memento 备忘录 Observer 观察者 State 状态 Strategy 策略 Template Method 模板方法 Visitor 访问者 "},"design/design-patterns/design-patterns.html":{"url":"design/design-patterns/design-patterns.html","title":"design-patterns","keywords":"","body":"1. design patterns1.1. 历史1.2. 定义1.3. 设计模式只是一把锤子1.4. 设计模式之道1.5. 面向对象vs设计模式1.6. 模式详解1.7. 设计模式的应用1.8. 设计模式要素1.9. 描述设计模式1.10. 设计模式编目1.11. 设计模式分类1.12. 设计模式将带来什么 Title Date Modified Category design patterns 2019-07-16 12:00 2019-11-20 12:00 design patterns 1. design patterns 设计模式，是对前人的已有的方案经验的总结，复用。 设计模式，通常依赖于面向对象设计相关的特性。 设计模式，重要是理解，灵活运用。不要生搬硬套，滥用，否则会造成过度设计。 1.1. 历史 最早出现在建筑领域中 在20世纪70年代，Christopher Alexander提出了城市建筑的模式，他认为：模式就是描述一个不断发生的问题和该问题的解决方案。 软件领域的设计模式是由 四人帮 在设计模式一书中提到的 随后，Erich Gamma，Richard Helm，Ralph Johnson和John Vlissides写了一本著名的参考书《设计模式：可复用面向对象软件的基础》。 后人也因为这本书称这4个人为4人组，将这本书中描述的模式称为GoF（Gang of Four）设计模式。 在这本书中，4人组将设计模式定义为：对被用来在特定场景下解决一般设计问题的类和互相通信的对象的描述。 1.2. 定义 通俗地说，可以把设计模式理解为对某一类问题的通用解决方案。 所谓“模式”是对问题和解决方案的基本内容的描述，所以该解决方案可以在不同的设置下复用。 模式不是一个详细描述。实际上，可以把它当做积累的智慧和经验的描述。它是对一般问题的一个经过多次提炼的解决方案。 模式对面向对象的软件设计有着巨大的影响。除了作为常见问题的经验检验的解决方案外，模式已经成为了谈论设计必用词汇。 因此，可以用对所用模式的描述来解释我们的设计。 模式描述了一个在我们周围不断重复发生的问题，以及该问题的解决方案的核心。 即：模式是重复发生的问题的解决方案。 1.3. 设计模式只是一把锤子 副标题：可复用面向对象软件的基础 设计模式解决的是“可复用”的设计问题 设计模式应用的领域是“面向对象”。 设计模式只能解决“可复用”的设计问题。 设计模式只是在面向对象语言中应用，如果是非面向对象的语言，就不怎么好用了。 所以，当你遇到一个问题就想到设计模式的时候，一定要注意“设计模式只是一把锤子”，不要拿着这把锤子到处去敲！ 设计模式并没有提出新的解决方案，设计模式只是将前人的经验进行了总结，提炼出模式化的东西。 作用在于，对软件设计有很好的指导作用。用一些现有的思路去解决恰好对应的问题。 但是，不要为了用而用，要找到真正符合的问题。 1.4. 设计模式之道 设计模式之道就隐藏在 “2.6.2封装实现依赖关系”的最后一段，很简单的一句话： 对变化的概念进行封装（encapsulate the concept that varies）。 首先，“找到变化”解决了“在哪里”使用设计模式的问题，即回答了“where”的问题。 其次，“封装变化”解决了“为什么”使用设计模式的问题，即回答了“why”的问题。 1.5. 面向对象vs设计模式 设计原则和设计模式是互补的，设计原则和设计模式互补体现在：设计原则主要用于指导“类的定义”的设计；而设计模式主要用于指导“类的行为”的设计。 设计模式通常和面向对象设计相关。现有的模式通常依赖于对象的特性，例如继承或多态，以提供通用性。 但是，模式中封装经验的一般原则对于任何的软件设计都适用。 模式是对其他设计师的知识和经验的一种复用。 软件设计最大的敌人，就是应付需求不断的变化。 如果从软件设计方法的角度出发，要在开发过程中应对未来可能的变化，解决之道则是——封装变化。 设计模式是“封装变化”思想的最佳阐释。 封装变化是开放封闭原则的具体体现。 1.6. 模式详解 “找到变化，封装变化”的设计模式之道， 加上GOF给出的“基于接口编程，而不是基于实现编程”和“优先使用对象组合而不是类继承”两个设计原则， 组成了《设计模式》一书中23个设计模式的指导思想，我称之为设计模式的“一个中心，两个基本点”紧紧抓住这个指导思想，理解23个设计模式就容易多了。 更进一步讲， GoF的23个设计模式，可以认为是“术”， 而我们提炼出来的设计模式思想，却是“道”， 如果你发现GoF的模式没有一个适合你，那么你完全可以自己想另外的方法来实现，而不必拘泥于已有的这23个设计模式。 1.7. 设计模式的应用 开始设计一个系统时，很难确定是否需要一个特定的模式。因此，在设计过程中使用模式通常包括：进行设计，体验问题，然后找到一个可用的模式。 我们当然有可能在原始模式书中所记载的23种通用模式中找到答案， 但有时候我们遇到的问题是一个不同的问题，那么你会发现，在已提出的数百个模式中寻找一个合适的解决方案不是件容易的事。 模式是一个绝妙的想法，但需要知道每个模式适用的情况，因此要在软件设计中不断积累经验才能学会有效地运用模式。 缺乏经验的程序员，即便是阅读过介绍模式的书籍，也会苦于确定是应该复用一个模式，还是应该开发一个专门的解决方案。 学习设计模式最重要的是理解，而不是生搬硬套。 要切记不能滥用设计模式，尤其在一些简单系统中。 如果系统中的对象都用工厂模式创建，系统中的工具类都设计成Singleton， 两个对象间的通信还要硬加上一层Mediator等都是不可取的， 只能毫无价值的提高系统复杂度，反而不利于系统的理解与维护。 除最初的设计外，重构也是一个很好的时机，系统架构设计师可以在重构的时候根据需要逐步应用设计模式改良系统，提高系统的维护性和复用性。 1.8. 设计模式要素 一般而言，一个模式有四个基本要素： 模式名称（pattern name） 问题（problem） 解决方案（solution） 效果（consequences） 1.9. 描述设计模式 我们将用统一的格式描述设计模式，每一个模式根据以下的模板被分成若干部分。模板具有统一的信息描述结构，有助于学习使用。 模式名和分类 意图 别名 动机 适用性 结构 参与者 协作 效果 实现 代码实例 已知应用 相关模式 1.10. 设计模式编目 23种经典设计模式 Abstract Factory： 提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 Adapter：将一个类的接口转换成客户希望的另外一个接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 Bridge：将抽象部分与它的实现部分分离，使它们都可以独立地变化。 Builder：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 Chain of Responsibilty：为解除请求的发送者和接收者之间耦合，而使多个对象都有机会处理这个请求。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它。 Command：将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可取消的操作。 Composite：将对象组合成树形结构以表示“部分-整体”的层次结构。Composite使得客户对单个对象和复合对象的使用具有一致性。 Decorator：动态地给一个对象添加一些额外的职责。就扩展功能而言，Decorator模式比生成子类方式更为灵活。 Facade：为子系统中的一组接口提供一个一致的界面，Facade模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 Factory Method：定义一个用于创建对象的接口，让子类决定将哪一个类实例化。Factory Method使一个类的实例化延迟到其子类。 Flyweight：运用共享技术有效地支持大量细粒度的对象。 Interpreter：给定一个语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子。 Iterator：提供一种方法顺序访问一个聚合对象中各个元素，而又不需暴露该对象内部表示。 Mediator：用一个中介对象来封装一系列的对象交互。中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 Memento：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到保存的状态。 Observer：定义对象间的一种一对多的依赖关系，以便当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并自动刷新。 Prototype：用原型实例指定创建对象的种类，并且通过拷贝这个原型来创建新的对象。 Proxy：为其他对象提供一个代理以控制对这个对象的访问。 Singleton：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 State：允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它所属的类。 Strategy：定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法的变化可独立于使用它的客户。 Template Method：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。Template Method使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 Visitor：表示一个作用于某对象结构中的各元素的操作。它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。 1.11. 设计模式分类 对设计模式的分类整理是重要的，它为我们使用的各种技术提供了标准的名称和定义。如果我们不研究软件中的设计模式，就无法对它们进行改进，更难以提出新的设计模式。 我们根据两条准则对模式进行分类。 第一是目的准则，即模式是用来完成什么工作的。 模式依据其目的可分为创建型（Creational），结构型（Structural），行为型（Behavioral）三种。 创建型模式与对象的创建有关。 结构型模式处理类或对象的组合。 行为型模式对类或对象怎样交互和怎样分配职责进行描述。 第二是范围准则，指定模式主要是用于类还是用于对象。 类模式处理类和子类之间的关系，这些关系通过继承建立，是静态的，在编译时刻便确定下来了。 对象模式处理对象间的关系，这些关系在运行时刻是可以变化的，更具动态性。 显然，存在着许多组织设计模式的方法。从多角度去思考模式有助于对它们的功能，差异和应用场合的更深入理解。 1.12. 设计模式将带来什么 为什么使用设计模式？ 一套通用的设计词汇 书写文档和学习的辅助手段 现有方法的一种补充 重构的目标 "},"design/design-patterns/creational/":{"url":"design/design-patterns/creational/","title":"创建型（creational）","keywords":"","body":"1. 创建型 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 创建型 Abstract Factory 抽象工厂 Builder 生成器 Factory Method 工厂方法 Prototype 原型 Singleton 单件 "},"design/design-patterns/creational/abstract_factory.html":{"url":"design/design-patterns/creational/abstract_factory.html","title":"Abstract Factory 抽象工厂","keywords":"","body":"1. 抽象工厂 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 抽象工厂 "},"design/design-patterns/creational/builder.html":{"url":"design/design-patterns/creational/builder.html","title":"Builder 生成器","keywords":"","body":"1. 生成器 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 生成器 "},"design/design-patterns/creational/factory_method.html":{"url":"design/design-patterns/creational/factory_method.html","title":"Factory Method 工厂方法","keywords":"","body":"1. 工厂方法 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 工厂方法 "},"design/design-patterns/creational/prototype.html":{"url":"design/design-patterns/creational/prototype.html","title":"Prototype 原型","keywords":"","body":"1. 原型 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 原型 "},"design/design-patterns/creational/singleton.html":{"url":"design/design-patterns/creational/singleton.html","title":"Singleton 单件","keywords":"","body":"1. 单件 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 单件 "},"design/design-patterns/structural/":{"url":"design/design-patterns/structural/","title":"结构型（structural）","keywords":"","body":"1. 结构型 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 结构型 Adapter 适配器 Bridge 桥接 Composite 组成 Decorator 装饰 Facade 外观 Flyweight 享元 Proxy 代理 "},"design/design-patterns/structural/adapter.html":{"url":"design/design-patterns/structural/adapter.html","title":"Adapter 适配器","keywords":"","body":"1. 适配器 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 适配器 "},"design/design-patterns/structural/bridge.html":{"url":"design/design-patterns/structural/bridge.html","title":"Bridge 桥接","keywords":"","body":"1. 桥接 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 桥接 "},"design/design-patterns/structural/composite.html":{"url":"design/design-patterns/structural/composite.html","title":"Composite 组成","keywords":"","body":"1. 组成 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 组成 "},"design/design-patterns/structural/decorator.html":{"url":"design/design-patterns/structural/decorator.html","title":"Decorator 装饰","keywords":"","body":"1. 装饰 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 装饰 "},"design/design-patterns/structural/facade.html":{"url":"design/design-patterns/structural/facade.html","title":"Facade 外观","keywords":"","body":"1. 外观 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 外观 "},"design/design-patterns/structural/flyweight.html":{"url":"design/design-patterns/structural/flyweight.html","title":"Flyweight 享元","keywords":"","body":"1. 享元 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 享元 "},"design/design-patterns/structural/proxy.html":{"url":"design/design-patterns/structural/proxy.html","title":"Proxy 代理","keywords":"","body":"1. 代理 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 代理 "},"design/design-patterns/behavioral/":{"url":"design/design-patterns/behavioral/","title":"行为型（behavioral）","keywords":"","body":"1. 行为型 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 行为型 Chain of Responsibility 职责链 Command 命令 Interpreter 解释器 Iterator 迭代器 Mediator 中介者 Memento 备忘录 Observer 观察者 State 状态 Strategy 策略 Template Method 模板方法 Visitor 访问者 "},"design/design-patterns/behavioral/chain_of_responsibility.html":{"url":"design/design-patterns/behavioral/chain_of_responsibility.html","title":"Chain of Responsibility 职责链","keywords":"","body":"1. 职责链 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 职责链 "},"design/design-patterns/behavioral/command.html":{"url":"design/design-patterns/behavioral/command.html","title":"Command 命令","keywords":"","body":"1. 命令 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 命令 "},"design/design-patterns/behavioral/interpreter.html":{"url":"design/design-patterns/behavioral/interpreter.html","title":"Interpreter 解释器","keywords":"","body":"1. 解释器 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 解释器 "},"design/design-patterns/behavioral/iterator.html":{"url":"design/design-patterns/behavioral/iterator.html","title":"Iterator 迭代器","keywords":"","body":"1. 迭代器 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 迭代器 "},"design/design-patterns/behavioral/mediator.html":{"url":"design/design-patterns/behavioral/mediator.html","title":"Mediator 中介者","keywords":"","body":"1. 中介者 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 中介者 "},"design/design-patterns/behavioral/memento.html":{"url":"design/design-patterns/behavioral/memento.html","title":"Memento 备忘录","keywords":"","body":"1. 备忘录 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 备忘录 "},"design/design-patterns/behavioral/observer.html":{"url":"design/design-patterns/behavioral/observer.html","title":"Observer 观察者","keywords":"","body":"1. 观察者 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 观察者 "},"design/design-patterns/behavioral/state.html":{"url":"design/design-patterns/behavioral/state.html","title":"State 状态","keywords":"","body":"1. 状态 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 状态 "},"design/design-patterns/behavioral/strategy.html":{"url":"design/design-patterns/behavioral/strategy.html","title":"Strategy 策略","keywords":"","body":"1. 策略 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 策略 "},"design/design-patterns/behavioral/template_method.html":{"url":"design/design-patterns/behavioral/template_method.html","title":"Template Method 模板方法","keywords":"","body":"1. 模板方法 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 模板方法 "},"design/design-patterns/behavioral/visitor.html":{"url":"design/design-patterns/behavioral/visitor.html","title":"Visitor 访问者","keywords":"","body":"1. 访问者 Title Date Modified Category design patterns 2019-11-20 12:00 2019-11-20 12:00 design patterns 1. 访问者 "},"design/关于设计模式的探讨.html":{"url":"design/关于设计模式的探讨.html","title":"关于设计模式的探讨(演讲稿)","keywords":"","body":"1. 关于设计模式的探讨（演讲稿）1.1. 关于架构演进的探讨1.1.1. 演示1.1.2. 说了什么1.2. 疑问1.3. 为什么自己会想到上面问题？1.3.1. 我之前对于设计模式的了解1.3.2. 已经很久没有思考过编程思想了1.4. 思想的辩证1.5. 从书中寻找答案1.6. 从书中了解到的东西1.6.1. 一些名词1.6.2. 正文1.7. Q&A Title Date Modified Category design 2019-11-23 12:00 2019-11-25 12:00 design 1. 关于设计模式的探讨（演讲稿） 1.1. 关于架构演进的探讨 1.1.1. 演示 https://github.com/mingz2013/demo-project-layout 1.1.2. 说了什么 代码结构不可能不变，重构是必然的。 很多同学写的代码很长，原因是不会拆分，或者没有拆分的意识。函数长，模块长，都是一个道理。 架构要进可攻退可守。进，通过微小的更改，即可适应架构的演进。退，保持现有功能的满足。以此保证设计的恰到好处。 设计，要同时保证优雅，效率，性能。 没有经过推演的代码，就是没有思考过的代码。 吃过见过。知道最终的模样，才知道开始怎么做。 拆字决，架构设计的屠龙宝刀。 关注数据流 数据源，配置数据源，数据库跟踪数据流，数据从接口流入，逻辑从不同数据源读取信息，经过计算。改变数据库的数据，最终返回数据。就这么简单。 1.2. 疑问 为什么使用设计模式？ 设计模式是必须的吗？ 我之前也没记住几个设计模式，但是也没有影响写出好的代码，我依据的是什么？ 不依赖于面向对象的设计模式怎么用？ 什么是设计模式？ 为什么需要设计模式？ 设计模式带来什么？ 如何使用设计模式？ 从上一个问题想到，为什么需要面向对象？ 什么是面向对象？ 面向对象是必须的吗？ 面向对象带来什么？ 如何使用面向对象？ 1.3. 为什么自己会想到上面问题？ 1.3.1. 我之前对于设计模式的了解 从旁边的同事整天抱着《head first设计模式》开始。 学java的时候，从教学视频里面学过设计模式。 自己读过《head first设计模式》，用java写过设计模式，画过设计模式的类图。 时间久了，后来没记住几个。 1.3.2. 已经很久没有思考过编程思想了 我已经很久没有去认真思考，或者看过关于编程思想的一些书了 还有，我本身对于C++，Java是比较排斥的，我喜欢的语言有python，Go，C。其实最近对于Python的动态性也有很多的讨厌了。python在写大型项目的时候不好把控。 一看到各种接口，各种实现等，就会感觉到复杂。尤其是在python中出现。可能，问题本身比较复杂，实现可能是没问题的。 有些人写各种语言的风格都是一样，从来不考虑各种语言的差别。 人本身是不善于处理复杂的事物的。 1.4. 思想的辩证 首先，设计模式，面向对象等都是要解决关于怎么设计的问题。 设计的一种思想。 思想上的东西，一定都是要辩证的。 当自己无法想清楚这件事的时候，就要读一些经典的书，不同类别的书，甚至于不同思想的书，如经典的软件设计流程，和敏捷开发，极限编程等。 辩证的东西，都是有两方面的，没有分歧的思想，不经过辩证的思想是不成熟的。 经过辩证的思想，才能为我所用。 1.5. 从书中寻找答案 《人月神话》 《软件工程》第9版 《系统架构师》第2版 《软件框架设计的艺术》 《软件工程：面向对象和传统的方法（原书第8版）》 《软件建模与设计：UML、用例、模式和软件体系结构》 《面向对象葵花宝典：思想、技巧与实践》 《Java编程思想(第4版)》 《敏捷软件开发 原则，模式与实战》 《代码整洁之道》 《设计模式：可复用面向对象软件的基础》 《软件设计精要与模式》第2版 《大话设计模式》 《head first设计模式》 《Python编程实战 运用设计模式、并发和程序库创建高质量程序》 《精通Python设计模式》 《JavaScript设计模式》 《C现代编程》 1.6. 从书中了解到的东西 我自己平时是怎么写代码的一些思考 看了一堆书，最后看到自己怀疑人生，我到底会不会用面向对象？？ 1.6.1. 一些名词 面相过程， 面向对象， 函数式编程。 计划的设计， 演进的设计。 封装， 继承， 多态。 五大原则 GoF 23个设计模式。 敏捷开发， 极限编程。 测试驱动开发。 结对编程。 重构。 接口， 抽象， 组合， 1.6.2. 正文 我们讨论的是什么？终究讨论的还是程序设计 http://mingz.me/note/design/ 1.7. Q&A 个人见解，欢迎讨论。 "},"unix-like/":{"url":"unix-like/","title":"Unix-like","keywords":"","body":" Title Date Modified Category linux 2019-06-06 12:00 2019-05-29 12:00 linux "},"network/":{"url":"network/","title":"network","keywords":"","body":" Title Date Modified Category network 2019-06-11 12:00 2019-06-11 12:00 network ip tcp http dns network "},"network/network.html":{"url":"network/network.html","title":"network","keywords":"","body":"1. 网络编程泛讲2. TCP/IP协议3. 网络编程基础API3.1. socket3.2. 字节序4. 高级API5. 服务器模型6. I/O模型7. 事件处理模式7.1. reactor7.2. proactor8. 并发模式9. IO复用10. 参考资料10.1. 参考书籍 Title Date Modified Category network 2019-05-29 12:00 2019-05-29 12:00 network 禁止转载 一些图文 出自参考书籍中的截图，如有侵权，请联系删除 1. 网络编程泛讲 2. TCP/IP协议 3. 网络编程基础API 3.1. socket 3.2. 字节序 4. 高级API 5. 服务器模型 6. I/O模型 7. 事件处理模式 7.1. reactor 7.2. proactor 8. 并发模式 9. IO复用 select，poll，epoll 10. 参考资料 10.1. 参考书籍 《Linux高性能服务器编程》 《后台开发 核心技术与应用实践》 《Linux多线程服务端编程：使用muduo C++网络库》 "},"network/ip.html":{"url":"network/ip.html","title":"IP","keywords":"","body":" Title Date Modified Category IP 2019-06-11 12:00 2019-06-11 12:00 network "},"network/tcp.html":{"url":"network/tcp.html","title":"TCP","keywords":"","body":" Title Date Modified Category TCP 2019-06-11 12:00 2019-06-11 12:00 network "},"network/http.html":{"url":"network/http.html","title":"HTTP","keywords":"","body":" Title Date Modified Category http 2019-06-11 12:00 2019-06-11 12:00 network "},"network/dns.html":{"url":"network/dns.html","title":"dns","keywords":"","body":" Title Date Modified Category dns 2019-06-12 12:00 2019-06-12 12:00 network "},"db/":{"url":"db/","title":"db","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db redis mongo 介绍 安装 mongo shell CRUD 聚合 数据模型 事务 索引 安全 Change Streams 复制 分片 管理 存储 hbase memcache "},"db/redis.html":{"url":"db/redis.html","title":"redis","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db "},"db/mongodb/":{"url":"db/mongodb/","title":"mongodb","keywords":"","body":"1. mongodb1.1. 参考资料1.1.1. books1.1.2. links Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 1. mongodb 主要参考线上文档，4.2版本文档。 https://docs.mongodb.com/manual/ 介绍 安装 mongo shell CRUD 聚合 数据模型 事务 索引 安全 Change Streams 复制 分片 管理 存储 源码分析 1.1. 参考资料 1.1.1. books 《大数据存储MongoDB实战指南》 《MongoDB实战 架构、开发与管理》 《MongoDB大数据处理权威指南》 《MONGODB实战》 《MongoDB权威指南》 《MongoDB管理与开发精要》 1.1.2. links http://www.mongoing.com/docs/index.html https://docs.mongodb.com/manual/ "},"db/mongodb/introduction.html":{"url":"db/mongodb/introduction.html","title":"介绍","keywords":"","body":" Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 大数据 NoSQL mongodb bson 数据类型 基本数据类型 null 布尔 32位整数 64位整数 64位浮点数 字符串 日期 正则表达式 代码 二进制数据 最大值 最小值 未定义 undefined 数组 内嵌文档 日期 数组 内嵌文档 _id 和 ObjectId "},"db/mongodb/installation.html":{"url":"db/mongodb/installation.html","title":"安装","keywords":"","body":" Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db "},"db/mongodb/the-mongo-shell.html":{"url":"db/mongodb/the-mongo-shell.html","title":"mongo shell","keywords":"","body":" Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db "},"db/mongodb/crud.html":{"url":"db/mongodb/crud.html","title":"CRUD","keywords":"","body":" Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db insert update remove upsert 查询 游标 "},"db/mongodb/aggregation.html":{"url":"db/mongodb/aggregation.html","title":"聚合","keywords":"","body":"1. 聚合 Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 1. 聚合 管道模式 MapReduce 简单聚集函数 "},"db/mongodb/data-models.html":{"url":"db/mongodb/data-models.html","title":"数据模型","keywords":"","body":" Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db "},"db/mongodb/transactions.html":{"url":"db/mongodb/transactions.html","title":"事务","keywords":"","body":"1. Transactions(事务) Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 1. Transactions(事务) "},"db/mongodb/indexes.html":{"url":"db/mongodb/indexes.html","title":"索引","keywords":"","body":"1. Indexes（索引） Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 1. Indexes（索引） 性能优化, explain() "},"db/mongodb/security.html":{"url":"db/mongodb/security.html","title":"安全","keywords":"","body":" Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db "},"db/mongodb/change-streams.html":{"url":"db/mongodb/change-streams.html","title":"Change Streams","keywords":"","body":" Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db "},"db/mongodb/replication.html":{"url":"db/mongodb/replication.html","title":"复制","keywords":"","body":"1. replication1.1. 冗余和高可用1.2. 复制集在MongoDB上的1.3. Asynchronous Replication1.4. Automatic Failover¶1.5. Read Operations1.6. Transactions1.7. Change Streams1.8. Additional Features¶ Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 1. replication 复制集 一个复制集，是一组mongod进程，维持了同样的数据集合。复制集提供了冗余和高可用,是所有功能的基础。 1.1. 冗余和高可用 复制集提供了冗余和增加了数据的可用性。 用多个数据备份再不同的数据库服务器上， 复制集比单个服务器 提高了一个容错级别。 复制集，提供了更大的读取容量，因为客户端可以将读取操作发送到不同的服务器。 在不同的数据中心维护数据副本，可以提高分布式应用程序的数据位置和可用性。 您还可以为专用的目的（如灾难恢复，报告或备份）维护其他副本。 1.2. 复制集在MongoDB上的 复制集，是一组维护相同数据集的mongod实例。 副本集包含多个数据承载节点（data bearing nodes）和一个仲裁节点（arbiter node）（可选）. 在数据承载节点中，一个且只有一个成员被用作主节点（primary node），其他节点用作辅助节点（secondary node）。 主节点负责接收所有的读写操作。 辅助节点，复制主节点的oplog，并应用到自身的数据集。 如果主节点不可用，一个合格的辅助节点将举行选举，自行选出新的主节点。 你也可以将一个mongod实例作为仲裁节点（arbiter node）添加到副本集。仲裁节点不维护数据集。 仲裁节点的功能是通过响应其他副本集成员的心跳和选择请求来维护副本集中的仲裁。 因为它们不存储数据集，所以仲裁节点是提供副本集仲裁功能的一种好方法，与具有数据集的完全功能副本集成员相比，仲裁节点的资源成本更低。 如果副本集的成员数为偶数，则添加一个仲裁节点以在初选中获得多数票。 仲裁节点不需要专用的硬件。 一个仲裁节点永远是一个仲裁节点，一个主节点可能会停止，变成一个辅助节点，一个辅助接点也可能选举变成一个主节点。 1.3. Asynchronous Replication 1.4. Automatic Failover¶ 1.5. Read Operations 1.6. Transactions 1.7. Change Streams 1.8. Additional Features¶ "},"db/mongodb/sharding.html":{"url":"db/mongodb/sharding.html","title":"分片","keywords":"","body":"1. Sharding1.1. Sharded Cluster1.1.1. Production Configuration1.1.2. Development Configuration1.2. Shards1.2.1. Primary Shard（主片）1.2.2. Shard Status1.2.3. Sharded Cluster Security1.3. Config Servers1.3.1. Replica Set Config Servers1.3.2. Read and Write Operations on Config Servers1.3.3. Config Server Availability1.3.4. Sharded Cluster Metadata1.3.5. Sharded Cluster Security1.4. mongos1.4.1. Routing And Results Process1.4.2. How mongos Handles Query Modifiers1.4.3. Confirm Connection to mongos Instances1.4.4. Targeted Operations vs. Broadcast Operations1.5. Shard Keys1.5.1. Shard Key Specification1.5.2. Change a Document’s Shard Key Value1.5.3. Shard Key Indexes1.5.4. Choosing a Shard Key1.6. Chunks1.7. Balancer and Even Chunk Distribution1.8. Advantages of Sharding (分片的优势)1.8.1. Reads/Writes1.8.2. Storage Capacity(存储容纳)1.8.3. High Availability（高可用）1.9. Considerations Before Sharding（分片前的注意事项）1.10. Sharded and Non-Sharded Collections(分片和未分片的集合)1.11. Connecting to a Sharded Cluster1.12. Sharding Strategy(分片策略)1.12.1. Hashed Sharding(哈希分片)1.12.2. Ranged Sharding （范围分片）1.13. Zones in Sharded Clusters1.13.1. Behavior and Operations1.13.2. Manage Shard Zones1.13.3. Segmenting Data by Location1.13.4. Tiered Hardware for Varying SLA or SLO1.13.5. Segmenting Data by Application or Customer1.13.6. Distributed Local Writes for Insert Only Workloads1.14. Data Partitioning with Chunks （数据通过块迁移）1.14.1. Initial Chunks1.14.2. Chunk Size1.14.3. Chunk Splits1.14.4. Merge Chunks in a Shared Cluster1.14.5. Chunk Migration1.14.6. Indivisible Chunks (不可分割的块)1.14.7. moveChunk directory1.15. Balancer(平衡器)1.15.1. Balancing1.15.2. Cluster Balancer1.15.3. Chunk Migration Procedure(块迁移过程)1.15.4. Shard Size1.16. Collations in Sharding1.17. Change Streams1.18. Transactions Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 参考 4.2版本文档 1. Sharding 分片，是一种跨多台机器分布数据的方法，mongodb使用分片来支持具有非常大的数据集和高吞吐量操作的部署。 具有大数据集或高吞吐量应用程序的数据库系统可能会挑战单个服务器的容量。例如，高查询率会耗尽服务器的CPU容量。大于系统RAM的工作集大小会对磁盘驱动器的I/O容量造成压力。 解决系统增长的方法有两种：垂直和水平缩放。 垂直扩展，包括增加单个服务器的容量，例如使用更强大的CPU，更多的RAM，更多的存储空间。垂直缩放有一个实际的最大值。 横向扩展，包括将系统数据集和负载划分到多台服务器上，根据需要添加额外的服务器以增加容量。虽然一台机器的整体速度或容量可能不高，但每台机器都处理整体工作负载的一个子集，可能比单个高速高容量服务器提供更好的效率。 扩展部署的容量只需要根据需要添加额外的服务器，这可能比单台机器的高端硬件的总体成本更低。权衡是增加了部署的基础设施和维护的复杂性。 MongoDB通过分片进行水平缩放。 1.1. Sharded Cluster 一个分片集群包含下面几个组件： shard: 每一个分片包含了分片数据的一个子集，每一个分片可以被部署为一个副本集。 mongos：mongos职责是作为一个请求的路由，提供一个接口，处于客户端程序和分片集群中间。 config servers: 配置服务器存储元数据和集群的配置信息。配置服务器必须部署为一个副本集。 分片数据是在collection 的级别，分布集合的数据到分片集群上。 1.1.1. Production Configuration 在生产环境中，确保数据是冗余的，并且您的系统是高度可用的。请参考下面内容部署生产环境的分片集群： 部署Config Servers 为3个节点的副本集 部署每个分片为3个节点的副本集 部署一个或多个mongos 路由 Replica Set Distribution 如果有可能，考虑部署每个副本集的一个副本到作为灾难恢复位置的站点中。 Number of Shards 分片需要至少两个分片来分发数据。 如果你计划在不就的将来启用分片，那么单分片集群可能很有用，但在部署时不需要这样做。 Number of mongos and Distribution 部署多个mongos路由器支持高可用和可扩展性。一种常见的模式是在每个应用服务器上放置一个mongos。在每个应用服务器上部署一个mongos路由器可以减少应用程序和路由器之间的网路延迟。 或者，您可以在专用主机上放置mongos，大型部署受益于这种方法，因为它将客户端应用程序服务器的数量和mongos实例的数量分离开来。可以更好地控制mongod实例所服务的连接数。 在自己的主机上安装mongos实例允许这些实例使用更多的内存。内存不会与mongod实例共享。可以使用主片来承载mongos路由器，但要注意，内存争用可能成为大型部署中的一个问题。 部署中可以拥有的mongos数量没有限制。但是，由于mongos路由器经常与您的配置服务器通信，因此随着路由器数量的增加，请密切监视配置服务器的性能。如果您看到性能下降，那么在您的部署中限制mongos路由器的数量可能是有益的。 1.1.2. Development Configuration 为了测试和开发，你可以部署一个分片集群用一个最小数量的组件。这些非生产环境集群由如下组件。 一个有一个成员的config server的复制集 至少一个分片，并搭建一个节点的复制集 一个mongos实例 1.2. Shards 一个分片包含了分片集群的分片数据的一个子集，整个集群的分片一起保持了集群的整个数据集。 mongodb3.6, 分片必须被部署为复制集去提供冗余和高可用。 用户，客户端，或应用程序只能连接到一个分片来执行本地管理和维护操作。 对单个片的执行查询只会返回数据的子集。连接到mongos以执行集群级别的操作，包括读或写操作。 1.2.1. Primary Shard（主片） 在分片集群中，每个数据库都有一个主片，它保存了所有未分片的集合。每个数据库都有自己的主片。主片与复制集中的主节点没有关系。 在创建新数据库时，mongos通过在数据量最少的集群中选择片来作为主片。 mongos使用listDatabase命令返回的totalsize字段作为选择条件的一部分。 要更改数据库的主片，请使用moveprimary命令。迁移主片的过程可能需要很长时间才能完成，在完成之前，你不应该访问与数据库关联的集合。根据迁移的数据量，迁移可能会影响整个集群操作。在尝试更改主片之前，请考虑对集群操作和网络负载的影响。 当你使用以前作为复制集的片部署新的分片集群时，所有现有的数据库将继续驻留在其原始的复制集上。随后创建的数据库可以驻留在集群中的任何碎片上。 1.2.2. Shard Status sh.status()方法可以查看集群状态。这些报告包括哪些碎片是数据库的主要碎片以及碎片之间的块分布。 1.2.3. Sharded Cluster Security 使用内部/成员身份验证来加强集群内的安全性，并防止未经授权的集群组件访问集群。必须使用适当的安全设置启动集群中的每个mongod，以便强制进行内部身份验证。 1.3. Config Servers 配置服务器存储分片集群的元数据。元数据反应了分片集群中所有数据和组件的状态和组织。元数据包括每个碎片上的块列表以及定义块的范围。 mongos实例缓存这些数据，并使用它将读写操作路由到正确的片。当集群的元数据发生变化时，mongos会更新缓存，例如块分割或添加片。片还从配置服务器读取块元数据。 配置服务器还存储身份验证配置信息，如基于角色的访问控制或集群的内部身份验证设置。 mongodb还是用配置服务器来管理分布式锁。 每个分片集群必须有自己的配置服务器。不要对不同的分片集群使用相同的配置服务器。 1.3.1. Replica Set Config Servers 从mongodb3.2开始，可以将分片集群的配置服务器部署为复制集（CSR），而不是三个镜像配置服务器（SCCC）。为配置服务器使用复制集可以提高配置服务器之间的一致性，因为mongodb可以利用配置数据的标准副本集读写协议。此外，为配置服务器使用副本集允许分片集群拥有3个及以上的配置服务器，因为复制集最多可以有50个成员。要将配置服务器部署为复制集，配置服务器必须运行wiredtiger存储引擎。 在3.4版本中，mongodb取消了对SCCC配置服务器的支持。 当用于配置服务器时，以下限制适用于复制集配置： 必须没有仲裁人。 必须没有延迟成员。 必须生成索引（即，任何成员都不应将BuildIndexes设置为false）。 1.3.2. Read and Write Operations on Config Servers Writes to Config Servers Reads from Config Servers 1.3.3. Config Server Availability 如果配置服务器副本集丢失其主节点，并且无法选择主节点，则集群的元数据将变为只读。您仍然可以从碎片中读取和写入数据，但是在副本集可以选择主数据之前，不会发生块迁移或块分割。 在分片集群中，mongod和mongos实例监视分片集群中的副本集（例如shard replica set，config server replica set）。 如果所有配置服务器都不可用，那么集群可能会变得不可操作。为了确保配置服务器保持可用和完整，配置服务器的备份至关重要。与集群中存储的数据相比，配置服务器上的数据较小，并且配置服务器的活动负载相对较低。 对于3.2分片集群，如果连续不成功的尝试监视配置服务器副本集的次数超过replmonitormaxfailedcheck参数值，则在重新启动该实例前，监视mongos或mongod实例将不可用。 1.3.4. Sharded Cluster Metadata use config连接config 数据库。 含有以下表： changelog chunks collections databases lockpings locks mongos settings shards version 1.3.5. Sharded Cluster Security 1.4. mongos mongos实例将查询和写操作路由到一个分片集群中的分片。从应用程序的角度来看，mongos提供了到分片集群的唯一接口。应用程序不应该与片直接通信。 mongos通过缓存配置服务器中的元数据来跟踪哪些数据是在哪些分片上的。mongos使用元数据将操作从应用程序和客户端路由到mongod实例。mongos没有持久状态，并且消耗最少的系统资源。 最常见的做法是在与应用服务器相同的系统上运行mongos实例，但是可以在分片上或其他专用资源上维护mongos实例。 1.4.1. Routing And Results Process mongos实例通过以下方式将查询路由到集群： 确定必须接收查询的片列表。 在所有目标片上建立游标。 然后，mongos合并来自每个目标片的数据，并返回结果文档。某些查询修饰符（如排序）在mongos检索结果之前对片执行。 在3.6版本中进行了更改：对于在多个碎片上运行的聚合操作，如果操作不需要在数据库的主碎片上运行，则这些操作可以将结果路由回mongos，然后在那里合并结果。 有两种情况下，管道不能在mongos上执行。 第一种情况发生在拆分管道的合并部分包含必须在主片上运行的阶段时。 第二种情况发生在拆分管道的合并部分包含一个可以将临时数据写入磁盘的阶段，并且客户端已指定allowdiskuse:true时。在这种情况下，假设合并管道中没有需要主片的其他阶段，合并将在聚集目标的片中随机选择的片上运行。 有关聚合工作如何在分片集群查询的组件之间拆分的详细信息，请使用explain:true作为aggregation()调用的参数。 在某些情况下，当片键或片键的前缀是查询的一部分时，mongos执行目标操作，将查询路由到集群中的分片子集。 1.4.2. How mongos Handles Query Modifiers 1.4.3. Confirm Connection to mongos Instances 1.4.4. Targeted Operations vs. Broadcast Operations 1.5. Shard Keys mongodb使用片键在不同的分片之间分发集合的文档。 片键由目标集合中每个文档存在的一个或多个字段组成。 在对一个集合进行分片时选择片键。一旦选择，不能更改。一个分片集合只能有一个片键。 选择分片会影响分片集群的性能，效率和可伸缩性。片键可能会阻碍具有最佳硬件和基础结构的集群。片键的选择及其支持索引也会影响集群使用分片的策略。 片键决定集合文档在集群的片中的分布。片键是一个索引字段或索引复合字段，存在于集合中的每个文档中。 mongodb使用片键值的范围对集合中的数据进行分区。每个范围定义了一个不重叠的片键值范围，并与一个块相关联。 mongodb尝试在集群中的片中均匀地分布块。片键与分块匹配的有效性有直接关系。 1.5.1. Shard Key Specification 1.5.2. Change a Document’s Shard Key Value 1.5.3. Shard Key Indexes 要对非空集合进行分片，集合必须具有以片键开始的索引。 对一个空的集合进行分片，如果集合没有针对指定的片键的适当索引，mongodb将创建索引。 Unique Indexes 不能在哈希索引上指定唯一约束。 对于基于范围分片的集合，只有以下索引可以是唯一的： 片键上的索引 一种复合索引，其中片键是前缀 默认的索引_id, 但是，如果_id字段不是片键或片键的前缀，那么_id索引只强制每个片的唯一性约束。 唯一的索引约束意味着： 对于待分片的集合，如何集合具有其他唯一索引，则不能分片该集合。 对于已分片的集合，不能在其他字段上创建唯一索引。 通过对片键使用唯一索引，mongodb可以强制片键值的唯一性。 mongodb对整个键的组合强制唯一性，而不是对片键的单个组件强制唯一性。 要对片键值强制唯一性，请将unique参数作为true传递给sh.shardcollection()方法。 如果集合为空，则sh.shardCollection在片键上创建唯一索引（如果该索引尚不存在）。 如果集合不为空，则必须先创建索引，然后才能使用sh.shardCollection()方法。 虽然可以有一个唯一的复合索引，其中片键是前缀，但如果使用unique参数，则集合必须具有片键上的唯一索引。 1.5.4. Choosing a Shard Key 片键的选择会影响块在可用片之间的创建和分布。这会影响分片集群中操作的整体效率和性能。 片键影响分片集群所使用的切分策略的性能和效率。 理想的片键允许mongodb在集群中均匀地分发文档。 至少，考虑潜在片键的基数，频率，和变化率的后果。 Restrictions(限制) Collection Size Shard Key Cardinality (基数) 片键的基数决定了均衡器可以创建的最大块数。这可以降低或消除集群中水平缩放的有效性。 在任何给定时间，一个唯一的片键值只能存在于一个块上。如果一个片键的基数为4，那么在分片集群中不能有超过4个块，每个块存储一个唯一的片键值。这将集群中有效片的数量限制为4个, 添加额外的片不会带来任何好处。 下图说明了使用字段x作为片键的分片集群。如果x的基数较低，插入的分布可能与以下类似： 本例中的集群不会水平扩展，因为传入写入只会路由到碎片的一个子集。 具有高基数的片键不能保证数据在整个分片集群中均匀分布，尽管它更好的促进了水平缩放。片键的频率和变化率也有助于数据分布。选择片键时考虑每个因素。 如果数据模型需要对基数较低的键进行分片，请考虑使用具有较高相对基数的字段的复合索引。 Shard Key Frequency(频率) 考虑一个表示片键值范围的集合，片键值的频率表示给定值在数据中出现的频率。如果大多数文档只包含这些值的一个子集，那么存储这些文档的块将成为集群中的瓶颈。 此外，随着这些块的增长，它们可能会成为不可分割的块，因为它们不能再进一步分割。这会降低或消除集群中水平缩放的有效性。 下图说明了使用字段x作为片键的分片集群。如果X值的一个子集出现在高频下，插入的分布可能类似于以下情况： 低频片键不能保证数据在分片集群中均匀分布。片键的基数和变化率也有助于数据分布。选择片键时考虑每个因素。 如果您的数据模型需要对具有高频值的键进行切分，请考虑使用唯一或低频值的复合索引。 Monotonically Changing Shard Keys(单调变化的片键) 值上单调增加或减少的片键更有可能将插入分布到集群的单个片上。 这是因为每个集群都有一个块来捕获一个上限为maxkey的范围。 MAXKEY的比较值始终高于所有其他值。类似的，有一个块捕获的范围的下限为minkey，minkey的比较值总是低于所有其他值。 如果片键值始终在增加，则所有新插入都将以maxkey作为上限路由到块。如果片键值总是减少，那么所有新插入都将以minkey作为下界路由到块。包含该块的片成为写操作的瓶颈。 下图说明了使用字段想作为片键的分片集群。如果x的值是单调递增的，则插入的分布可能类似于以下内容： 如果片键值单调减少，那么所有插入都将路由到块a。 不单调变化的片键不能保证数据在分片集群中均匀分布。片键的基数和频率也有助于数据分布。选择片键时考虑每个因素。 如果您的数据模型需要对单调变化的键进行切分，请考虑使用哈希切分。 1.6. Chunks mongodb将分片数据分割成块。每一个块都有一个基于片键的包含的范围。 1.7. Balancer and Even Chunk Distribution 为了在集群的所有分片上实现块的均匀分布，在后台运行一个均衡器来跨分片迁移块。 1.8. Advantages of Sharding (分片的优势) 1.8.1. Reads/Writes 读写会被分摊在多个分片上。 1.8.2. Storage Capacity(存储容纳) 1.8.3. High Availability（高可用） 1.9. Considerations Before Sharding（分片前的注意事项） 分片集群的基础设施和复杂性需要自己的规划，执行和维护。 为了保证集群的性能和效率，在选择片键时要慎重考虑，切分后不能更改片键。也不能取消分片集合的共享。 分片有一定的操作要求和限制。 如果 查询不包括 片键 或复合片键的前缀，那么mongos将执行广播操作，查询分片集群中的所有片。这些查询可能耗时很长。 1.10. Sharded and Non-Sharded Collections(分片和未分片的集合) 一个数据库可以混合使用有分片和未分片的集合。 分片集合在集群中的分片之间进行切割和分布。 未分片的集合存储在主片上。每个数据库都有自己的主片。 1.11. Connecting to a Sharded Cluster 你必须连接到mongos路由器，才能与分片集群中的任何集合进行交互。这包括分片和未分片的集合。为了执行读写操作，客户端不应该连接到单个的分片。 你可以用连接mongod一样的方式连接mongos。 1.12. Sharding Strategy(分片策略) 支持两种分片策略。 1.12.1. Hashed Sharding(哈希分片) 哈希分片，计算分片片键的散列值，然后根据散列值为每个块分配一个范围。 当一个range 片键是关闭状态，但他们的散列值不太可能位于同一块。基于散列值的数据分布有助于更均匀的 数据分布，尤其是在片键单调变化的数据集中。 然而，散列分布，意味着基于片键的查询不太可能以单个片为目标，从而导致更多的集群范围的广播操作。 mongos可以将具有相等匹配的查询作为单个片的目标。 Hashed Sharding Shard Key 作为散列片键选择的字段应该具有良好的基数，或者具有大量不同的值。哈希键对于具有像ObjectId值或时间戳一样单调变化的字段的片键是理想的。一个很好的例子是默认的_id字段，假设它只包含ObjectId值。 Hashed vs Ranged Sharding 给定一个集合，使用单调递增的值x作为片键，使用范围分片导致传入插入的分布类似于以下内容： 因为x的值总是在增加，所以具有maxkey上限的块接收大多数写入。这将插入操作限制到包含这个块的单个片，从而减少或消除了分片集群中分布式写入的优势。 通过在x上使用哈希索引，插入的分布类似于以下内容： 由于数据现在分布的更均匀，插入可以有效地分布在整个集群中。 Shard the Collection Shard a Populated Collection Shard an Empty Collection 1.12.2. Ranged Sharding （范围分片） 范围分片，根据片键将数据划分为多个范围，然后根据片键值为每个块分配一个范围。 一个范围的片键个能会位于同一个块。这允许目标操作，只将操作路由到包含所需数据的片。 范围分片，的效率取决于选择的片键。考虑不周的片键可能会导致数据分布不均匀，这可能会抵消分片的好处，或导致性能瓶颈。 如果没有配置诸如哈希分片或区域分片的其他选项，则默认基于范围的分片。 Shard Key Selection 范围分片是最有效的，当片键展示出如下特征： Large Shard Key Cardinality Low Shard Key Frequency Non-Monotonically Changing Shard Keys 下图说明了使用字段x作为片键的分片集群。如果x的值具有较大的范围，低频率和非单调速率变化，则插入看上去如下所示： Shard a Populated Collection Shard an Empty Collection 1.13. Zones in Sharded Clusters 在分片集群中，可以基于片键创建分片数据区域。可以将每个区域与集群中的一个或多个片关联。片可以与任意数量的区域关联。 在平衡集群中，mongodb将一个区域覆盖的块迁移到与该区域相关联的那些片上。 可以应用区域分片的一些常见部署模式如下： 隔离特定片集上的特定数据子集。 确保最相关的数据位于地理位置最靠近应用服务器的片上。 根据片硬件的硬件/性能将数据路由到片。 下图显示了一个带有三个片和两个区域的片集。A区表示下限为1，上限为10的范围。B区表示下限为10，上限为20的范围。片a和b有A区。片b也有B区。片Charlia 没有与之相关的区域。集群处于稳定状态，没有任何块违反任何区域。 1.13.1. Behavior and Operations Ranges 每个区域包含一个集合的一个或多个片键值范围。区域覆盖的每个范围始终包括其下边界，不包括其上边界。 区域不能共享范围，也不能有重叠的范围。 Initial Chunk Distribution 通过在对空集合或不存在的集合进行分片之前定义区域和区域范围，分片集合操作将为定义的区域范围以及任何其他块创建块，以覆盖整个片键值范围，并执行初始块分布平衡。位于区域范围内。最初创建和分发块允许更快的设置分区切分。在初始分布之后，平衡器将继续管理块分布。 Balancer 均衡器视图将一个分片集合的块平均分布在集群中的所有分片上。 对于标记为迁移的每个块，平衡器检查每个可能的目标片是否有任何已配置的区域。如果块范围属于一个区域，则平衡器会将块迁移到该区域内的片中。不属于某个区域的块可以存在于集群中的任何片上，并正常迁移。 在平衡回合中，如果平衡器检测到任何块违反了为给定片配置的区域，均衡器会将这些块迁移到不存在冲突的片。 将一个区域与一个或多个片关联，并为片收集配置一个片键范围后，集群可能需要一些时间来迁移片收集的受影响数据。这取决于块的划分和集群中数据的当前分布。当平衡完成时，给定区域中文档的读写只路由到该区域中的片。 配置后，在未来的平衡回合中，平衡器将尊重区域。 Shard Key 定义要覆盖的区域的新范围时，必须使用片键中包含的字段。如果使用复合片键，范围必须包括片键的前缀。 不能使用未包含片键的字段创建区域。 为集合选择片键时，请考虑可能要用于配置区域的字段。切分后，不能更改片键。 Hashed Shard Keys and Zones 在散列的片键上使用区域时，每个区域都包含散列的片键值。 边界表示的是散列值，而不是实际值。 通常，包含哈希片键值序列范围的区域可能会显示出意外的行为。 可以使用minkey和maxkey创建一个覆盖整个片键值范围的区域，以确保mongodb将特定集合的所有数据限制在该区域中的片或片。 Shard Zone Boundaries 区域范围始终包含下边界，不包括下边界。 1.13.2. Manage Shard Zones 1.13.3. Segmenting Data by Location 1.13.4. Tiered Hardware for Varying SLA or SLO 1.13.5. Segmenting Data by Application or Customer 1.13.6. Distributed Local Writes for Insert Only Workloads 1.14. Data Partitioning with Chunks （数据通过块迁移） mongodb使用与几何关联的片键将数据划分为块。一个块包含一个子集的分片数据。每个块都有一个基于片键的 上下范围。 mongodb根据片键值将写入路由到适当的块。mongodb在块超过配置的块大小时分割块。插入和更新都可以触发块分割。 块可以表示的最小范围是单个唯一的片键值。不能拆分只包含具有单个片键值的文档的块。 1.14.1. Initial Chunks 在大多数情况下，分片集群将自动创建/分割和分发块，而无需用户干预。但是，在数量有限的情况下，mongodb无需创建足够的块或以足够快的速度分发数据以支持所需的吞吐量。 例如，如果您希望将大量数据摄取到不平衡的集群中，或者如果摄取数据将导致数据不平衡，例如单调的增加或减少片键。在这些情况下，预拆分空分片集合的块可以帮助提高吞吐量。 或者，从mongo4.0.3开始，通过在划分空集合或不存在的集合之前定义区域和区域范围，分片集合操作将为定义的区域范围以及任何其他块创建块，以覆盖整个片键值范围，并根据区域范围形成初始块分布。有关详细信息，请参见空集合。 Populated Collection (已填充的集合) 分片操作创建初始快以覆盖片键值的整个范围。创建的块的数量取决于配置的块大小。 在初始块创建之后，平衡器将这些初始快在片之间进行适当的迁移，并继续管理块的分布。 Empty Collection(空集合) 如果为空或不存在的集合定义了分区和区的范围（从mongodb4.0.3开始提供）： 分片操作 为定义的分区范围创建空块以及任何其他块，以覆盖片键值的整个范围，并根据区域范围执行初始块分布。最初创建和分发块允许更快的设置分区切分。 在初始分布之后，平衡器将继续管理块分布。 如果没有为空集合或不存在的集合定义区域和区域范围： 对于散列片： 分片操作创建空块以覆盖片键值的整个范围，并执行初始块的分布。默认情况下，该操作为每个片创建2个块，并在集群中迁移。可以使用numInitialChunks选项指定不同数量的初始块。最初创建和分发块允许更快的设置分片。 在初始分布之后，平衡器将继续管理块分布。 对于范围分片： 分片操作创建一个单独的空块，以覆盖片键值的整个范围。 在初始块创建之后，均衡器会在适当的情况下跨片迁移初始块，并继续管理块分布。 1.14.2. Chunk Size mongodb中的默认块大小为64MB。可以增大或减小块大小。考虑更改默认块大小的影响： 小数据块会导致更均匀的数据分布，代价是更频繁的迁移。这会在查询路由（mongos）层产生开销。 大块会导致较少的迁移。从网络的角度和查询路由层的内部开销来看，这都更有效。但是，这些效率是以潜在的数据分布不均匀为代价的。 块大小影响要迁移的每个块的最大文档树。 块大小影响切分现有集合时的最大集合大小。切分后，块大小不限制集合大小。 对于许多部署来说，以稍微不太均匀分布的数据集为代价避免频繁和潜在的虚假迁移是有意义的。 Limitations 更改块大小会影响块分割的时间，但对其效果有一些限制。 自动拆分只能在插入和更新期间发生。如果减小块的大小，可能需要一些时间才能将所有块分割到新的大小。 拆分不能\"撤销\"。如果增加块大小，则现有块必须通过插入或更新来增长，直到达到新的大小。 1.14.3. Chunk Splits 分割是一个防止块增长过大的过程。当块超过指定的块大小时，或者如果块中的文档数超过要迁移的每个块的最大文档数，mongodb将根据块所代表的片键值分割块。 必要时，可以将块分割成多个块。插入和更新可能触发拆分。分割是一种有效的元数据更改。要创建拆分，mongodb不会迁移任何数据或影响碎片。 分割可能导致收集块在片之间的不均匀分布。在这种情况下，平衡器跨片重新分配块。有关跨碎片平衡块的更多详细信息，请参阅集群平衡器。 通常，如果块超过最大块大小，mongodb会在插入后拆分块。但是，如果出现以下情况，您可能需要手动拆分块： 您的集群中有大量的数据，只有很少的块，就像使用现有数据部署集群之后的情况一样。 您希望添加大量最初驻留在单个块或片中的数据。例如，您计划插入大量具有介于300和400之间的片键值的数据，但是您的片键值在250和500之间的所有值都在一个块中。 如果移动有利于将来的插入，平衡器可能会立即将最近分割的块迁移到新的片。平衡器不区分手动分割和系统自动分割的块。 1.14.4. Merge Chunks in a Shared Cluster mergechunks命令允许您将同一个shard上的连续块合并为单个块。本教程介绍如何在分片集群中合并相邻的块。 1.14.5. Chunk Migration mongodb迁移分片集群中的块，以便将分片集合中的块均匀地分布在片中。迁移可以是： 手动，仅在有限的情况下使用手动迁移，例如在大容量插入期间分发数据。有关详细信息，请参阅手动迁移块。 自动，当分片集合的块在片之间分布不均匀时，Balancer进程会自动迁移块。有关详细信息，请参阅迁移阈值。 有关分片集群平衡器的详细信息，请参阅分片集群平衡器。 1.14.6. Indivisible Chunks (不可分割的块) 在某些情况下，块可以超出指定的块大小，但不能进行拆分。最常见的情况是当一个块表示一个单独的片键值。由于块无法分割，它继续超出块大小，成为一个巨大的块。这些巨型块在继续增长时可能成为性能瓶颈，特别是在片键值出现频率很高的情况下。 添加新数据或新碎片可能会导致集群内的数据分布不平衡。一个特定的片可能会获得比另一个片更多的块，或者块的大小可能会超过配置的最大块大小。 mongodb使用两个进程来确保集群的平衡：分块和平衡器 1.14.7. moveChunk directory 在mongodb2.6和3.0中，默认情况下启用sharding.archiveMovedChunks。默认情况下，所有其他mongodb版本都禁用了此功能。 启用后，源片将迁移的块中的文档存档到以storage.dbPath中moveChunk目录下的集合命名空间命名的目录中。 如果迁移过程中发生错误，这些文件可能有助于恢复迁移过程中受影响的文档。 一旦成功完成迁移，并且不需要从这些文件恢复文档，您就可以安全地删除这些文件。或者，如果数据库的现有备份可用于恢复，则也可以在迁移后删除这些文件。 要确定所有迁移是否完成，请在连接到mongos实例时运行sh.isBalancerRuning()。 1.15. Balancer(平衡器) 1.15.1. Balancing Balancer是一个管理块迁移的后台进程。如果最大和最小片之间的块数差异超过迁移阈值，则平衡器将开始跨集群迁移块，以确保数据均匀分布。 你可以管理平衡器的某些方面。均衡器还尊重作为在分片集群中配置区域的一部分而创建的任何区域。 mongodb balancer是一个后台进程，它监视每个片上的块的数量。当给定片上的块的数量达到特定的迁移阈值时，均衡器会尝试在片之间自动迁移块，并达到每个片相等的块数量。 对于用户和应用程序层来说，分片集群的平衡过程完全是透明的，尽管在执行过程中可能会有一些性能影响。 从mongo3.4开始，平衡器在配置服务器副本集（CSR）的主服务器上运行： 在3.4版本中，当Balancer进程处于活动状态时，配置服务器副本集的主副本通过修改配置数据库中locks集合中的_id:balancer文档来获取 balancer lock。这个 \"平衡锁\"永远不会释放。 从3.6版本开始，平衡机不再需要\"锁定\"。 1.15.2. Cluster Balancer 平衡器进程负责在每个分片集合的分片之间均匀地重新分配分片集合的块。默认情况下，始终启用平衡器进程。 为了解决分块集合的不均匀块分布问题，平衡器将多块的分块迁移到少块的分块。均衡器迁移块，直到在片之间为集合分片了均匀的块。 在版本2.6中进行了更改：块迁移可能会对磁盘空间产生影响。从mongo2.6开始，源片默认自动存档迁移的文档。有关详细信息，请参见moveChunk目录。 块迁移在带宽和工作负载方面会带来一些开销，这两者都会影响数据库性能。平衡器视图通过以下方式将影响降至最低： 在任何给定时间限制一个片至多迁移一次；即一个片不能同时参与多个块迁移。为了从一个片迁移多个块，均衡器一次迁移一个块。 在2.4版本中进行了更改：从3.4版本开始，mongodb可以执行并行块迁移。由于一个片一次最多可以参与一个迁移的限制，对于一个具有n个片的分片集群，mongodb最多可以同时执行n/2(向下取整)块迁移。 只有当具有最大块数的片集合与具有最小块数的片集合之间的块数差异达到迁移阈值时，才开始平衡轮。 您可以暂时禁用平衡机进行维护。 您还可以限制运行平衡器的窗口，以防止它影响生产流量。 Adding and Removing Shards from the Cluster 将片添加到集群会造成不平衡，因为新片没有块。当mongodb立即开始将数据迁移到新的片时，在集群平衡之前可能需要一些时间。 从集群中删除片会造成类似的不平衡，因为驻留在该片上的块必须在整个集群中重新分布。当mongodb立即开始排出一个删除的片时，在集群平衡之前可能会需要一些时间。在此过程中，不要关闭与已删除片关联的服务器。 当您删除具有不均匀块分布的集群中的片时，平衡器首先从排出的片中删除块，然后平衡剩余的不均匀块分布。 1.15.3. Chunk Migration Procedure(块迁移过程) 所有块迁移都使用以下过程： 均衡器进程将moveChunk命令发送到源片。 源使用内部movechunk命令启动移动。在迁移过程中，对块的操作将路由到源片。源片负责块的传入写入操作。 目标片构建源所需的任何索引，这些索引在目标上不存在。 目标片开始请求块中的文档，并开始接收数据的副本。 在接收到块中的最终文档后，目标片将启动同步过程，以确保它对迁移期间发生的迁移文档进行了更改。 完全同步后，源片连接到配置数据库，并使用块的新位置更新集群元数据。 源片完成元数据更新后，一旦块上没有打开的游标，源片将删除其文档副本。 迁移过程确保一致性，并在平衡期间最大限度的提高块的可用性。 Migration Thresholds (迁移阈值) 为了最小化平衡对集群的影响，只有在分片集合的块分布达到特定阈值之后，平衡器才会开始平衡。阈值适用于集合中块数最多的片和集合中块数最少的片之间的块数差异。 平衡器具有以下阈值： Number of Chunks Migration Threshold Fewer than 20 2 20-79 4 80 and greater 8 当目标集合的任何两个片上的块数之差小于两个或块迁移失败时，平衡器程序将停止在目标集合上运行。 Asynchronous Chunk Migration Cleanup (异步块迁移清理) 为了从一个片迁移多个块，均衡器一次迁移一个块。但是，在开始下一个块迁移之前，均衡器不会等待当前迁移的删除阶段完成。 这种排队行为运行片在严重不均衡的集群中更快的卸载块，例如在执行初始数据加载而不预拆分和添加新碎片时。 此行为还影响movechunk命令，使用movechunk命令的迁移脚本可能会更快的进行。 在某些情况下，删除阶段可能会持续更长时间。如果多个删除阶段已排队，但尚未完成，则副本集主阶段的崩溃可能会从多个迁移中孤立数据。 作为balancer和movechunk命令的设置，waitfordelete可以更改行为，以便当前迁移的删除阶段阻止下一个块迁移的开始。waitfordelete通常用于内部测试。 Chunk Migration and Replication¶ (区块迁移和复制) 在3.4版本中更改。 在块迁移过程中，_secondaryThrottle 值决定迁移何时与块中的下一个文档一起进行。 在config.settings集合中： 如果均衡器的_secondaryThrottle设置设置为写问题，则在块迁移期间移动的每个文档都必须继续在下一个文档之前收到请求的确认。 如果balancer的_secondary限制设置设置为true，则在块迁移过程中移动的每个文档都必须至少收到一个secondary的确认，然后才能继续迁移块中的下一个文档。这相当于{w:2}的写关注点。 如果未设置_secondaryThrottle设置，则迁移过程不会等待复制到辅助文件，而是继续执行下一个文档。 独立于任何辅助限制设置，区块迁移的某些阶段具有以下复制策略： mongodb在使用块的新位置更新配置服务器之前，在源片上短暂的暂停所有要迁移的集合的应用程序读写，并在更新后恢复应用程序读写。块移动要求在将块移动提交到配置服务器之前和之后，副本集的大多数成员都要确认所有写入操作。 当传出块迁移完成并发生清理时，必须将所有写入复制到大多数服务器，然后才能继续进一步清理（从其他传出迁移）或新的传入迁移。 Maximum Number of Documents Per Chunk to Migrate (要迁移的每个块的最大文档数) 3.4.11中进行了更改。 如果块中的文档数大于配置快大小除以平均文档大小的结果的1.3倍，则mongodb无法移动块。stats()包含avgobjsize字段，该字段表示集合中的平均文档大小。 1.15.4. Shard Size 默认情况下，mongodb会随着数据集的增长，用每个片上的数据填充所有可能磁盘空间。为了确保集群始终具有处理数据增长的能力，可以监视磁盘使用情况以及其他性能指标。 1.16. Collations in Sharding 1.17. Change Streams 1.18. Transactions ±±±≠≠≠ "},"db/mongodb/administration.html":{"url":"db/mongodb/administration.html","title":"管理","keywords":"","body":"1. administration Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 1. administration 监控 mongostat mongotop mongosniff serverStatus stats Web 备份恢复 mongoexport, mongoimport mongodump, mongorestore 权限控制 "},"db/mongodb/storage.html":{"url":"db/mongodb/storage.html","title":"存储","keywords":"","body":"1. storage Title Date Modified Category mongodb 2019-08-23 12:00 2019-08-23 12:00 db 1. storage GridFS Journaling日志功能 "},"db/hbase.html":{"url":"db/hbase.html","title":"hbase","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db "},"db/memcache.html":{"url":"db/memcache.html","title":"memcache","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db "},"concurrent/":{"url":"concurrent/","title":"concurrent","keywords":"","body":"1. concurrent1.1. 引论1.2. 概念1.3. 并行架构1.3.1. 位级（bit-level）并行1.3.2. 指令级（instruction-level）并行1.3.3. 数据级（data）并行1.3.4. 任务级（task-level）并行1.4. 并发架构1.4.1. 并发的世界，并发的软件1.4.2. 分布式的世界，分布式的软件1.4.3. 不可预测的世界，容错性强的软件1.4.4. 复杂的世界，简单的软件1.5. 七个模型1.6. 总结回顾1.7. 参考资料1.7.1. books Title Date Modified Category concurrent 2019-07-13 12:00 2019-07-13 12:00 concurrent 1. concurrent 1.1. 引论 并发编程的概念并不新，却直到最近才火起来。 并发编程复兴的主要驱动力来自于所谓的“多核危机”。正如摩尔定律所语言的那样，芯片性能仍在不断提高，CPU的速度会继续提升，但计算机的发展方向已然转向多核化。 为了让代码运行的更快，单纯依靠更快的硬件已无法满足要求，我们需要利用多核，也就是发掘并行执行的潜力。 1.2. 概念 并发 是 同一时间应对（dealing with）多件事情的能力 并行 是 同一时间动手做（doing）多件事情的能力 并发和并行的共同点就是它们比传统的串行编程模型更优秀。 1.3. 并行架构 人们通常认为并行等同于多核，但现代计算机在不同层次上都使用了并行技术。 1.3.1. 位级（bit-level）并行 为什么32位计算机的运行速度比8位计算机更快？因为并行。对于两个32位数的加法，8位计算机必须进行多次8位计算，而32位计算机可以一步完成。即并行的处理32位数的4字节。 1.3.2. 指令级（instruction-level）并行 现代CPU的并行度很高，其中使用的技术包括流水线，乱序执行和猜测执行等。 程序猿通常可以不关心处理器内部并行的细节，因为尽管处理器内部的并行度很高，但是经过精心设计，从外部看上去所有处理都像是串行的。 1.3.3. 数据级（data）并行 数据级并行（也称为“单指令多数据”， SIMD）架构，可以并行的在大量数据上施加同一操作。这并不适合解决所有问题，但在适合的场景却可以大展身手。 图像处理就是一种适合进行数据级并行的场景。比如，为了增加图片亮度就需要增加每一个像素的亮度。现代GPU（图形处理器）也因图像处理的特点而演化成了极其强大的数据并行处理器。 1.3.4. 任务级（task-level）并行 终于来到了大家所认为的并行形式——多处理器。从程序猿的角度来看，多处理器架构最明显的分类特征是其内存模型（共享内存模型或分布式内存模型）。 对于共享内存的多处理器系统，每个处理器都能访问整个内存，处理器之间的通信主要通过内存进行。 对于分布式内存的多处理器系统，每个处理器都有自己的内存，处理器之间的通信主要通过网络进行， 通过内存通信比通过网络通信更简单更快速，所以用共享内存编程往往更容易。 然而，当处理器个数逐渐增多，共享内存就会遭遇性能瓶颈----此时不得不转向分布式内存。 如果要开发一个容错系统，就要使用多台计算机以规避硬件故障对系统的影响，此时也必须借助于分布式内存。 1.4. 并发架构 使用并发的目的，不仅仅是为了让程序并行运行从而发挥多核的优势。若正确使用并发，程序还将获得以下优点：及时响应，高效，容错，简单。 1.4.1. 并发的世界，并发的软件 世界是并发的，为了与其有效地交互，软件也应是并发的。 1.4.2. 分布式的世界，分布式的软件 有时，我们要解决地理分布型问题。软件在非同步运行的多台计算机上分布式的运行，其本质是并发。 此外，分布式软件还具有容错性。我们可以将服务器一半部署在欧洲，另一半部署在美国，这样如果一个区域停电就不会造成软件整体不可用。 1.4.3. 不可预测的世界，容错性强的软件 软件有bug，程序会崩溃。即使存在完美的没有bug的程序，运行程序的硬件也可能出现故障。 为了增强软件的容错性，并发代码的关键是独立性和故障检测。 串行程序的容错性远不如并发程序。 1.4.4. 复杂的世界，简单的软件 用串行方案解决一个并发问题往往需要付出额外的代价，而且解决方案会晦涩难懂。如果解决方案有着与问题类似的并发结构，就会简单许多：我们不需要创建一个复杂的线程来处理问题中的多个任务，只需要用多个简单的线程分别处理不同的任务即可。 1.5. 七个模型 线程与锁 线程与锁模型有很多众所周知的不足，但仍是其他模型的技术基础，也是很多并发软件开发的首选。 函数式编程 函数式编程日渐重要的原因之一，是其对并发编程和并行编程提供了良好的支持。函数式编程消除了可变状态，所以从根本上是线程安全的，而且易于并行执行。 Clojure之道-分离标识与状态 编程语言Clojure是一种指令式编程和函数式编程的混搭方案，在两种编程方式上取得了微妙的平衡来发挥两者的优势。 actor actor模型是一种适用性很广的并发编程模型，适用于共享内存模型和分布式内存模型，也适合解决地理分布型问题，能提供强大的容错性。 通信顺序编程 表面上看，CSP模型与actor模型很相似，两者都基于消息传递。不过CSP模型侧重于传递消息的通道，而actor模型侧重于通道两端的实体，使用CSP模型的代码会带有明显不同的风格。 数据级并行 每个笔记本电脑里都藏着一台超级计算机——GPU。GPU利用了数据级并行，不仅可以快速进行图像处理，也可以用于更广阔的领域。 Lambda架构 大数据时代的到来离不开并行----现在我们只需要增加计算资源，就能具有处理TB级数据的能力。Lambda架构综合了MapReduce和流式处理的特点，是一种可以处理多种大数据问题的架构。 1.6. 总结回顾 1.7. 参考资料 1.7.1. books 《七周七并发模型》 "},"concurrent/thread.html":{"url":"concurrent/thread.html","title":"线程与锁","keywords":"","body":""},"concurrent/function.html":{"url":"concurrent/function.html","title":"函数式编程","keywords":"","body":""},"concurrent/clojure.html":{"url":"concurrent/clojure.html","title":"Clojure之道-分离标识与状态","keywords":"","body":""},"concurrent/actor.html":{"url":"concurrent/actor.html","title":"actor","keywords":"","body":""},"concurrent/csp.html":{"url":"concurrent/csp.html","title":"通信顺序编程","keywords":"","body":""},"concurrent/data_concurrent.html":{"url":"concurrent/data_concurrent.html","title":"数据级并行","keywords":"","body":""},"concurrent/lambda.html":{"url":"concurrent/lambda.html","title":"Lambda架构","keywords":"","body":""},"distribution/":{"url":"distribution/","title":"Distribution","keywords":"","body":"1. 分布式1.1. CAP1.2. BASE1.3. RPC1.4. Actor2. 目录 Title Date Modified Category distribution 2019-06-10 12:00 2019-06-10 12:00 distribution 1. 分布式 1.1. CAP 1.2. BASE 1.3. RPC 1.4. Actor 2. 目录 HACluster cache mq Kafka byzantine cap paxos raft registry consul etcd Zookeeper "},"distribution/hacluster.html":{"url":"distribution/hacluster.html","title":"HACluster","keywords":"","body":"1. HACluster1.1. 高可用衡量标准1.2. 常见高可用方案1.3. 虚拟服务1.3.1. DNS轮询1.3.2. 客户端调度1.3.3. 应用层负载调度1.3.4. IP层负载调度1.4. 工具2. 参考资料2.1. books Title Date Modified Category hacluster 2019-07-11 12:00 2019-07-11 12:00 distribution 1. HACluster 高可用集群（High Availability Cluster，HACluster）一般至少由两台以上服务器组成，这一组服务器作为一个整体向用户提供可靠的网络服务，其中的单台服务器就叫作节点（Node）。 高可用集群可以通过多种技术手段实现，而服务器集群是实现高可用最流行的方案之一。 集群负载在高可用集群中起着核心的控制作用，通过负载均衡软件实现故障检查和业务切换的自动化。 1.1. 高可用衡量标准 高可用（High Available，HA）集群通过系统的可靠性（reliability）和可维护性（maintainability）来衡量。 通常使用平均无故障时间（MTTF）来衡量系统的可靠性，用平均维修时间（MTTR）来衡量系统的可维护性。于是可用性被定义为：HA=MTTF/(MTTF+MTTR)*100%。 按照这个概念，具体的HA衡量标准如下： 99%为一年宕机时间不超过4天 99.9%为一年宕机时间不超过10小时 99.99%为一年宕机时间不超过1小时 99.999%为一年宕机时间不超过6分钟 1.2. 常见高可用方案 共享存储 故障转移 负载均衡 分布集群 1.3. 虚拟服务 在所有的已知的可伸缩网络服务结构中，它们都需要一个或者多个前端的负载调度器，通过调度器的调度实现虚拟服务。 在大部分网络服务中，客户端与服务端之间都有一层或者多层代理程序。这些代理程序便是一套完整的虚拟服务实现方案。这些方案可以在不同的层次上实现多台服务器的负载均衡。 目前，用集群解决网络服务性能问题的方法可分为以下四类： DNS轮询， 客户端调度， 应用层负载调度 和IP层负载调度。 1.3.1. DNS轮询 DNS轮询也称为RR-DNS(Round-Robin Domain Name System), DNS服务器会把域名轮流解析这组服务器的不同IP地址，从而将访问负载分到各台服务器上。这是它的基本工作原理，但实际上商用的DNS负载会更为复杂（成本更大），这里有以下三个明显的问题。 TTL问题 负载压力问题 系统扩展维护问题 鉴于以上这些问题，目前DNS轮询的方案一般只用于跨区域的负载调度场景，例如一定规模的集群中，通过DNS轮询使北方的用户访问北方的服务器，南方的用户访问南方的服务器，因为在跨区域的负载调度中，DNS轮询的成本最低。 1.3.2. 客户端调度 客户端调度的方式比较少见，也不具有普遍的适用性。 1.3.3. 应用层负载调度 应用层负载调度，又叫七层负载均衡，也叫反向代理负载均衡。 其结构基本上就是多台应用服务器通过高速的网络连接成一个集群系统，在前端有一个基于应用层的负载调度器。当用户访问请求到达调度器时，请求会提交给负载均衡调度器，它分析请求并根据各个应用服务器的负载情况，重写请求并发送到其中一台应用服务器，取得结果后，再返回给用户。 这种负载方案应用非常广泛， 当然他也存在一些问题。主要是系统处理开销较大，当请求到达负载均衡调度器，一直到处理结束，调度器需要进行四次从核心空间到用户空间或从用户空间到核心空间的上下文切换和内存复制；需要进行二次TCP连接，一次是从用户到调度器，另一次是从调度器到应用服务器；需要对请求进行分析和重写。这些处理都需要一定的CPU，内存和网络等资源。当服务规模扩增时，调度器本身可能会成为系统的瓶颈。 这种防范优点十分突出，自定义程度高，可以根据要求设计出满足各种场景的负载要求。 1.3.4. IP层负载调度 与应用层负载调度方案相比，IP层负载调度的可配置程度远不及前者，但是后者的效率确实是最高的，因此在很多企业中都愿意选择IP层负载调度方案。 1.4. 工具 Nginx HA LVS 2. 参考资料 2.1. books 《容器云运维实战：Docker与Kubernetes集群》 "},"distribution/cache.html":{"url":"distribution/cache.html","title":"Cache","keywords":"","body":"1. cache1.1. cache L1 L2 L31.2. 多核CPU与内存共享1.3. 缓存实现的几种方式1.4. redis1.5. Memcache Title Date Modified Category cache 2019-06-10 12:00 2019-06-11 12:00 distribution 1. cache 1.1. cache L1 L2 L3 1.2. 多核CPU与内存共享 1.3. 缓存实现的几种方式 1.4. redis 1.5. Memcache "},"distribution/mq/":{"url":"distribution/mq/","title":"MQ","keywords":"","body":" Title Date Modified Category mq 2019-06-11 12:00 2019-06-11 12:00 distribution Kafka "},"distribution/mq/kafka.html":{"url":"distribution/mq/kafka.html","title":"kafka","keywords":"","body":" Title Date Modified Category kafka 2019-06-11 12:00 2019-06-11 12:00 distribution "},"distribution/byzantine.html":{"url":"distribution/byzantine.html","title":"byzantine","keywords":"","body":" Title Date Modified Category 拜占庭将军问题 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/cap.html":{"url":"distribution/cap.html","title":"cap","keywords":"","body":" Title Date Modified Category CAP 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/paxos.html":{"url":"distribution/paxos.html","title":"paxos","keywords":"","body":" Title Date Modified Category paxos 2019-07-11 12:00 2019-07-11 12:00 distribution "},"distribution/raft.html":{"url":"distribution/raft.html","title":"raft","keywords":"","body":" Title Date Modified Category raft 2019-07-11 12:00 2019-07-11 12:00 distribution "},"distribution/registry/":{"url":"distribution/registry/","title":"registry","keywords":"","body":" Title Date Modified Category 服务注册与发现 2019-06-12 12:00 2019-06-12 12:00 distribution consul etcd Zookeeper "},"distribution/registry/consul.html":{"url":"distribution/registry/consul.html","title":"consul","keywords":"","body":" Title Date Modified Category Consul 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/registry/etcd.html":{"url":"distribution/registry/etcd.html","title":"etcd","keywords":"","body":" Title Date Modified Category etcd 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/registry/zookeeper.html":{"url":"distribution/registry/zookeeper.html","title":"Zookeeper","keywords":"","body":" Title Date Modified Category ZooKeeper 2019-06-12 12:00 2019-06-12 12:00 distribution "},"kernel/":{"url":"kernel/","title":"Kernel","keywords":"","body":"1. kernel Title Date Modified Category kernel 2019-11-19 12:00 2019-11-19 12:00 kernel 1. kernel "},"micros/":{"url":"micros/","title":"micros","keywords":"","body":"1. MicroService架构探索 Title Date Modified Category micros 2019-05-29 12:00 2019-06-10 12:00 micros 禁止转载 本目录内文章，图片和文字资源大多来自于网络和参考书籍，如有侵权，请联系删除 1. MicroService架构探索 各位领导大家好，今天给大家汇报一下最近的一些关于微服务的研究。 MicroService Consul go-micro SpringCloud Docker Docker Compose Docker Swarm Mesos Kubernetes Helm DevOps OpenShift 3 Serverless Istio OpenShift 4 Rancher Chaos Engineering ELK EFK Monitoring Prometheus Zipkin 总结 Q & A "},"micros/microservice.html":{"url":"micros/microservice.html","title":"MicroService","keywords":"","body":"1. MicroService1.1. 概述1.1.1. 微服务设计的理念：1.1.2. 为什么要使用微服务1.1.3. 微服务特点，如下所述。1.1.4. 微服务带来的问题。1.2. todos demo1.3. 参考资料 Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. MicroService 1.1. 概述 微服务是一种软件架构模式，用来把大而重的应用程序切成许多可管理的、可管理的独立服务，各服务之间的通信并不受不同语言的协议影响，每个服务只管做好一件事情。 1.1.1. 微服务设计的理念： 各服务要小 - 单一的业务目标应该是要细粒度，就像Unix的”只做一件事并且要做好”理念。 组织文化要包含部署与测试的自动化，这个降低管理与操作的负担。 设计原则要包含失败与错误，就像抗脆弱的系统。 1.1.2. 为什么要使用微服务 随着组织的扩大，使用的技术和员工的数量都在增加，管理单一代码实现的服务，只会变得越来越复杂。 1.1.3. 微服务特点，如下所述。 在结构上，将原有的从技术角度拆分的组件，升级为从业务角度拆分的独立运行的服务，这些服务具备各自的实现平台，并且独占自有数据，在服务之间以智能端点和哑管道的方式通信。 在工程上，从产品而非项目的角度进行设计，强调迭代，自动化和面向故障的设计方法。 1.1.4. 微服务带来的问题。 微服务架构在很大程度上提高了应用的伸缩性，方便了部门或业务之间的协作，使技术岗位能够更好地引入新技术并提高自动化程度，最终达到减耗增效的目的，然而和所有新方法一样，微服务架构在解决老问题的同时，也带来了一些新问题，例如： 实例数量急剧增长，对部署和运维的自动化要求更高。 用网络调动代替内部API，对网络这一不可靠的基础设施依赖增强 调用链路变长，分布式跟踪称为必选项目 日志分散严重，跟踪和分析难度加大 服务分散，受攻击面积更大 在不同的服务之间存在协作关系，需要有更好的跨服务控制协调能力 自动伸缩，路由管理，故障控制，存储共享，等等。 1.2. todos demo TODO 1.3. 参考资料 "},"micros/consul.html":{"url":"micros/consul.html","title":"Consul","keywords":"","body":"1. Consul1.1. 概念1.1.1. 服务注册与发现1.1.2. Consul1.2. 演示1.2.1. install consul1.2.2. run the agent1.2.3. services1.2.4. Connect1.2.5. Consul Cluster1.2.6. Health Checks1.2.7. KV Data1.2.8. Web UI1.3. todos demo1.4. 参考资料1.4.1. GitHub1.4.2. Website Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Consul 1.1. 概念 1.1.1. 服务注册与发现 1.1.2. Consul 1.2. 演示 1.2.1. install consul $brew install consul verifying the installation $consul 1.2.2. run the agent starting the agent $consul agent -dev 为了简单，我们以开发模式启动consul agent。这个模式可以快速和容易的启动一个单节点的consul环境. 这个模式不适合用于生产环境，因为它不保存任何状态。 cluster members $consul members Node Address Status Type Build Protocol DC Segment avril.local 127.0.0.1:8301 alive server 1.3.0 2 dc1 在另一个terminal中执行consul members，你可以看到consul cluster的members，你可以看到，只有 one member（yourself）. 输出显示了我们自己的node，这address it is running on，its health state, its role in the cluster, and some version information. 额外的元数据信息可以通过-detailed flag看到. 这个命令的输出，基于gossip protocol, and is 最终一致的。也就是说，在任何节点在同一时间，看到的世界，by 你本地的agent 可能不完全匹配这状态在servers。一个强一致的系统的展示，可以用这HTTP API 去远程请求consul servers $curl localhost:8500/v1/catalog/nodes [ { \"ID\": \"9a8b671d-ffdb-6445-f436-9ad02cf7d219\", \"Node\": \"avril.local\", \"Address\": \"127.0.0.1\", \"Datacenter\": \"dc1\", \"TaggedAddresses\": { \"lan\": \"127.0.0.1\", \"wan\": \"127.0.0.1\" }, \"Meta\": { \"consul-network-segment\": \"\" }, \"CreateIndex\": 9, \"ModifyIndex\": 10 } ] 对于这个HTTP API额外的说一下，DNS interface可以被用来请求这个节点。提示：你必须确保你的DNS 发现 指向 consul agent's DNS server, which 运行在 8600默认端口上的。这DNS 入口的格式，（类似 \"avril.local.node.consul\"）可以被发现在一会 $dig @127.0.0.1 -p 8600 avril.local.node.cansul ; > DiG 9.10.6 > @127.0.0.1 -p 8600 avril.local.node.cansul ; (1 server found) ;; global options: +cmd ;; Got answer: ;; ->>HEADERstopping the agent 你可以ctrl-C去优雅的停止这个agent，当中断这个agent，你可以看到，它离开的cluster，and shut down。 为了优雅的leaving，consul 通知其他集群成员，这个节点离开了。如果你强行kill这个agent 进程，其他成员将发现这个node fail的。 当一个成员离开，它的服务和检查，将从catalog移除。当一个成员fails，它的健康仅仅标记为critical, 但它不会从catalog中移除。 cansul往往会重连 failed nodes，允许它从好的网络状态下恢复。然而离开的节点永远不会联系。 另外，如果一个agent 正在操作一个server，一个优雅的离开方式是重要的，去避免造成一些超出控制的影响. 1.2.3. services registering services 在前面的步骤里，我们运行了我们的第一个agent，查看了集群的成员，并且访问了这个节点。在本节guide，我们将注册我们第一个service，并且query这个service。 defining a service 一个服务，可以通过，提供一个服务定义文件，或者调用一个合适的HTTP API 一个服务定义，是最常用的方式去注册service，所以，我们用这种方式开启下一步。我们将基于上一步的agent 配置。 首先，创建一个目录用于consul configuration。consul loads 所有的配置文件，in the 配置目录，所以一个通用的形式，在unix系统上是定义这个目录like /etc/consul.d(the .d suffix implies \"this directory contaions a set of configuration files\"). $sudo mkdir /etc/consul.d 接下来，我们写一个服务定义文件，我们假装我们有一个服务named\"web\" 跑在80端口，另外，我们给它一个tag，我们可以用来额外的方式查询这个service. $ echo '{\"service\": {\"name\": \"web\", \"tags\": [\"rails\"], \"port\": 80}}' \\ | sudo tee /etc/consul.d/web.json 现在，重启agent，提供这个配置目录 $ consul agent -dev -config-dir=/etc/consul.d 你可以注意到他的输出，同步的这个web service。这意味着这个agent加载了这个服务配置，从配置文件里，并且成功注册了他在这服务catalog。 如果你想去注册multiple services，你可以创建multiple service配置文件在这配置目录里。 querying services Once the agent is started and the service is synced, we can query the service using either the DNS or HTTP API. DNS API 让我们首先请求我们的服务，用DNS API。for the DNS API, the DNS name for servics is NAME.service.consul. By default, all DNS names are always in the consul namespace, though this is configurable. The service subdomain tells Consul we're querying services, and the NAME is the name of the service. For the web service we registered, these conventions and settings yield a fully-qualified domain name of web.service.consul $ dig @127.0.0.1 -p 8600 web.service.consul 你可以看到，一个记录返回了这IP地址，of 这个节点，on which 这个服务存在的。一个记录可以仅仅包含IP地址。 你可以用这DNS API to retrieve the entrie address/port pair as a SRV record $ dig @127.0.0.1 -p 8600 web.service.consul SRV 这个服务记录，说，这个web service 运行在80端口，并且在节点。。上，并且额外的信息返回了，通过这DNS，with the 一个记录 for the node。 实际上，我们也可以通过DNS API去过滤服务用tags， $ dig @127.0.0.1 -p 8600 rails.web.service.consul HTTP API $ curl http://localhost:8500/v1/catalog/service/web [{\"Node\":\"Armons-MacBook-Air\",\"Address\":\"172.20.20.11\",\"ServiceID\":\"web\", \\ \"ServiceName\":\"web\",\"ServiceTags\":[\"rails\"],\"ServicePort\":80}] The catalog API gives all nodes hosting a given service. As we will see later with health checks you'll typically want to query just for healthy instances where the checks are passing. This is what DNS is doing under the hood. Here's a query to look for only healthy instances: $ curl 'http://localhost:8500/v1/health/service/web?passing' [{\"Node\":\"Armons-MacBook-Air\",\"Address\":\"172.20.20.11\",\"Service\":{ \\ \"ID\":\"web\", \"Service\":\"web\", \"Tags\":[\"rails\"],\"Port\":80}, \"Checks\": ...}] updating services 服务定义可以被更新，通过改变配置文件，和发送 a SIGHUP to the agent. 这可以让你更新services 没有任何停机或不可用。 这HTTP API可以被用来，add，remove，modify services dynamically。 1.2.4. Connect 1.2.5. Consul Cluster 1.2.6. Health Checks 1.2.7. KV Data 1.2.8. Web UI 1.3. todos demo TODO 1.4. 参考资料 1.4.1. GitHub https://github.com/hashicorp/consul 1.4.2. Website https://www.consul.io/ "},"micros/go-micro.html":{"url":"micros/go-micro.html","title":"go-micro","keywords":"","body":"1. go-micro1.1. 概述1.1.1. 特性1.2. todos demo1.2.1. 架构1.2.2. 演示1.3. 参考资料1.3.1. GitHub1.3.2. WebSite Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. go-micro 1.1. 概述 Micro是一套微服务构建工具库。对于微服务架构的应用，Micro提供平台层面、高度弹性的工具组件，让服务开发者们可以把复杂的分布式系统以简单的方式构建起来，并且尽可能让开发者使用最少的时间完成基础架构的构建。 1.1.1. 特性 网关 Web Dashboard 服务发现 负载均衡 同步通信 异步通信 消息编码 服务接口-Golang开发框架 组件可插拔 1.2. todos demo 1.2.1. 架构 1.2.2. 演示 TODO 1.3. 参考资料 1.3.1. GitHub https://github.com/micro 1.3.2. WebSite https://micro.mu/ https://micro.mu/docs/cn/index.html "},"micros/spring-cloud.html":{"url":"micros/spring-cloud.html","title":"SpringCloud","keywords":"","body":"1. SpringCloud1.1. 概念1.2. 参考资料 Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. SpringCloud 1.1. 概念 Spring Cloud最早在功能层面为微服务治理定义了一系列标准特性，例如智能路由，熔断机制，服务注册与发现等，并提供了对应的库和组件来实现这些标准特性。到目前为止，这些库和组件被广泛采用。 Spring Cloud缺点： 既博采众家之长，也导致了一些散乱的局面，即用户需要学习和熟悉各组件的”方言“并加以运维，这在客观上提高了应用门槛 需要在代码级别对诸多组件进行控制，包括Sidecar在内的组件都依赖Java的实现，这和微服务的多语言协作目标是背道而驰的 自身并没有对调度，资源，DevOps等提供相关支持，需要借助其他平台来完成，然而目前的容器编排事实标准是k8s，二者的部分功能存在重合或者冲突，这在一定程度上影响了Spring Cloud的长远发展。 1.2. 参考资料 "},"micros/docker.html":{"url":"micros/docker.html","title":"Docker","keywords":"","body":"1. Docker1.1. 概述1.1.1. Container1.1.2. Docker1.2. 使用1.3. Docker 与微服务1.4. Docker周边工具1.4.1. 运维工具1.4.2. 网络支持1.4.3. 监控与日志1.4.4. Docker持续集成1.4.5. 私有镜像仓库1.4.6. 公有云1.4.7. 集群管理面板1.5. 基于Docker的PaaS平台1.5.1. 操作系统1.5.2. Serverless1.6. 参考资料1.6.1. GitHub1.6.2. WebSite1.6.3. Books Title Date Modified Category docker 2019-05-29 12:00 2019-05-29 12:00 micros 1. Docker 1.1. 概述 1.1.1. Container 1.1.2. Docker 事实上的标准 docker，优势，可以构建一个隔离的，稳定的，安全地，高性能的容器运行环境。 1.2. 使用 docker help 1.3. Docker 与微服务 1.4. Docker周边工具 1.4.1. 运维工具 Ansible 1.4.2. 网络支持 Pipework Flannel Weave Net Calico 1.4.3. 监控与日志 cAdvisor 原生集群监控 Logspout 日志处理 Grafana 数据可视化 Heapster Prometheus EFK Filebeat ELK (ElasticSearch，Logstash，Kibana) Fluentd Graylog Cat Zipkin Pinpoint InfluxDB 1.4.4. Docker持续集成 Drone 轻量级CI工具 Travis CI 著名的CI/CD服务商 1.4.5. 私有镜像仓库 https://github.com/docker/distribution VMWare Harbor SUSE Portus 1.4.6. 公有云 GKE 1.4.7. 集群管理面板 Shipyard Portainer ** Panamax Seagull 1.5. 基于Docker的PaaS平台 Deis 轻量级PaaS平台 Tsuru 可扩展PaaS平台, 基于Swarm Flynn 模块化PaaS平台 openshift 1.5.1. 操作系统 CoreOS RancherOS Red hat Atomic VMWare Photon 1.5.2. Serverless Kubeless Function Trigger Fission OpenFaaS 1.6. 参考资料 1.6.1. GitHub https://github.com/docker 1.6.2. WebSite https://www.docker.com/ 1.6.3. Books 《Docker技术入门与实战（第3版）》 "},"micros/docker-compose.html":{"url":"micros/docker-compose.html","title":"Docker Compose","keywords":"","body":"1. Docker Compose1.1. 简介1.2. 使用1.3. todos demo1.3.1. demo1.3.2. 演示 Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Docker Compose 1.1. 简介 单机服务编排工具 1.2. 使用 docker-compose help 1.3. todos demo 1.3.1. demo https://github.com/mingz2013/demo-todos-go-micro https://github.com/mingz2013/demo-todos-vue 1.3.2. 演示 展示todos demo的代码架构，项目里面的文档 本地演示用docker-compose实现单机部署 展示todos demo的控制台 http://localhost:8082 展示todos demo的vue前端 http://localhost:8082/todos/#/todos 展示进程scale。 "},"micros/docker-swarm.html":{"url":"micros/docker-swarm.html","title":"Docker Swarm","keywords":"","body":"1. Docker Swarm1.1. Docker Machine1.2. Docker Compose1.3. Docker Swarm1.4. Docker Node1.5. Docker Service1.6. Docker Stack1.7. Docker Network1.8. todos demo1.8.1. 演示1.9. 参考资料1.9.1. Books1.9.2. Sites Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Docker Swarm Docker Machine 创建 Docker 主机 Docker Swarm 配置集群节点 Docker Service 部署单个集群服务 Docker Stack 部署多个服务，以及 GUI 管理页面 docker-machine、docker swarm、docker node、docker service 和 docker stack 常用命令 1.1. Docker Machine Docker Machine是Docker官方编排项目之一，是一个简化Docker安装的命令行工具，可以帮助用户构建拥有Docker运行环境的虚拟机，并能够远程管理虚拟机及其里面的容器。 1.2. Docker Compose Docker Compose是Docker的一种编排服务，是一个用于在Docker上定义并运行复杂应用的工具，可以让用户在集群中部署分布式应用。通过Compose，用户可以很容易的用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker Compose解决了容器与容器之间如何管理编排的问题，适合开发和测试环境。 1.3. Docker Swarm Swarm是Docker公司在2014年12月初发布的一套较为简单的工具，用来管理Docker集群，它将一群Docker宿主机变成一个单一的，虚拟的主机，使用Swarm操作集群，会使用户感觉就像是在一台主机上进行操作。Swarm使用标准的Docker API接口作为其前端访问入口，换言之，各种形式的Docker Client都可以直接与Swarm通信。 1.4. Docker Node 1.5. Docker Service 1.6. Docker Stack stack 是构成特定环境中的 service 集合, 它是自动部署多个相互关联的服务的简便方法，而无需单独定义每个服务。 docker stack忽略构建命令，无法使用stack构建新镜像。 stack 是一组相互关联的服务，它是服务的上一层，这些服务共享依赖关系，并且可以一起编排和缩放。 单个 stack 能够定义和协调整个应用程序的功能，简单来说 stack 就是一组服务的集合。 1.7. Docker Network 1.8. todos demo https://github.com/mingz2013/demo-todos-go-micro 1.8.1. 演示 搭建单节点swarm集群 用栈部署todos demo 部署Portainer 用Portainer管理页面管理todos demo。 1.9. 参考资料 1.9.1. Books 《容器云运维实战：Docker与Kubernetes集群》 1.9.2. Sites https://www.portainer.io "},"micros/mesos.html":{"url":"micros/mesos.html","title":"Mesos","keywords":"","body":"1. Mesos Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Mesos Mesos项目是源自UC Berkeley的对集群资源进行抽象和管理的开源项目，类似于操作系统内核，使用它可以很容易的实现分布式应用的自动化调度。 同时，Mesos自身也很好的结合和主持了Docker等相关容器技术，基于Mesos已有的大量应用框架，可以实现用户应用的快速上线。 Twitter 宣布抛弃 Mesos 全面转向 Kubernetes "},"micros/k8s.html":{"url":"micros/k8s.html","title":"Kubernetes","keywords":"","body":"1. kubernetes1.1. 概念1.1.1. Helm1.2. 使用1.3. dashboard1.4. todos demo1.5. 参考资料1.5.1. GitHub1.5.2. WebSite1.5.3. Books Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. kubernetes 1.1. 概念 k8s业已称为容器编排领域事实上的标准 还要考虑集群管理，高可用，安全，持续集成等方方面面的问题。 这些关于容器集群管理的问题，其实就是容器编排的问题，即Kubernetes要解决的问题。 Kubernetes特性 自动装箱 自我修复 水平扩展 服务发现和负载均衡 自动发布和回滚 密钥和配置管理 存储编排 批量处理执行 1.1.1. Helm Kuberneres的安装包管理器，类似于yum，apt-get等 K8s类似于微服务层的操作系统，Helm类似于操作系统上的包管理器。 1.2. 使用 1.3. dashboard 1.4. todos demo TODO 1.5. 参考资料 1.5.1. GitHub https://github.com/kubernetes 1.5.2. WebSite https://kubernetes.io/ https://kubernetes.io/zh/docs/tutorials/ 1.5.3. Books 《每天5分钟玩转Kubernetes》 《Kubernetes进阶实战》 《基于Kubernetes的容器云平台实战》 "},"micros/helm.html":{"url":"micros/helm.html","title":"Helm","keywords":"","body":"1. Helm Title Date Modified Category Helm 2019-06-11 12:00 2019-06-11 12:00 micros 1. Helm Helm可大大简化应用管理的难度。 简单来说，Helm就是k8s的应用程序包管理器，类似于Linux操作系统上的yum或apt-get等，可用于实现帮助用户查找，分享及使用k8s应用程序，目前的版本由CNCF（Microsoft，Google，Bitnami和Helm社区）维护。它的核心打包功能组件称为chart，可以帮助用户创建，安装及升级复杂应用。 "},"micros/devops.html":{"url":"micros/devops.html","title":"DevOps","keywords":"","body":"1. DevOps Title Date Modified Category devops 2019-05-29 12:00 2019-05-29 12:00 micros 1. DevOps DevOps（Development & Operations）即开发运维一体化，可理解为软件研发的一种过程，方法，文化，运动或实践，主要是通过一条高度自动化的流水线来加强开发，测试，运维和其他部门之间的沟通和协作，加速产品和服务的交付。 "},"micros/openshift-3.html":{"url":"micros/openshift-3.html","title":"OpenShift 3","keywords":"","body":"1. OpenShift 31.1. 概念1.1.1. Red Hat1.1.2. OpenShift1.1.3. 混合云1.2. 演示1.3. todos demo1.4. 参考资料1.4.1. GitHub1.4.2. WebSite1.4.3. Books Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. OpenShift 3 1.1. 概念 1.1.1. Red Hat Red Hat就是开源软件商业模式的奠基人，而且是目前世界上最大的开源软件公司。 作为一个开源软件公司，red hat所有产品的企业版的源代码也是完全公开的。 Red Hat是Kubernetes, Istio的主要贡献者之一。 1.1.2. OpenShift OpenShift是一个开源容器云平台，是一个基于主流的容器技术Docker及Kubernetes构建的云平台。 通过OpenShift这个平台，企业可以快速在内部网络中构建出一个多租户的云平台，在这朵云上提供应用开发，测试，部署，运维的各项服务（如图1-2所示）。 OpenShift在一个平台上贯通开发，测试，部署，运维的流程，实现高度的自动化，满足应用持续集成及持续交付和部署的需求；满足企业及组织对容器管理，容器编排的需求。 通过OpenShift的灵活架构，企业可以以OpenShift作为核心，在其上搭建一个企业的DevOps引擎，推动企业的DevOps变革和转型。 容器引擎及容器编排组件是两项关键的技术，但还不能满足生产效率的要求。 OpenShift在Docker和k8s的基础上提供了各种功能，以满足业务应用，研发用户及运维用户在生产效率上的诉求。 应用开发框架及中间件 应用及服务目录 自动化流程及工具。 软件自定义网络 性能监控及日志管理 多用户接口 自动化集群部署及管理 OpenShift集成了原生的Kubernetes作为容器编排组件。OpenShift通过Kubernetes来管理容器集群中的机器节点及容器，为业务应用提供： 容器调度 弹性伸缩 异常自愈 持久化卷 服务发现 配置管理 K8s是一个容器编排工具，虽然提供了很多的功能，但只是一个工具。而OpenShift是一整套企业解决方案。 架构概览 核心组件 构建与部署自动化 CI/CD 企业部署 多环境单集群 多环境多集群 多数据中心 高可用 主控节点的高可用 度量与日志管理 度量采集 日志采集 1.1.3. 混合云 1.2. 演示 演示本地macos的OpenShift单节点集群 演示OpenShift的Web Dashboard 1.3. todos demo TODO 1.4. 参考资料 1.4.1. GitHub https://github.com/openshift 1.4.2. WebSite http://www.openshift.org https://www.okd.io/ 1.4.3. Books 《开源容器云OpenShift 构建基于Kubernetes的企业应用云》 "},"micros/serverless.html":{"url":"micros/serverless.html","title":"Serverless","keywords":"","body":"1. Serverless1.1. 概述1.2. 参考资料1.2.1. books Title Date Modified Category serverless 2019-06-11 12:00 2019-06-11 12:00 micros 1. Serverless 1.1. 概述 Serverless下包含的两个概念： 函数即服务，即Function as a Service，简称FaaS 后端即服务，即Backend as a Service，简称BaaS。 目前，Serverless平台主要分为三大类： 公有云上的功能即服务（Functions as a Service，FaaS）解决方案。 运行在共有和私有数据中心的Serverless框架，如Fission运行在Kubernetes上，Funktion运行在Kubernetes上，IBM OpenWhisk运行在Docker上。 提供agnostic应用接口或/和现有Serverless框架增值服务的包装框架，如Serverless.com支持AWS Lambda，Apex支持AWS Lambda。 Serverless适用场景: 应用负载变化显著的场景 基于事件驱动的算法服务化场景 基于事件驱动的数据分析服务化场景 基于事件驱动的数据服务化场景 低频请求场景 1.2. 参考资料 1.2.1. books 《基于Kubernetes的容器云平台实战》 "},"micros/istio.html":{"url":"micros/istio.html","title":"Istio","keywords":"","body":"1. Istio1.1. 概述1.1.1. Service Mesh1.1.2. Istio1.2. todos demo1.3. 参考资料1.3.1. GitHub1.3.2. WebSite1.3.3. Books Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Istio 1.1. 概述 1.1.1. Service Mesh 要讨论服务网格（Service Mesh），就必须提到微服务（Microservices）。 为了解决微服务架构产生的一些问题，以k8s为代表的容器云系统出现了。这类容器云系统以容器技术为基础，在进程级别为微服务提供了一致的部署，调度，伸缩，监控，日志等功能。 然而，除了进程本身的问题，微服务之间的通信和联系更加复杂，其中的观测，控制和服务质量等都成为微服务方案的短板，因此随着k8s成为事实标准，Service mesh顺势登场。 自Service Mesh技术诞生以来，国内外出现了很多产品，下面选择其中几个重要的产品和事件，大概理理Service Mesh相关产品的发展情况。 Buoyant公司的CEO William，曾经给出对服务网格的定义：服务网格是一个独立的基础设施层，用来处理服务之间的通信。 现代的云原生应用是由各种复杂技术构建的服务组成的，服务网格负责在这些组成部分之间进行可靠的请求传递。 目前典型的服务网格通常提供了一组轻量级的网络代理，这些代理会在应用无感知的情况下，同应用并行部署，运行。 Service Mesh主要功能： 负载均衡 服务发现 熔断 动态路由 安全通信 多语言支持 多协议支持 指标和分布式追踪 重试和最后期限 总结一下，Service Mesh实现了四大关键功能： 实现对基础设施的抽象化 为应用请求提供可靠传递 每个业务节点部署轻量级代理 透明化，应用程序无感知。 Service Mesh类似于更高级的一层网络栈。 k8s就是微服务级别的操作系统。 Helm是k8s的包管理工具，类似于yum，apt-get。 Sidecar 1.1.2. Istio 事实上的标准 2017年5月，Google，IBM和Lyft宣布了Istio的诞生。Istio以Envoy为数据平面，通过Sidecar的方式让Envoy同业务容器一起运行，并劫持其通信，接受控制平面的统一管理，在此基础上为服务之间的通信提供了丰富的连接，控制，观察，安全等特性。 Istio一经发布，便立刻获得Red Hat，F5等大牌厂商的响应，虽然立足不稳，但各个合作方都展示了对社区，行业的强大影响力。于是，Istio很快就超越了Linkerd，成为Service Mesh的代表产品。 这里将Istio的特性总结如下。 连接：对网格内部的服务之间的调用所产生的流量进行智能管理，并以此为基础，为微服务的部署，测试和升级等操作提供有力保障。 安全：为网络内部的服务之间的调用提供认证，加密和鉴权支持，在不侵入代码的情况下，加固现有服务，提高其安全性。 策略：在控制面定制策略，并在服务中实施 观察：对服务之间的调用进行跟踪和测量，获取服务的状态信息。 1.2. todos demo TODO 1.3. 参考资料 1.3.1. GitHub https://github.com/istio 1.3.2. WebSite https://istio.io/ https://istio.io/zh/docs/ 1.3.3. Books 《深入浅出Istio：Service Mesh快速入门与实践》 《基于Kubernetes的容器云平台实战》 "},"micros/openshift-4.html":{"url":"micros/openshift-4.html","title":"OpenShift 4","keywords":"","body":"1. OpenShift 41.1. 概述1.2. todos demo1.3. 参考资料1.3.1. GitHub1.3.2. WebSite1.3.3. Books Title Date Modified Category openshift 4 2019-05-29 12:00 2019-05-29 12:00 micros 1. OpenShift 4 1.1. 概述 集成了Istio 目前处于测试版本状态。 只提供了Linux上的测试部署方案。 1.2. todos demo TODO 1.3. 参考资料 1.3.1. GitHub 1.3.2. WebSite 1.3.3. Books "},"micros/rancher.html":{"url":"micros/rancher.html","title":"Rancher","keywords":"","body":"1. Rancher1.1. 演示1.2. 参考资料1.2.1. github1.2.2. website Title Date Modified Category Rancher 2019-06-10 12:00 2019-06-10 12:00 micros 1. Rancher 1.1. 演示 演示Rancher安装 Rancher管理macos上单节点k8s集群 1.2. 参考资料 1.2.1. github https://github.com/rancher/rancher 1.2.2. website https://rancher.com/ https://www.cnrancher.com/ https://www.cnrancher.com/docs/rancher/v2.x/cn/overview/ https://www.rancher.cn/ "},"micros/chaos-engineering.html":{"url":"micros/chaos-engineering.html","title":"Chaos Engineering","keywords":"","body":"1. Chaos Engineering Title Date Modified Category chaos 2019-05-29 12:00 2019-05-29 12:00 micros 1. Chaos Engineering 混沌工程 "},"micros/elk.html":{"url":"micros/elk.html","title":"ELK","keywords":"","body":"1. ELK1.1. 将日志输出到Docker容器外1.2. 使用Docker容器日志1.3. syslog Linux日志系统1.4. Docker 日志架构1.5. ELK1.5.1. 日志存储系统：Elasticsearch1.5.2. 日志收集系统：Logstash1.5.3. 日志查询系统：Kibana1.5.4. ELK 集成日志中心2. 参考资料2.1. books Title Date Modified Category ELK 2019-06-11 12:00 2019-06-11 12:00 micros 1. ELK 1.1. 将日志输出到Docker容器外 docker run -v ~/logs:~/logs hello 1.2. 使用Docker容器日志 docker logs 查看DOcker当前所设置的日志驱动类型，它是json-file。 docker info | grep 'Logging Driver' 我们进入/var/lib/docker/containers/目录，就会看到一个名为-json.log的文件，它就是我们要寻找的JSON日志文件了。 原来如此，当我们通过docker logs命令所看到的日志，实际上就是解析这个JSON日志文件后的输出。 既然应用程序的日志可以写入JSON文件中，那么也能写入其他日志驱动中，json-file只是Docker日志驱动的一种默认选项，Docker已为我们提供了大量的日志驱动类型。 none：容器不输出任何日志 json-file: 容器输出的日志以JSON格式写入文件中 syslog：容器输出的日志写入宿主机的Syslog中 journald：容器输出的日志写入宿主机的Journald中 gelf：容器输出的日志以GELF（Graylog Extended Log Format）格式写入Graylog中 fluentd：容器输出的日志写入宿主机的Fluentd中 awslogs：容器输出的日志写入Amazon CloudWatch Logs中 splunk：容器输出的日志写入splunk中 etwlogs：容器输出的日志写入ETW（Event Tracing for Windows）中 gcplogs：容器输出的日志写入GCP（Google Cloud Platform）中 nats：容器输出的日志写入NATS服务器中 我们可以在docker run命令中通过--log-driver参数来设置具体的Docker日志驱动，也可以通过--log-opt参数来指定对应日志驱动的相关选项。 就拿默认的json-file来说，其实可以这样启动docker容器： docker run -d -p 80:80 --log-driver json-file --log-opt max-size=10m --log-opt max-file=3 --name nginx nginx 在以上众多日志驱动类型中，最为常用的是Syslog，因为Syslog是Linux的日志系统，很多日志分析工具都可以从Syslog中获取日志，比如流行的ELK日志中心，它包括以下三个组件。 日志存储：由Elasticsearch负责 日志收集：由Logstash负责 日志查询：由Kinana负责 在ELK的三个组件中， Logstash用于收集日志，Syslog中写入的日志可转发到Logstash中， 随后将日志存入Elasticsearch中， 最后可通过Kibana来查询日志。 1.3. syslog Linux日志系统 默认情况下，Linux操作系统已安装了Syslog软件包，但它叫Rsyslog。实际上，Rsyslog是Syslog标准的一种实现。除了Rsyslog这一种实现，还有一种叫Syslog-ng的第三方实现。 查看命令 rsyslogd -v 开启Rsyslog服务： 编辑配置文件 vi /etc/rsylog.conf 重启服务 systemctl restart rsyslog 查看端口 netstat -anpt | grep 514 启动一个nginx容器，用syslog日志驱动 docker run \\ -d \\ -p 80:80 \\ --log-driver syslog \\ --log-opt syslog-address=tcp://localhost:514 \\ --log-opt tag=\"{{.ImageName}}/{{.Name}}/{{.ID}}\" \\ --name nginx \\ nginx tail -f /var/log/messages 1.4. Docker 日志架构 Docker 容器（Docker Container） 中的应用程序（Application） 将 日志写入到标准输出设备（STDOUT），Docker守护进程（Docker Daemon）负责从STDOUT中获取日志，并将日志写入对应的日志驱动中， 目前，应用程序中的日志已经从Docker容器内部成功写入宿主机的Syslog中，接下来我们要做的是，将Syslog中的日志转发到ELK平台的Logstash中，从而建立我们所需要的“应用日志中心”， 1.5. ELK 从Elastic公司的官网上，我们就能快速了解该公司所提供的产品，用官方的说法，叫“开源Elastic栈（Open Source Elastic Stack）”。 从官网上可知，Elastic官方推出了6款开源产品。 Kibana：用于数据可视化 Elasticsearch：用于数据搜索，分析与存储 Logstash：用于数据收集，将数据存入Elasticsearch中 Beats：用于数据传输，将数据从磁盘上传输到Logstash中 X-Pack：提供一些扩展功能，包括安全，预警，监控，报表，图形化等 Elastic Cloud：提供Elastic栈的云服务，提供公有云与私有云解决方案 1.5.1. 日志存储系统：Elasticsearch Elasticsearch是一个可高度扩展的开源全文搜索与分析引擎，它可以帮助我们快速的存储，搜索与分析大规模的实时数据。Elasticsearch的底层基于开源搜索引擎Lucene，并在此基础上提供了一系列便于应用程序使用的REST API，并且还提供了先天性的集群能力，可自由水平扩展以支持日益增长的数据。 通过Docker容器启动Elasticsearch： docker run \\ --rm \\ -p 9200:9200 \\ --name elasticsearch \\ elasticsearch 1.5.2. 日志收集系统：Logstash Logstash是一款开源的数据收集引擎，它既提供了实时管道能力，也提供了灵活的插件机制，我们可以自由选择已有的插件，也能自行开发所需的插件。我们使用Logstash更多的时候都是在做参数配置，以实现我们所需的功能。 1.5.3. 日志查询系统：Kibana Kibana是一个开源的基于Elasticsearch的分析与可视化平台，我们既可用它来查看并搜索存储在Elasticsearch中的数据，也可用它来制作各式各样的图表，表格，地图等图形化数据。 1.5.4. ELK 集成日志中心 2. 参考资料 2.1. books 《架构探险：轻量级微服务架构（下册）》 "},"micros/efk.html":{"url":"micros/efk.html","title":"EFK","keywords":"","body":"1. EFK1.1. Elasticsearch1.2. 日志采集代理fluentd1.3. Kibana Title Date Modified Category ELK 2019-06-11 12:00 2019-06-11 12:00 micros 1. EFK 一种流行的开源解决方案是将fluentd作为节点级代理程序进行日志采集，并将之聚合存储于Elasticsearch进行日志分析，以及通过Kibana进行数据可视化。这种组合通常简称EFK。 1.1. Elasticsearch 1.2. 日志采集代理fluentd fluentd是一个开源的数据收集器，基于C和Ruby语言开发，它目前有数百种以Ruby Gem形式独立存在的可选插件，用于连接多种数据源和数据输出组件等，如fluent-plugin-elasticsearch插件用于实现将采集到的数据发送给Elasticsearch。 1.3. Kibana Kibana是Elasticsearch的数据分析及可视化平台，能够用来搜索，查看存储在Elasticsearch索引中的数据。 "},"micros/monitoring.html":{"url":"micros/monitoring.html","title":"Monitoring","keywords":"","body":"1. Monitoring1.1. 时序数据收集系统：cAdvisor1.2. 时序数据存储系统：InfluxDB1.3. 时序数据分析系统：Grafana1.4. 集成InfluxDB+cAdvisor+Grafana 系统监控平台2. 参考资料2.1. books Title Date Modified Category Monitoring 2019-06-11 12:00 2019-06-11 12:00 micros 1. Monitoring 下面我们要做的就是搭建一个微服务系统监控中心，该平台会不断收集每个微服务所在DOcker容器中随时间变化的数据（简称“时序数据”），包括CPU，内存，网络，磁盘等使用情况。 我们同样也需要使用一系列开源技术来搭建这款系统监控中心，该平台首先会从DOcker容器中收集相关时序数据，随后会将这些时序数据存入一个时序数据库中，最后通过一个Web应用程序以图表的方式来展示并分析这些时序数据。 可见，系统监控中心包括了三个系统，即时序数据收集系统，时序数据存储系统，时序数据分析系统，这三个系统需要天然无缝的整合在一起。 经过一番调研后决定使用cAdvisor实现时序数据收集，使用InflusDB实现时序数据存储系统，使用Grafana实现时序数据分析。 1.1. 时序数据收集系统：cAdvisor cAdvisor是Google推出的一款基于Go语言的开源产品，它用于分析DOcker容器在运行中的资源使用与性能特征。cAdvisor使用起来非常简单，我们可以通过启动Docker容器的方式来运行它，当它运行后即可监控当前宿主机中所有Docker容器的运行状况。 docker run \\ -d \\ -p 8080:8080 \\ -v /:/rootfs \\ -v /var/run:/var/run \\ -v /sys:/sys \\ -v /var/lib/docker:/var/lib/docker \\ --name=cadvisor \\ google/cadvisor cAdvisor提供了一个Web控制台，以便于我们通过图形化的方式来查看它所收集的时序数据，我们可在浏览器上通过8080端口来访问该控制台。 cAdvisor还提供了一套REST API，我们可通过浏览器，Postman客户端，应用程序来访问它的REST API。我们可利用cAdvisor所提供的REST API自行封装客户端API，这样更有利于程序开发，官方也提供了一个基于Go语言的客户端API。 cAdvisor虽然使用起来非常方便，通过它自带的Web控制台也能基本满足我们的监控需求，但仍然存在以下两个问题。 只能监控当前宿主机的运行状况，如何监控远程主机呢？ 只能看到当前一段时间内的时序数据，如何长期存储呢？ 1.2. 时序数据存储系统：InfluxDB InfluxDB是InfluxData公司的产品之一，它是一款开源产品，用于存储相应的时序数据。由于时序数据是随时间变化而产生的，每分每秒（甚至每毫秒）都会产生相应的数据，而且这个数据量还会不断积累，最终将形成一个庞大的数据集。InfluxDB天生就用来存储这些大数据，同时还能对外提供高效的数据查询功能。 当然，我们依旧使用docker run的方式启动InfluxDB容器。 docker run \\ -d \\ -p 8086:8086 \\ -v ~/influxdb:/var/lib/influxdb \\ --name influxdb \\ influxdb 进入容器内部，执行influx命令，来启动一个命令行客户端。 docker exec -it influxdb influx 1.3. 时序数据分析系统：Grafana Grafana是一款基于Web的开源时序数据分析软件，它的功能十分强大，界面非常专业且相当易用。它能无缝对接InfluxDB数据源，非常轻松愉快的就能将我们带入数据可视化的世界。 docker run \\ -d \\ -p 3000:3000 \\ -v ~/grafana:/var/lib/grafana \\ --name grafana \\ grafana/grafana 1.4. 集成InfluxDB+cAdvisor+Grafana 系统监控平台 InfluxDB，cAdvisor，Grafana集成在一起，它们三个系统的组合将构成一个完整的系统监控平台。 InfluxDB是存放时序数据的中心，cAdvisor将时序数据存入InfluxDB，Grafana从InfluxDB中获取时序数据。 启动InfluxDB容器 启动cAdvisor容器 启动Grafana容器 2. 参考资料 2.1. books 《架构探险：轻量级微服务架构（下册）》 "},"micros/prometheus.html":{"url":"micros/prometheus.html","title":"Prometheus","keywords":"","body":"1. Prometheus1.1. k8s上的集群监控方案1.2. Prometheus1.3. Prometheus Operator2. 参考资料2.1. books Title Date Modified Category Prometheus 2019-06-11 12:00 2019-06-11 12:00 micros 1. Prometheus k8s上的集群监控方案 1.1. k8s上的集群监控方案 Weave Scope可以展示集群和应用的完整视图。其出色的交互性让用户能够轻松对容器化应用进行实时监控和问题诊断。 Heaspter是k8s原生的集群监控方案。预定义的Dashboard能够从Cluster和Pods两个层次监控k8s。 Prometheus Operator可能是目前功能最全面的k8s开源监控方案。除了能监控Node和Pod，还支持集群的各种管理组件，比如API Server，Scheduler，Controller Manager等。 1.2. Prometheus 因为Prometheus Operator是基于Prometheus的，所以我们需要先了解一下Prometheus。 Prometheus是一个非常优秀的监控工具。准确的说应该是监控方案。Prometheus提供了数据搜集，存储，处理，可视化和告警一套完整的解决方案。Prometheus的架构如图14-31所示。 官网上的原始架构图比上面这张要复杂一些，为了避免注意力分散，这里只保留了最重要的组件。 Prometheus Server Exporter 可视化组件 Alertmanager 1.3. Prometheus Operator Prometheus Operator的目标是尽可能简化在K8s中部署和维护Prometheus的工作，其架构如图14-32所示。 图中每一个对象都是k8s中运行的资源。 Operator Prometheus Server Service ServiceMonitor Alertmanager 2. 参考资料 2.1. books 《每天5分钟玩转Kubernetes》 "},"micros/zipkin.html":{"url":"micros/zipkin.html","title":"Zipkin","keywords":"","body":"1. Zipkin1.1. 微服务监控方案1.2. Zipkin1.3. Span1.4. Trace1.5. Reporter2. 参考资料2.1. books Title Date Modified Category Zipkin 2019-06-11 12:00 2019-06-11 12:00 micros 1. Zipkin Zipkin是Twitter公司开源的一款调用追踪中心（也称为分布式追踪系统），它可以帮助我们收集分布式系统中每个组件所花费的调用时长，并通过图形化界面的方式来展现整个调用链依赖关系，还能展现调用每个组件所花费的时长。 1.1. 微服务监控方案 1.2. Zipkin Zipkin在系统设计上参考了Google Dapper，它是Google公司内部所使用的大规模分布式系统追踪基础设施。 可以毫不夸张的说，Zipkin是开源社区中调用追踪中心的首选方案，我们可从Zipkin官网上了解更多关于它的相关介绍与使用方法。 使用Zipkin之前，我们有必要学习它的几个核心概念。 1.3. Span 是调用一个组件所经历的一段过程，也就是说，从请求组件开始，直到组件响应为止，在这段过程中会花费一定的时间，这是一个时间跨度，所以我们形象的将其称为Span。 1.4. Trace Trace指的是从客户端发出请求，直到完成整个内部调用的全部过程，我们将这个过程称为一次追踪，Trace就是这次追踪过程。 1.5. Reporter 我们需要将Span与Trace所产生的追踪数据推送至Zipkin中，因此需要在相关的组件中安置一个客户端，它用于收集这些追踪数据并将它们报告给Zipkin，我们将这个客户端称为Reporter。 只有被Reporter装配的（Instrumented）组件才能通过Transport向Zipkin发送数据，随后通过COllector进行数据收集，并通过Storage进行数据存储（可将数据持久化到Database中）。 此后，可通过API（Query Service）来查询Storage中的数据，并通过一个UI（Web UI）来展示Trace与Span的调用链及其相关数据。 可以把Transport理解为一个数据传输方式，Zipkin提供了多种主要方式。最简单的情况下，可通过HTTP来传输数据，在并发量较高的情况下，可通过Kafka或Scribe来传输数据，可起到数据缓冲的作用，提高了整个调用追踪中心的吞吐率。 Kafka是一个Apache开源的一款分布式消息系统，Scribe是Facebook开源的一款日志收集系统。 下面，开始进入Zipkin的内部来学习它的系统架构。 Collector Storage Query Service Web UI 2. 参考资料 2.1. books 《架构探险：轻量级微服务架构（下册）》 "},"ops/":{"url":"ops/","title":"ops","keywords":"","body":" Title Date Modified Category ops 2019-06-11 12:00 2019-06-11 12:00 ops Ansible "},"ops/ansible.html":{"url":"ops/ansible.html","title":"ansible","keywords":"","body":"1. Ansible1.1. Ansible的特性与框架 Title Date Modified Category ansible 2019-06-11 12:00 2019-06-11 12:00 ops 1. Ansible Ansible就是一个简单的自动化运维工具。 现在，成熟的自动化运维工具已经有了不少，比如Ansible，Puppet，Cfengine，Chef，Func，Fabric。 Ansible是一款由Python编程语言开发，基于SSH远程通信的自动化运维工具， 1.1. Ansible的特性与框架 对于Ansible的特性主要有如下几个： 不需要在被管控主机上安装客户端 无服务端，使用时直接运行命令即可 基于模块工作，可使用任意语言开发模块 使用yaml语言定制编排剧本playbook 基于SSH远程通信协议 可实现多级指挥 支持sudo 基于python语言，管理维护简单 支持邮件，日志等多种功能。 "},"hack/":{"url":"hack/","title":"hack","keywords":"","body":" Title Date Modified Category js 2019-06-14 12:00 2019-06-14 12:00 hack JS代码加密 "},"hack/js代码加密.html":{"url":"hack/js代码加密.html","title":"JS代码加密","keywords":"","body":"1. js代码加密 Title Date Modified Category js 2019-06-14 12:00 2019-06-14 12:00 hack 1. js代码加密 这里的js代码加密指的是客户端js代码的加密，包括运行在浏览器中的js，和运行在v8等js引擎中的js。 js在客户端执行，很容易被破解，找到源码。所以js代码的加密也成了一个研究的课题。 加密方式总结： 破坏代码的可读性 也就是代码混淆，使之不可读，增加破解的成本 加逻辑炸弹 如指定运行的域名，非指定域名的情况下做一些破坏性操作等。 与服务器端强交互 与服务器端频繁交互，或将一些代码放到服务端动态加载。 WebAssembly 这是一个比较新的技术，目前用的很少，不过主流浏览器都有支持。 "},"tools/":{"url":"tools/","title":"Tools","keywords":"","body":" Title Date Modified Category tools 2019-06-11 12:00 2019-06-11 12:00 tools gitbook "},"tools/gitbook.html":{"url":"tools/gitbook.html","title":"gitbook","keywords":"","body":"1. Gitbook Title Date Modified Category gitbook 2019-06-11 12:00 2019-06-11 12:00 tools 1. Gitbook 流程图插件 https://github.com/knsv/mermaid "},"opengl/":{"url":"opengl/","title":"OpenGL","keywords":"","body":" Title Date Modified Category opengl 2019-06-06 12:00 2019-06-06 12:00 opengl "},"cocos/":{"url":"cocos/","title":"Cocos","keywords":"","body":" Title Date Modified Category cocos 2019-07-11 12:00 2019-07-11 12:00 cocos "},"unity/":{"url":"unity/","title":"Unity","keywords":"","body":" Title Date Modified Category unity 2019-06-06 12:00 2019-06-06 12:00 unity "}}