{"./":{"url":"./","title":"Introduction","keywords":"","body":"之前的 blog项目实在不好用，以后的笔记都转移到这里来 本书地址 http://mingz.me/note/ 本书github https://github.com/mingz2013/note 本书讨论区 https://github.com/mingz2013/note/issues 看的书很多，但是本人实在健忘。 最近将一些学过的东西，系统整理出来，便于后续查阅复习。 还有就是，将所学到的东西整理出来，也是一个给外界展示自己的机会，否则知识永远躺在印象笔记里，别人也不知道。 "},"every-day-use/":{"url":"every-day-use/","title":"every day use","keywords":"","body":"1. every day use Title Date Modified Category every day use 2019-06-06 12:00 2019-06-06 12:00 every day use 1. every day use mongo redis docker k8s golang python nodejs adb git svn ctf wireshark nmap shell macos brew sublime vscode vim markdown jetbrains unity chrome "},"every-day-use/mongo.html":{"url":"every-day-use/mongo.html","title":"mongo","keywords":"","body":"1. mongo1.1. use in macos1.2. use in centos 71.2.1. 使用1.3. client1.4. tools Title Date Modified Category mongo 2019-06-06 12:00 2019-06-06 12:00 every day use 1. mongo 1.1. use in macos brew install mongo brew services start mongodb brew services stop mongodb mongod --config /usr/local/etc/mongod.conf 1.2. use in centos 7 vim /etc/yum.repos.d/mongodb-org-4.0.repo ```repo [mongodb-org-4.0] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.0/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-4.0.asc - `yum install mongodb-org` - `systemctl restart mongod.service` ## 开启验证 ### 配置 ```conf // /etc/mongod.conf # Run with/without security (without by default) #auth = true #noauth = true 1.2.1. 使用 use spider db.createUser({user:”spider\",pwd:\"spider2016\",roles:[{role:\"dbOwner\",db:\"spider\"}]}) db.auth(spider, spider2016) 1.3. client mongo show dbs use testDBName show collections db.dropDatabase() // 删除数据库 db.pUser.remove({'role':'admin'}) db.bankUser.drop() db.users.find({'id':1}, {'_id':0, 'name':1}) db.users.find({'_id':ObjectId('5cf65f785568e41dbaf66ee6')}) db.post.update({}, {$rename:{url:'site'}}) // 字段改名 db.collection.ensureIndex({a:1}) // 创建索引 db.collection.find({a:5, b:3,c:{$lt:2},d:{$gt:4}}).sort({c:1}) 1.4. tools mongodump -h dbhost -d dbname -o dbdir mongostore -h dbhost -d dbname --directoryerdb dbdir mongoexport --csv -f company_name,item_category,site -d dbName -c collectionName -q '{\"item_category_num\":102}' -o 102.csv mongoimport --db dbName --collection collectionName --file file.json "},"every-day-use/redis.html":{"url":"every-day-use/redis.html","title":"redis","keywords":"","body":"1. redis1.1. use in macos1.2. client Title Date Modified Category redis 2019-06-06 12:00 2019-06-06 12:00 every day use 1. redis 1.1. use in macos brew install redid brew services start redis redis-server /usr/local/etc/redis.conf 1.2. client redis-cli #连接redis服务器 select 1 # 选择数据库 keys * # 查看指定的key type gamedata # 查看指定key的类型 flushdb # 清空数据库 set event_id 1 set user_id 1 GET key hlen db "},"every-day-use/docker.html":{"url":"every-day-use/docker.html","title":"docker","keywords":"","body":"1. Docker1.1. cmd1.2. docker-compose Title Date Modified Category docker 2019-06-06 12:00 2019-06-06 12:00 every day use 1. Docker https://docs.docker.com/ 1.1. cmd docker help docker search 从镜像源搜索软件 docker pull 从镜像源拉取软件 docker images 显示镜像列表 docker ps 显示容器列表 docker run 运行镜像为容器 docker start 启动容器 docker stop 停止运行中的容器 docker rm 删除容器 docker rmi 删除镜像 docker login mingz2013 password # 这里是用户名，不是邮箱 docker run -d consul # -d 后台执行 docker run -d -i -t centos /bin/bash # -d 后台运行 docker exec -it containerID /bin/bash docker attach docker rm $(docker ps -a -q) # 删除容器 docker rmi -f $(docker images -q) # 删除镜像 --link 链接一个容器，起一个别名，在容器内部可用别名访问 1.2. docker-compose docker-compose 的 --links 参数也一样 docker-compose version docker-compose up docker-compose down docker-compose start docker-compose stop docker-compose restart docker-compose pause docker-compose unpause docker-compose build docker-compose create docker-compose images docker-compose pull docker-compose push docker-compose ps docker-compose logs docker-compose exec docker-compose config # 确认并展示compose file docker-compose events docker-compose kill docker-compose rm docker-compose run docker-compose scale #缩放服务个数 docker-compose scale todos-srv=2 WARNING: The scale command is deprecated. Use the up command with the --scale flag instead. docker-compose up -d --scale todos-api=3 docker-compose up -d --scale todos-srv=2;todos-api=3 "},"every-day-use/k8s.html":{"url":"every-day-use/k8s.html","title":"k8s","keywords":"","body":" Title Date Modified Category k8s 2019-06-06 12:00 2019-06-06 12:00 every day use kubectl run kubectl expose kubectl annotate kubectl autoscale kubectl convert kubectl create kubectl create clusterrole kubectl create clusterrolebinding kubectl create configmap kubectl create deployment kubectl create namespace kubectl create poddisruptionbudget kubectl create quota kubectl create role kubectl create rolebinding kubectl create service kubectl create secret kubectl delete kubectl edit kubectl label kubectl patch kubectl replace kubectl rolling-update kubectl rollout kubectl scale kubectl set "},"every-day-use/golang.html":{"url":"every-day-use/golang.html","title":"golang","keywords":"","body":" Title Date Modified Category golang 2019-06-06 12:00 2019-06-06 12:00 every day use go get github.com/xxx/xxx 安装包 go get -u github.com/xxx/xxx 更新 go doc http.ListenAndServe 查看doc go run xxx.go 直接编译执行go go build xxx.go 编译 go install CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build # 交叉编译 "},"every-day-use/python.html":{"url":"every-day-use/python.html","title":"python","keywords":"","body":" Title Date Modified Category 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/nodejs.html":{"url":"every-day-use/nodejs.html","title":"nodejs","keywords":"","body":" Title Date Modified Category nodejs 2019-06-06 12:00 2019-06-06 12:00 every day use node install -g gitbook 安装gitbook全局的 npm install -g gitbook-cli "},"every-day-use/adb.html":{"url":"every-day-use/adb.html","title":"adb","keywords":"","body":" Title Date Modified Category adb 2019-06-06 12:00 2019-06-06 12:00 every day use adb shell adb logcat adb install adb uninstall com.xiuxayo.numbers_blast adb install -r final.apk adb shell am start -n com.xiuxayo.numbers_blast/com.xiuxayo.numbers_blast.MainActivity https://apkpure.com/cn/ good way to download apk from google play app store. 拷贝文件 adb push adb pull "},"every-day-use/git.html":{"url":"every-day-use/git.html","title":"git","keywords":"","body":" Title Date Modified Category idapro 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/svn.html":{"url":"every-day-use/svn.html","title":"svn","keywords":"","body":" Title Date Modified Category 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/ctf.html":{"url":"every-day-use/ctf.html","title":"ctf","keywords":"","body":"1.1. python Title Date Modified Category ctf 2019-06-06 12:00 2019-06-06 12:00 every day use 1.1. python ord(c) # 参数是长度为1的字符串，简称字符。当参数为统一对象时（unicode object），返回能代表该字符的统一编码，当参数为8比特的字符串时，返回该字节的值。例如ord(‘a’) 返回整形数值97，ord(u’\\u2020’)返回8224. chr(i) # 返回一个字符，字符的asc2码等于参数中的整形数值。如chr(97)返回字符’a’ , 该方法是 ord 的反方法。参数必须是0-255的整形数值，否则会抛出valueError错误。 hex() # str() # "},"every-day-use/wireshark.html":{"url":"every-day-use/wireshark.html","title":"wireshark","keywords":"","body":" Title Date Modified Category wireshark 2019-06-06 12:00 2019-06-06 12:00 every day use ip.src==192.168.1.102 // 过滤源ip ip.src==192.168.1.102 and http // 过滤源ip和http协议 ip.src==192.168.1.100 or ip.dst==192.168.1.100 (ip.src==192.168.1.101 or ip.dst==192.168.1.101 or ip.src==192.168.1.100 or ip.dst==192.168.1.100 or ip.dst==192.168.1.107 or ip.src==192.168.1.107) wireshark抓取的pcapng文件 wireshark打开 File->export objects->http->save all 导出所有http请求到文件夹 过滤文件 读取文件 "},"every-day-use/nmap.html":{"url":"every-day-use/nmap.html","title":"nmap","keywords":"","body":" Title Date Modified Category nmap 2019-06-06 12:00 2019-06-06 12:00 every day use nmap -sS -Pn -A 192.168.20.1/24 80-8000 "},"every-day-use/shell.html":{"url":"every-day-use/shell.html","title":"shell","keywords":"","body":"1. 相关资料2. 帮助2.1. 安装man手册中文3. 文件目录操作3.1. 查找目录3.2. 展示目录3.3. du查看某个文件或目录占用磁盘空间的大小3.4. 分割文本文件，为多个小文件4. 按每个文件1000行来分割除5. 按照每个文件100K来分割6. 文本操作6.1. 查看文本文件 内容6.2. 操作命令6.3. 查询日志6.4. 根据每行的空格分割6.5. 去除重复行6.6. 查找非重复行6.7. 查找重复行6.8. 统计7. 后台执行8. 刻盘9. 压缩解压9.1. 压缩（compress）：9.2. 解压操作:10. tar -zxvf /usr/local/auto_bak/test.tar.gz11. where which12. 日期13. 时间14. 用户与权限14.1. 用户管理14.2. chmod 权限解读14.3. 进程管理14.4. 网络相关15. 网络抓包分析16. 系统信息查看17. 远程连接操作18. 拷贝本地文件(夹)到远程服务器，只需要将后面两个参数反过来就可以19. 两个网络命令20. telnet21. 跟踪系统调用22. purge23. 3个常用基于Linux系统命令行WEB网站浏览工具（w3m/Links/Lynx)24. 特殊问题24.1. jq24.2. sed Title Date Modified Category shell 2019-06-06 12:00 2019-06-06 12:00 every day use 1. 相关资料 http://linuxtools-rst.readthedocs.io/zh_CN/latest/index.html 2. 帮助 man # 手册 man ls ls --help 2.1. 安装man手册中文 yum list | grep man | grep page yum install man-pages yum install man-pages-zh-CNalias cman=‘man -M /usr//share/man/zh_CN'man poll cman poll 3. 文件目录操作 ln -s filename sy_file # 建立软连接 # rm -rf dir # 删除目录 3.1. 查找目录 find . -name “poker” find . -name xz find . -name \"*.[c|h]\" 3.2. 展示目录 ls -l ls -h # 转换kb -> MB 3.3. du查看某个文件或目录占用磁盘空间的大小 du -ah —max-depth=1 du -d 1 -h # mac 这个是我想要的结果a表示显示目录下所有的文件和文件夹（不含子目录）， h表示以人类能看懂的方式， max-depth表示目录的深度。 for i in *; do mv \"$i\" \"$i.txt\"; done # 批量加后缀 for i in qianlima_*; do mv “$i\" \"$i.csv\"; done ls | grep ping | grep log | while read line; do wc -l $line;done; 3.4. 分割文本文件，为多个小文件 split 参数： -b ：后面可接欲分割成的档案大小，可加单位，例如 b, k, m 等； -l ：以行数来进行分割； 4. 按每个文件1000行来分割除 split -l 1000 httperr8007.log http httpaa，httpab，httpac ........ 5. 按照每个文件100K来分割 split -b 100k httperr8007.log http httpaa，httpab，httpac ........ 6. 文本操作 6.1. 查看文本文件 内容 cat more less tail head tail -f server.log # 实时查看日志 6.2. 操作命令 grep awk sed Ack Ag grep -A 10 -B 10 ‘Traceback' log/log.log # 显示 traceback 和 前十行 和 后十行 grep -C 10 ’Traceback’ log/log.log # 等价于上一行， -A 10 -B 10 grep “ERROR” log/2016-05-06.log | awk -F '' '{print $1}' | awk '{print $2}' | grep 'jd' | grep 'list' grep python | wc -l 查看日志条数 grep -r ‘123’ . 查找当前目录下所有文件 包含 123 的 行 6.3. 查询日志 find . -name GT712*06_04 | xargs grep ‘Majiang2.saveRecord ok' | grep '440392' 6.4. 根据每行的空格分割 (cat 3.txt | awk ‘{print $1}' && cat 3.txt | awk '{print $2}' && cat 3.txt | awk '{print $3}' && cat 3.txt | awk '{print $4}' && cat 3.txt | awk '{print $5}' | cat 3.txt | awk '{print $6}' | cat 3.txt | awk '{print $7}') | sort | uniq | wc -l (cat 4.txt | awk '{print $2}' | sort | uniq && cat 4.txt | awk '{print $4}' | sort | uniq && cat 4.txt | awk '{print $6}' | sort | uniq && cat 4.txt | awk '{print $6}' | sort | uniq && cat 4.txt | awk '{print $8}' | sort | uniq && cat 4.txt | awk '{print $10}' | sort | uniq && cat 4.txt | awk '{print $12}' | sort | uniq && cat 4.txt | awk '{print $14}' | sort | uniq && cat 4.txt | awk '{print $16}' | sort | uniq && cat 4.txt | awk '{print $18}' | sort | uniq && cat 4.txt | awk '{print $20}' | sort | uniq) | sort | uniq grep 'comId' json.txt | awk -F '\"' '{print $4}' | sort | uniq -c | wc -l grep “MONGO\" 1.txt | awk -F '' '{print $2}' > 2.txt 6.5. 去除重复行 sort file |uniq6.6. 查找非重复行 sort file |uniq -u6.7. 查找重复行 sort file |uniq -d6.8. 统计 sort file | uniq -c cat 3.txt | sort | uniq 去除重复行 cat 1.txt | sort | uniq | wc -l 统计非重复行数量7. 后台执行 nohup pypy modify.py # 后台执行命令 pypy modify.py & # 后台运行命令 命令后加 & command & ： 后台运行，你关掉终端会停止运行 nohup command & ： 后台运行，你关掉终端也会继续运行 8. 刻盘 刻盘：dd if=./Windows10.iso of=/dev/sdc 9. 压缩解压 /usr/local/test tar -cvf /usr/local/auto_bak/test.tar /usr/local/test 仅打包，不压缩 tar -zcvf /usr/local/auto_bak/test.tar.gz /usr/local/test 打包后，以gzip压缩 在参数f后面的压缩文件名是自己取的，习惯上用tar来做，如果加z参数，则以tar.gz 或tgz来代表gzip压缩过的tar file文件 9.1. 压缩（compress）： tar -zcvf /usr/local/auto_bak/test.tar.gz /usr/local/test9.2. 解压操作: 10. tar -zxvf /usr/local/auto_bak/test.tar.gz tar zxvf demo.tar.gz -C demo-dir # 解压到指定目录，前提是目录事先存在 11. where which which pip # 查看pip路径位置 whereis python which pypy | xargs ls -l -G 12. 日期 date +“%Y-%m-%d %H:%M.%S\" date +”%Y%m%d\" --date='1 days ago' 13. 时间 time可统计命令运行时间 time pypy main.py 14. 用户与权限 那就是sudo su 或者sudo -sH 默认缺省为获取root 用户 14.1. 用户管理 useradd name userdel name cat /etc/passwd chown #更改文件所有者 chown tyhall-difang:tyhall-difang -R . chmod #更改文件权限 drwxr-xr-x 7 zhaojm staff 238 Jun 26 19:30 go/ chmod 777 filename 三个标志位， 所有者，用户组，其他用户 每个标志位三个二进制位 读，写，执行 14.2. chmod 权限解读 二、chmod整个命令的形式的用法如下： sudo chmod -（代表类型）×××（所有者）×××（组用户）×××（其他用户） 三位数的每一位都表示一个用户类型的权限设置。取值是0～7，即二进制的[000]~[111]。 这个三位的二进制数的每一位分别表示读、写、执行权限。 如000表示三项权限均无，而100表示只读。这样，我们就有了下面的对应： 0 [000] 无任何权限 4 [100] 只读权限 6 [110] 读写权限 7 [111] 读写执行权限 要求就是： 1、将当前目录中的所有“子目录”的权限设置为755； 2、将当前目录中的所有“文件”的权限设置为644。 解决方法： chmod 644 -R * chmod 755 find -type d 也可以用： 用find彻底些 find /path -type f -exec chmod 644 {} /; find /path -type d -exec chmod 755 {} /; 1060 chmod 664 -R log37 1061 chmod 775 find log37 -type d 14.3. 进程管理 kill -9 3719 # 杀死3719 PID 进程 ps -ef ps -aux | grep python ps -aux | grep phantomjs | awk '{print $2}' | while read line; do kill -9 $line; done ps -A | grep pypy | awk ‘{print $1}’ | xargs kill -9 14.4. 网络相关 netstat -ntlp -n 显示所有选项 -t 只显示tcp连接 -l 只显示listen -p 将program name 附加到 PID后面 lsof -i:80 查看80端口占用情况 netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' 查看网络负载 15. 网络抓包分析 tcpdump tshark 16. 系统信息查看 dmidecode # 查看系统信息 top 查看cpu利用率 iostat 查看io df -hl 查看磁盘 env # 查看当前环境变量 cat /etc/redhat-release 17. 远程连接操作 ssh root@192.168.2.22 #ssh 登录服务器 scp root@www.baidu.com:/home/root/test.txt ./#拷贝远程服务器文件到本地 scp -r root@www.baidu.com:/home/root/myfloder ./ # 拷贝远程服务器文件夹到本地18. 拷贝本地文件(夹)到远程服务器，只需要将后面两个参数反过来就可以 rsync -aupv root@192.168.1.11:/home/test.log /home # 相比scp稳定，速度快 rsync 用于拷贝数据 19. 两个网络命令 socat ,可用于绑定一个程序到一个端口 nc socat tcp-listen:8888, exec:ipython,pty,stderr # 将一个程序转发到一个端口 socat tcp-listen:8888,fork exec:ipython,pty,stderr # 支持并发 socat tcp-listen:8888,fork exec:bash,pty,stderr 20. telnet 退出 ^] ctrl+] 21. 跟踪系统调用 strace strace ls 22. purge 释放内存空间， 系统会自以为是的缓存一些应用，以为你会再次打开 23. 3个常用基于Linux系统命令行WEB网站浏览工具（w3m/Links/Lynx) 24. 特殊问题 我需要在 服务器上 通过 sudo su - tyhall-difang 切换到tyhall-difang 用户，怎么scp tyhall-difang用户下的文件到本地 1 tyhall-difang用户下，chmod 755 /home/tyhall-difang 改为其他人可读可进 2 tyhall-difang用户下拷贝文件到/tmp/目录下 dig DNS查询 adb install ..apk adb install -r 覆盖安装 adb logcat 看日志 压缩所有文件和目录，单独压缩 ls -l | awk '{print $9}' | awk -F '/' '{print $1}'| while read i; do tar -zcvf $i.tar.gz $i;done; 24.1. jq jq json处理工具,shell工具 https://stedolan.github.io/jq/ https://stedolan.github.io/jq/tutorial/ jq . 24.2. sed "},"every-day-use/macos.html":{"url":"every-day-use/macos.html","title":"macos","keywords":"","body":" Title Date Modified Category macos 2019-06-06 12:00 2019-06-06 12:00 every day use command + k 清空terminal屏幕消息 terminal中的复制粘贴 shift ctrl c shift ctrl v 退出telnet ctrl + ] "},"every-day-use/brew.html":{"url":"every-day-use/brew.html","title":"brew","keywords":"","body":"1. brew Title Date Modified Category brew 2019-06-06 12:00 2019-06-06 12:00 every day use 1. brew brew update brew outdated brew upgrade brew upgrade; brew cleanup brew services brew services list brew services start redis brew services stop mongodb brew install redis "},"every-day-use/sublime.html":{"url":"every-day-use/sublime.html","title":"sublime","keywords":"","body":" Title Date Modified Category sublime 2019-06-06 12:00 2019-06-06 12:00 every day use command + shift + p // 打开命令快捷键 set syntax:json // 设置json格式解析 format:javascript // 以js格式化 "},"every-day-use/vscode.html":{"url":"every-day-use/vscode.html","title":"vscode","keywords":"","body":" Title Date Modified Category vscode 2019-06-06 12:00 2019-06-06 12:00 every day use command + shift + p command + p command + shift + N 打开新窗口 command + N 新建文件 "},"every-day-use/vim.html":{"url":"every-day-use/vim.html","title":"vim","keywords":"","body":" Title Date Modified Category vim 2019-06-06 12:00 2019-06-06 12:00 every day use shell命令 :命令模式 :Sex! \"左右分割窗口，在左侧打开文件浏览器 :Sex “上下分割窗口，在上面打开文件浏览器 :vsplit, :new, :split \"分割窗口 :tab new \"打开新tab :/, :? “向前搜索，向后搜索 :e file “切换文件 :%!xxd ---->切换到十六进制显示 :%!xxd -r ---->切回文本方式显示 快捷键 g + t “切换tab ctrl + w \"切换分割窗口 ctrl + h, j, k, l “左下上右 切换窗口 ctrl + p “自动补全 折叠代码：zc 打开折叠：zo 　　 需要注意的是在1、2两种方法中，^V和^M指的是Ctrl+V和Ctrl+M.你必须要手工进行输入，而不是粘贴。 在vi中处理：首先使用vi打开文件，然后按ESC键，接着输入命令：%s/^V^M//. ：%s/^M$//g 　 1.在Vim中可以直接查看文件编码 :set fileencoding 1.在Vim中直接进行转换文件编码,比如将一个文件转换成utf-8格式 :set fileencoding=utf-8 按两下d，删除一行 "},"every-day-use/markdown.html":{"url":"every-day-use/markdown.html","title":"markdown","keywords":"","body":" Title Date Modified Category markdown 2019-06-06 12:00 2019-06-06 12:00 every day use "},"every-day-use/jetbrains.html":{"url":"every-day-use/jetbrains.html","title":"jetbrains","keywords":"","body":"1. 快捷键2. mark directory as -> sources root Title Date Modified Category jetbrains 2019-06-06 12:00 2019-06-06 12:00 every day use 1. 快捷键 Option+Command+l 格式化代码 command + / 注释 alt + / 提示 shift + command + k git push 2. mark directory as -> sources root inspect code， 分析代码 Diagrams ， UML类图 "},"every-day-use/unity.html":{"url":"every-day-use/unity.html","title":"unity","keywords":"","body":"1. 基本操作2. 基础经验 Title Date Modified Category unity 2019-06-06 12:00 2019-06-06 12:00 every day use 1. 基本操作 command + shit + F 先选中摄像机，将场景所见变成摄像机视角 q w e r t y 快捷键 alt + 滑动 改变视角 ctrl + 滑动 缩放场景 command + d 复制一个对象 按住command拖动，一米一米的拖动 2. 基础经验 空物体设坐标为000，子物体和世界坐标一致，便于操作 "},"every-day-use/chrome.html":{"url":"every-day-use/chrome.html","title":"chrome","keywords":"","body":"1. Console API1.1. 命令行1. Console API 当打开 firebug (也包括 Chrome 等浏览器的自带调试工具)，window 下面会注册一个叫做 console 的对象，它提供多种方法向控制台输出信息，供开发人员调试使用。下面是这些方法的一个简单介绍，适时地运用它们，对于提高开发效率很有帮助。 console.log(object[, object, ...]) 使用频率最高的一条语句：向控制台输出一条消息。支持 C 语言 printf 式的格式化输出。当然，也可以不使用格式化输出来达到同样的目的： var animal='frog', count=10; console.log(\"The %s jumped over %d tall buildings\", animal, count); console.log(\"The\", animal, \"jumped over\", count, \"tall buildings\"); console.debug(object[, object, ...]) 向控制台输出一条信息，它包括一个指向该行代码位置的超链接。 console.info(object[, object, ...]) 向控制台输出一条信息，该信息包含一个表示“信息”的图标，和指向该行代码位置的超链接。 console.warn(object[, object, ...]) 同 info。区别是图标与样式不同。 console.error(object[, object, ...]) 同 info。区别是图标与样式不同。error 实际上和 throw new Error() 产生的效果相同，使用该语句时会向浏览器抛出一个 js 异常。 console.assert(expression[, object, ...]) 断言，测试一条表达式是否为真，不为真时将抛出异常（断言失败）。 console.dir(object) 输出一个对象的全部属性（输出结果类似于 DOM 面板中的样式）。 console.dirxml(node) 输出一个 HTML 或者 XML 元素的结构树，点击结构树上面的节点进入到 HTML 面板。 console.trace() 输出 Javascript 执行时的堆栈追踪。 console.group(object[, object, ...]) 输出消息的同时打开一个嵌套块，用以缩进输出的内容。调用 console.groupEnd() 用以结束这个块的输出。 console.groupCollapsed() 同 console.group(); 区别在于嵌套块默认是收起的。 console.time(name) 计时器，当调用 console.timeEnd(name);并传递相同的 name 为参数时，计时停止，并输出执行两条语句之间代码所消耗的时间（毫秒）。 console.profile([title]) 与 profileEnd() 结合使用，用来做性能测试，与 console 面板上 profile 按钮的功能完全相同。 console.count([title]) 输出该行代码被执行的次数，参数 title 将在输出时作为输出结果的前缀使用。 console.clear() 清空控制台 1.1. 命令行 控制台的输出面板右边，是控制台的输入面板（Chrome 调试工具对应为下方），在这里除了可以运行常规的 javascript 代码，还内置了相当数量的命令行可以辅助我们的调试工作，下面是一些常用命令行的简单介绍。 $(id) 返回一个给定 id 的元素。 $$(selector) 返回给定的 css 选择器匹配到的一组元素。 $x(xpath) 返回给定的 XPath 表达式匹配到的一组元素。 $0 在 HTML 面板中选中的元素。 $1 上一次在 HTML 面板中选中的元素。 $n(index) 访问最近 5 个被选中过的元素，index 的范围： 0 – 4。 dir(object) 同 console.dir(object)。 dirxml(node) 同 console.dirxml(node)。 clear() 同 console.clear()。 inspect(object[, tabName])() 在合适的（或一个指定的） tab 中检视一个对象。 keys(object) 返回一个对象的所有属性的键。 values(object) 返回一个对象的所有属性的值。 debug(fn) 在函数第一行添加一个断点，使用 undebug(fn) 移除断点。 monitor(fn) 开启一个函数的调用日志，使用 unmonitor(fn) 关闭该功能。非常有用的一个命令，但是它似乎并没有很好地工作。 monitorEvents(object[, types]) 开启一个元素的某个事件（或所有事件）被触发时的日志记录。用例如下： monitorEvents($0,['click']) 上面的命令行被执行后，将开启当前在 HTML 面板中被选中元素的 click 事件监控，一旦这个元素的 click 事件被触发，事件对象将会在控制台输出。如果不指定第二个参数，将对所有事件进行记录。 profile([title]) 同 console.profile([title]) $x('//div[@id=\"float_icon\"]/div/img')[0].click() 直接操作元素 类似于selenium操作 "},"math/":{"url":"math/","title":"Math","keywords":"","body":""},"algorithm/":{"url":"algorithm/","title":"algorithm","keywords":"","body":"1. 本部分对应源码2. 参考资料2.1. books Title Date Modified Category algorithm 2019-06-06 12:00 2019-07-08 12:00 algorithm 数据结构 算法 List stack queue string tree graph searching 顺序表查找 有序表查找 线性索引查找 二叉排序树查找 散列表查找 sort 冒泡排序（Bubble Sort） 简单选择排序（Simple Selection Sort） 直接插入排序（Straight Insertion Sort） 希尔排序（Shell Sort） 堆排序（Heap Sort） 归并排序（Merging Sort） 快速排序（Quick Sort） 1. 本部分对应源码 https://github.com/mingz2013/data-structures-c 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/data_structures.html":{"url":"algorithm/data_structures.html","title":"数据结构","keywords":"","body":"1. 数据结构1.1. 基本概念1.1.1. 数据1.1.2. 数据元素1.1.3. 数据项1.1.4. 数据对象1.1.5. 数据结构1.2. 逻辑结构与物理结构1.2.1. 逻辑结构：是指数据对象中数据元素之间的相互关系。1.2.2. 物理结构1.3. 抽象数据类型1.3.1. 数据类型1.3.2. 抽象数据类型1.4. 总结回顾2. 参考资料2.1. books Title Date Modified Category 数据结构 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. 数据结构 数据结构：是相互之间存在一种或多种特定关系的数据元素的集合。 1.1. 基本概念 1.1.1. 数据 数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合。 1.1.2. 数据元素 数据元素：是组成数据的，有一定意义的基本单位，在计算机中通常作为整体处理，也被称为记录。 1.1.3. 数据项 数据项：一个数据元素可以由若干个数据项组成。 数据项是数据不可分割的最小单位。 1.1.4. 数据对象 数据对象：是性质相同的数据元素的集合，是数据的子集。 1.1.5. 数据结构 数据结构：是相互之间存在一种或多种特定关系的数据元素的集合。 1.2. 逻辑结构与物理结构 我们在用示意图表示数据的逻辑结构时，要注意两点： 将每一个元素看做一个节点，用圆圈表示。 元素之间的逻辑关系用节点之间的连线表示，如果这个关系是有方向的，那么用带箭头的连线表示。 1.2.1. 逻辑结构：是指数据对象中数据元素之间的相互关系。 逻辑结构是针对具体问题的，是为了解决某个问题，在对问题理解的基础上，选择一个合适的数据结构表示数据元素之间的逻辑关系。 集合结构 集合结构：集合结构中的数据元素除了同属于一个集合外，它们之间没有其他关系。 线性结构 线性结构：线性结构中的数据元素之间是一对一的关系。 树形结构 树形结构：树形结构中的数据元素之间存在一种一对多的层次关系。 图形结构 图形结构：图形结构的数据元素是多对多的关系。 1.2.2. 物理结构 物理结构：是指数据的逻辑结构在计算机中的存储形式。 逻辑结构是面向问题的，而物理结构就是面向计算机的，其基本的目标就是将数据及其逻辑关系存储到计算机的内存中。 数据元素的存储结构形式有两种：顺序存储和链式存储 顺序存储结构 顺序存储结构：是把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系是一致的。 链式存储结构 链式存储结构：是把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的。 1.3. 抽象数据类型 1.3.1. 数据类型 数据类型：是指一组性质相同的值的集合及定义在此集合上的一些操作的总称。 在C语言中，按照取值的不同，数据类型可以分为两类： 原子类型：是不可以再分解的基本类型，包括整型，实型，字符型等。 结构类型：由若干个类型组合而成，是可以再分解的。例如，整型数组是由若干整型数据组成的。 抽象是指抽取出事物具有的普遍性的本质。 1.3.2. 抽象数据类型 抽象数据类型（Abstract Data Type，ADT）：是指一个数学模型及定义在该模型上的一组操作。 ”抽象“的意义在于数据类型的数学抽象特性。 抽象数据类型体现了程序设计中问题分解，抽象和信息隐藏的特性。 为了便于在之后的讲解中对抽象数据类型进行规范的描述，我们给出了描述抽象数据类型的标准格式： ADT 抽象数据类型名 Data 数据元素之间逻辑关系的定义 Operation 操作1 初始条件 操作结果描述 操作2 ... 操作n ... endADT 1.4. 总结回顾 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/algorithm.html":{"url":"algorithm/algorithm.html","title":"算法","keywords":"","body":"1. 算法1.1. 算法的特性1.2. 算法设计的要求1.3. 算法效率的度量方法1.4. 函数的渐进增长1.5. 算法时间复杂度1.5.1. 推导大O阶方法1.5.2. 常数阶1.5.3. 线性阶1.5.4. 对数阶1.5.5. 平方阶1.5.6. 常见的时间复杂度1.5.7. 最坏情况与平均情况1.5.8. 算法空间复杂度1.6. 总结2. 参考资料2.1. books Title Date Modified Category algorithm 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. 算法 算法（Algorithm）是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作。 1.1. 算法的特性 算法具有五个基本特性：输入，输出，有穷性，明确性，可行性。 输入输出：算法具有零个或多个输入。算法至少有一个或多个输出。 有穷性：算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且每一个步骤在可接受的时间内完成。 确定性：算法的每一步骤都具有确定的含义，不会出现二义性。 可行性：算法的每一步都必须是可行的，也就是说，每一步都能够通过执行有限次数完成。 1.2. 算法设计的要求 正确性：算法的正确性是指算法至少应该具有输入，输出和加工处理无歧义性，能正确反映问题的需求，能够得到问题的正确答案， 可读性：算法设计的另一目的是为了便于阅读，理解和交流。 健壮性：当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名其妙的结果。 时间效率高和存储量低：设计算法应该尽量满足时间效率高和存储量低的需求。 时间效率：指的是算法的执行时间，对于同一个问题，如果有多个算法能够解决，执行时间短的算法效率高，执行时间长的效率低。 存储量需求：指的是算法在执行过程中需要的最大存储空间，主要指算法程序运行时所占用的内存或外部硬盘存储空间。 1.3. 算法效率的度量方法 事后统计方法：这种方法主要是通过设计好的测试程序和数据，利用计算机计时器对不同算法编制的程序的运行时间进行比较，从而确定算法效率的高低。 事前分析估算法：在计算机程序编制前，依据统计方法对算法进行估算。 1.4. 函数的渐进增长 函数的渐进增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n>N,f(n)总是比g(n)大，那么，我们说f(n)的增长渐近快于g(n)。 判断一个算法的效率时，函数中的常数和其他次要项常常可以忽略，而更应该关注主项（最高阶项）的阶数。 某个算法，随着n的增大，它会越来越优于另一算法，或者越来越差于另一算法。 这其实就是事前估算方法的理论依据，通过算法时间复杂度来估算算法时间效率。 1.5. 算法时间复杂度 在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，记作：T(n) = O(f(n))。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。 这样用大写O()来体现算法时间复杂度的记法，我们称之为 大O记法。 一般情况下，随着n的增大，T(n)增长最慢的算法为最优算法。 显然，由此算法时间复杂度的定义可知，我们的三个求和算法的时间复杂度分别为O(n), O(1), O(n^2)。我们分别给它们取了非官方的名称，O(1)叫常数阶，O(n)叫线性阶，O(n^2)叫平方阶，当然，还有其他的一些阶，我们之后会介绍。 1.5.1. 推导大O阶方法 推导大O阶： 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中，只保留最高阶项。 如果最高阶项存在且不是1，则去除与这个项相乘的常数。 得到的结果就是大O阶。 1.5.2. 常数阶 首先顺序结构的时间复杂度。下面的算法，也就是刚才的第二种算法（高斯算法），为什么时间复杂度不是O（3）而是O（1）。 int sum = 0, n = 100; /* 执行一次 */ sum = (1 + n) * n / 2; /* 执行一次 */ printf(\"%d\", sum); /* 执行一次 */ 这个算法的运行次数函数是f(n)=3。根据我们推导大O阶的方法，第一步就是把常数项3改为1。在保留最高阶项时发现，它根本没有最高阶项，所以这个算法的时间复杂度为O(1)。 另外，我们试想一下，如果这个算法当中的语句sum=(1+n)*n/2有10句，即： int sum = 0, n = 100; /* 执行一次 */ sum = (1 + n) * n / 2; /* 执行第1次 */ sum = (1 + n) * n / 2; /* 执行第2次 */ sum = (1 + n) * n / 2; /* 执行第3次 */ sum = (1 + n) * n / 2; /* 执行第4次 */ sum = (1 + n) * n / 2; /* 执行第5次 */ sum = (1 + n) * n / 2; /* 执行第6次 */ sum = (1 + n) * n / 2; /* 执行第7次 */ sum = (1 + n) * n / 2; /* 执行第8次 */ sum = (1 + n) * n / 2; /* 执行第9次 */ sum = (1 + n) * n / 2; /* 执行第10次 */ printf(\"%d\", sum); /* 执行一次 */ 事实上无论n为多少，上面的两段代码就是3次和12次执行的差异。这种与问题的大小无关（n的多少），执行时间恒定的算法，我们称之为具有O（1）的时间复杂度，又叫常数阶。 注意：不管这个常数是多少，我们都记作O（1），而不能是O（3），O（12）等其他任何数字，这是初学者常常犯的错误。 对于分支结构而言，无论是真，还是假，执行的次数都是恒定的，不会随着n的变大而发生变化，所以单纯的分支结构（不包含在循环结构中），其时间复杂度也是O(1)。 1.5.3. 线性阶 线性阶的循环结构会复杂很多。要确定某个算法的阶次，我们常常需要确定某个特定语句或某个语句集运行的次数。 因此，我们要分析算法的复杂度，关键就是要分析循环结构的运行情况。 下面这段代码，它的循环的时间复杂度为O(n), 因为循环体中的代码须要执行n次。 int i; for (i = 0; i 1.5.4. 对数阶 下面的这段代码，时间复杂度又是多少呢？ int count = 1; while (count 由于每次count乘以2之后，就距离n更近了一分。也就是说，有多少个2相乘后大于n，就会退出循环。由2^x=n得到x=log2n. 所以这个循环的时间复杂度为O(logn)。 1.5.5. 平方阶 下面例子是一个循环嵌套，它的内循环刚才我们已经分析过，时间复杂度为O(n)。 int i,j; for (i = 0; i 而对于外层的循环，不过是内部这个时间复杂度为O(n)的语句，再循环n次。所以这段代码的时间复杂度为O(n^2)。 如果外循环的循环次数改为了m，时间复杂度就变为O(m*n)。 int i,j; for (i = 0; i 所以我们可以总结得出，循环的时间复杂度等于循环体的复杂度乘以该循环运行的次数。 那么下面这个循环嵌套，它的时间复杂度是多少呢？ int i,j; for (i = 0; i 由于当i=0时，内循环执行了n次，当i=1时，执行了n-1次，…当i=n-1时，执行了1次。所以总的执行次数为： n + (n - 1) + (n - 2) + ...+ 1 = n(n + 1) / 2 = n^2/2 + n/2 用我们推导大O阶的方法，第一条，没有加法常数不予考虑；第二条，只保留最高阶项，因此保留n^2/2;第三条，去除这个项相乘的常数，也就是去除1/2,最终这段代码的时间复杂度为O(n^2)。 从这个例子，我们也可以得到一个经验，其实理解大O推导不算难，难的是对数列的一些相关运算，这更多的是考察你的数学知识和能力。 我们继续看例子，对于方法调用的时间复杂度又如何分析。 int i,j; for (i = 0; i 函数体是打印这个参数。其实这很好理解，function函数的时间复杂度是O(1)。所以整体的时间复杂度为O(n)。 加入function是下面这样的： void function(int count) { int j; for (j = count; j 事实上，这和刚才举的例子是一样的，只不过把嵌套内循环放到了函数中，所以最终的时间复杂度为O(n^2)。 下面这段相对复杂的语句： n++; /* 执行次数为1 */ function(n); /* 执行次数为n */ int i,j; for (i = 0; i 它的执行次数f(n) = 1 + n + n^2 + n(n+1)/2 = 3/2 n^2 + 3/2 n + 1, 根据推导大O阶的方法，最终这段代码的时间复杂度也是O(n^2)。 1.5.6. 常见的时间复杂度 常见的时间复杂度如表2-10-1所示。 常用的时间复杂度所耗费的时间从大到小依次是： 1.5.7. 最坏情况与平均情况 算法的分析也是类似，我们查找一个有n个随机数字数组中的某个数字，最好的情况是第一个数字就是，那么算法的时间复杂度为O(1)，但也有可能这个数字就在最后一个位置上待着，那么算法的时间复杂度就是O(n), 这是最坏的一种情况了。 最坏情况运行时间是一种保证，那就是运行时间将不会再坏了。在应用中，这是一种最重要的需求，通常，除非特别指定，我们提到的运行时间都是最坏情况的运行时间。 而平均运行时间也就是从概率的角度看，这个数字在每一个位置的可能性是相同的，所以平均的查找时间为n/2次后发现这个目标元素。 平均运行时间是所有情况中最有意义的，因为它是期望的运行时间。 对算法的分析， 一种方法是计算所有情况的平均值，这种时间复杂度的计算方法称为平均时间复杂度。 另一种方法是计算最坏情况下的时间复杂度，这种方法称为最坏时间复杂度。 一般在没有特殊说明的情况下，都是指最坏时间复杂度。 1.5.8. 算法空间复杂度 我们在写代码时，完全可以用空间来换时间。 算法的空间复杂度通过计算算法所需的存储空间实现，算法空间复杂度的计算公式记作：S(n)=O(f(n))，其中，n为问题的规模，f(n)为语句关于n所占存储空间的函数。 一般情况下，一个程序在机器上执行时，除了需要存储程序本身的指令，常数，变量和输入数据外，还需要存储对数据操作的存储单元。 若输入数据所占空间只取决于问题本身，和算法无关，这样只需要分析该算法在实现时所需的辅助单元即可。 若算法执行时所需的辅助空间相对于输入数据量而言是个常数，则称此算法为原地工作，空间复杂度为O(1)。 通常，我们都是用”时间复杂度“来指运行时间的需求，使用”空间复杂度“指空间需求。 当不用限定词的使用”复杂度“时，通常都是指时间复杂度。显然我们这本书重点要讲的还是算啊发的时间复杂度问题。 1.6. 总结 主要谈了算法的一些基本概念。谈到了数据结构与算法的关系是相互依赖不可分割的。 算法的定义：算法是解决特定问题求解步骤的描述，在计算机中为指令的有限序列，并且每条指令表示一个或多个操作。 算法的特性：有穷性，确定性，可行性，输入，输出。 算法的设计的要求：正确性，可读性，健壮性，高效率和低存储量需求。 算法特性与算法设计的要求 容易混， 需要对比记忆。 算法的度量方法：事后统计方法（不科学，不准确），事前分析估算方法。 函数的渐近增长：给定两个函数f(n)和g(n), 如果存在一个整数N，使得对于所有的n>N，f(n)总是比g(n)大，那么，我们说f(n)的增长渐近快于g(n)。于是我们可以得出一个结论，判断一个算法好不好，我们只通过少量的数据是不能做出准确判断的，如果我们可以对比算法的关键执行次数函数的渐近增长性，基本就可以分析出：某个算法，随着n的变大，它会越来越优于另一算法，或者越来越差于另一算法。 然后给出了算法时间复杂度的定义和推导大O阶的步骤。 推导大O阶： 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中，只保留最高阶项 如果最高阶项存在且不是1，则去除与这个项相乘的常数。 得到的结果就是大O阶。 通过这个步骤，我们可以在得到算法的运行次数表达式后，很快得到它的时间复杂度，即大O阶。同时也提醒了大家，其实推导大O阶很容易，但如何得到运行次数的表达式却是需要数学功底的。 接着我们给出了常见的时间复杂度所消耗时间的大小排列： 最后，我们给出了关于算法最坏情况和平均情况的概念，以及空间复杂度的概念。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/list.html":{"url":"algorithm/list.html","title":"List","keywords":"","body":"1. 线性表1.1. 线性表的抽象数据类型1.2. 线性表的顺序存储结构1.2.1. 数据长度与线性表长度区别1.2.2. 地址计算方法1.2.3. 顺序存储结构的插入与删除1.2.4. 线性表顺序存储结构的优缺点1.3. 线性表的链式存储结构1.3.1. 头指针与头结点的异同1.3.2. 线性表链式存储结构代码描述1.3.3. 单链表的读取1.3.4. 单链表的插入和删除1.3.5. 单链表的整表创建和整表删除1.4. 单链表结构和顺序存储结构优缺点1.5. 静态链表1.5.1. 静态链表的插入删除操作1.5.2. 静态链表优缺点1.6. 循环链表1.7. 双向链表2. 总结3. 参考资料3.1. books Title Date Modified Category 线性表 2019-07-01 12:00 2019-07-05 12:00 algorithm 1. 线性表 线性表（List）：零个或多个数据元素的有限序列。 若将线性表记为（a1,…,ai-1,ai,ai+1,…,an）,则表中ai-1领先于ai, ai领先于ai+1，称ai-1是ai的直接前驱元素，ai+1是ai的直接后继元素。当i=1,2…,n-1时，ai有且仅有一个直接后继，当i=2,3,…n时，ai有且仅有一个直接前驱。如图3-2-1所示。 线性表元素的个数n（n>=0）定义为线性表的长度，当n=0时，称为空表。 在较复杂的线性表中，一个数据元素可以由若干个数据项组成。 1.1. 线性表的抽象数据类型 ADT 线性表(List) Data 线性表的数据对象集合为{a1, a2, ..., an}, 每个元素的类型均为DataType。其中，除第一个元素a1外，每一个元素有且只有一个直接前驱元素，除了最后一个元素an外，每一个元素有且只有一个直接后继元素。数据元素之间的关系是一对一的关系。 Operation InitList(*L): 初始化操作，建立一个空的线性表L。 ListEmpty(L): 若线性表为空，返回true，否则返回false。 ClearList(*L): 将线性表清空。 GetElem(L, i, *e): 将线性表L中的第i个位置元素值返回给e。 LocateElem(L, e): 在线性表L中查找与给定值e相等的元素，如果查找成功，返回该元素在表中序号表示成功；否则，返回0表示失败。 ListInsert(*L, i, e): 在线性表L中的第i个位置插入新元素e。 ListDelete(*L, i, *e): 删除线性表L中第i个位置元素，并用e返回其值。 ListLength(L): 返回线性表L的元素个数。 endADT 对于不同的应用，线性表的基本操作是不同的，上述操作是最基本的，对于实际问题中涉及的关于线性表的更复杂操作，完全可以用这些基本操作的组合来实现。 1.2. 线性表的顺序存储结构 线性表的顺序存储结构，指的是用一段地址连续的存储单元依次存储线性表中的数据元素。 线性表（a1,a2,…an）的顺序存储示意图如下： 既然线性表的每个数据元素的类型都相同，所以可以用C语言（其他语言也相同）的一维数组来实现顺序存储结构，即把第一个数据元素存到数组下标为0的位置中，接着把线性表相邻的元素存储在数组中相邻的位置。 #define MAXSIZE 20 /* 存储空间初始分配量 */ typedef int ElemType; /* ElemType类型根据实际情况而定，这里假设为int */ typedef struct { ElemType data[MAXSIZE]; /* 数组存储数据元素，最大值为MAXSIZE */ int length; /* 线性表当前长度 */ } SqList; 我们发现描述顺序存储结构需要三个属性： 存储空间的起始位置：数组data，它的存储位置就是存储空间的存储位置。 线性表的最大存储容量：数组长度MaxSize。 线性表的当前长度：length。 1.2.1. 数据长度与线性表长度区别 数组的长度，线性表的长度，两个概念需要区分一下。 数组的长度是存放线性表的存储空间的长度，存储分配后这个量是一般是不变的。 线性表的长度是线性表中数据元素的个数，随着线性表插入和删除操作的进行，这个量是变化的。 在任意时刻，线性表的长度应该小于等于数组的长度。 1.2.2. 地址计算方法 用数组存储顺序表意味着要分配固定长度的数组空间，由于线性表中可以进行插入和删除操作，因此分配的数组空间要大于等于当前线性表的长度。 存储器中的每个存储单元都有自己的编号，这个编号称为地址。 假设每个数据元素占用的是C个存储单元，那么线性表中第i+1个数据元素的存储位置和第i个数据元素的存储位置满足下列关系（LOC表示获得存储位置的函数）。 所以对于第i个数据元素ai的存储位置可以由a1推算得出： 从图3-4-4来理解： 通过这个公式，你可以随时算出线性表中任意位置的地址，不管它是第一个还是最后一个，都是相同的时间。那么我们对每个线性表位置的存入或者取出数据，对于计算机来说都是相等的时间，也就是一个常数，因此用我们算法中学到的时间复杂度的概念来说，它的存取时间性能为O(1)。我们通常把具有这一特点的存储结构称为随机存取结构。 1.2.3. 顺序存储结构的插入与删除 现在我们来分析一下，插入和删除的时间复杂度。 最好情况O(1), 最坏情况O(n)。平均时间复杂度还是O(n)。 这说明，线性表的顺序存储结构，在存，读数据时，不管是哪个位置，时间复杂度都是O(1)，而插入或删除时，时间复杂度都是O(n)。 这说明，它比较适合元素个数不太变化，而更多是存取数据的应用。 1.2.4. 线性表顺序存储结构的优缺点 1.3. 线性表的链式存储结构 为了表示每个数据元素ai与其直接后继数据元素ai+1之间的逻辑关系，对数据元素ai来说，除了存储其本身的信息之外，还需存储一个指示其直接后继的信息（即直接后继的存储位置）。我们把存储数据元素信息的域称为数据域，把存储直接后继位置的域称为指针域。指针域中存储的信息称作指针或链。这两部分信息组成数据元素ai的存储映像，称为节点（Node）。 n个节点（ai的存储映像）链接成一个链表，即为线性表（a1,a2,…an）的链式存储结构，因为此链表的每个节点中只包含一个指针域，所以叫做单链表。 我们把链表中第一个节点的存储位置叫做头指针。 为了更加方便对链表进行操作，会在单链表的第一个节点前附设一个节点，称为头结点。 1.3.1. 头指针与头结点的异同 1.3.2. 线性表链式存储结构代码描述 /* 线性表的单链表存储结构 */ typedef struct Node { ElemType data; struct Node * next; } Node; typedef struct Node * LinkList; /* 定义LinkList */ 从这个结构定义中，我们知道，节点由存放数据元素的数据域存放后继结点地址的指针域组成。 1.3.3. 单链表的读取 最坏情况的时间复杂度是O(n) 1.3.4. 单链表的插入和删除 从整个算法来说，我们很容易推导出：它们时间复杂度都是O(n). 如果在我们不知道第i个元素的指针位置，单链表数据结构在插入和删除操作上，与线性表的顺序存储结构是没有太大优势的。 但如果，我们希望从第i个位置，插入10个元素，对于顺序存储结构意味着，每一次插入都需要移动n-i个元素，每次都是O(n).而单链表，我们只需要在第一次时，找到第i个位置的指针，此时为O(n)。接下来只是简单地通过赋值移动指针而已，时间复杂度都是O(1)。 显然，对于插入或删除数据越频繁的操作，单链表的效率优势就越是明显。 1.3.5. 单链表的整表创建和整表删除 1.4. 单链表结构和顺序存储结构优缺点 若线性表需要频繁查找，很少进行插入和删除操作时，宜采用顺序存储结构。 若需要频繁插入和删除时，宜采用单链表结构。 当线性表中的元素个数变化较大或者根本不知道有多大时，最好采用单链表结构，这样可以不需要考虑存储空间的大小问题。 而如果事先知道线性表的大致长度，比如一年12个月，一周就是七天，这种用顺序存储结构效率会高很多。 1.5. 静态链表 用数组描述的链表叫做静态链表，这种描述方法还有起名叫做游标实现法。 /* 线性表的静态链表存储结构 */ #define MAXSIZE 1000 /* 假设链表的最大长度是1000 */ typedef struct { ElemType data; int cur; /* 游标(Cursor), 为0时表示无指向 */ } Component, StaticLinkList[MAXSIZE]; 1.5.1. 静态链表的插入删除操作 1.5.2. 静态链表优缺点 1.6. 循环链表 将单链表中终端节点的指针端由空指针改为指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称循环链表（circular linked list）。 1.7. 双向链表 双向链表（double linked list）是在单链表的每个节点中，再设置一个指向其前驱节点的指针域。 typedef struct DulNode { ElemType data; struct DulNode * prior; /* 直接前驱指针 */ struct DulNode * next; /* 直接后继指针 */ } DulNode, *DuLinkList; 2. 总结 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/stack.html":{"url":"algorithm/stack.html","title":"stack","keywords":"","body":"1. stack1.1. 栈的顺序存储结构及实现1.1.1. 顺序存储结构的 进栈 出栈 操作1.1.2. 两栈共享空间1.2. 栈的链式存储结构及实现1.2.1. 栈的链式存储结构 进栈 出栈 操作1.3. 栈的作用2. 总结3. 参考资料3.1. books Title Date Modified Category stack 2019-07-01 12:00 2019-07-05 12:00 algorithm 1. stack 栈（stack）是限定仅在表尾进行插入和删除操作的线性表。 我们把允许插入和删除的一端称为栈顶（top），另一端称为栈底（bottom），不含任何数据元素的栈称为空栈。栈又称为后进先出（Last In First Out）的线性表，简称LIFO结构。 栈的插入操作，叫作进栈，也称压栈，入栈。 栈的删除操作，叫作出栈，也有的叫作弹栈。 ADT 栈(stack) Data 同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。 Operation InitStack(*S): 初始化操作，建立一个空栈S。 DestroyStack(*s): 若栈存在，则销毁它。 ClearStack(s): 将栈清空。 StackEmpty(S): 若栈为空，返回true，否则返回false。 GetTop(S, *e): 若栈存在且非空，用e返回S的栈顶元素。 Push(*S, e): 若栈S存在，插入新元素e到栈S中并成为栈顶元素。 Pop(*S, e): 删除栈S中栈顶元素，并用e返回其值。 StackLength(S): 返回栈S的元素个数。 endADT 由于栈本身就是一个线性表，那么上一章我们讨论了线性表的顺序存储和链式存储，对于栈来说，也是同样适用的。 1.1. 栈的顺序存储结构及实现 typedef int SElemType; /* SElemType 类型根据实际情况而定，这里假设为int */ typedef struct { SElemType data[MAXSIZE]; int top; /* 用于栈顶指针 */ }SqStack; 1.1.1. 顺序存储结构的 进栈 出栈 操作 1.1.2. 两栈共享空间 如果我们有两个相同类型的栈，我们为它们各自开辟了数组空间，极有可能是第一个栈已经满了，再进栈就溢出了，而另一个栈还有很多存储空间空闲。 /* 两栈共享空间结构 */ typedef struct { SElemType data[MAXSIZE]; int top1; /* 栈1栈顶指针 */ int top2; /* 栈2栈顶指针 */ } SqDoubleStack; 1.2. 栈的链式存储结构及实现 栈的链式存储结构，简称为链栈。 typedef struct StackNode { SElemType data; struct StackNode * next; } StackNode, *LinkStackPtr; typedef struct LinkStack { LinkStackPtr top; int count; }LinkStack; 1.2.1. 栈的链式存储结构 进栈 出栈 操作 1.3. 栈的作用 栈的引入简化了程序设计的问题，划分了不同关注层次，使得思考范围缩小，更加聚焦于我们要解决的问题核心。 反之，像数组等，因为要分散精力去考虑数组的下标增减等细节问题，反而掩盖了问题的本质。 2. 总结 顺序栈 两栈共享空间 链栈 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/queue.html":{"url":"algorithm/queue.html","title":"queue","keywords":"","body":"1. queue1.1. 循环队列1.2. 队列顺序存储的不足1.3. 队列的链式存储结构及实现1.3.1. 队列的链式存储结构 入队 出队 操作2. 总结3. 参考资料3.1. books Title Date Modified Category queue 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. queue 队列（Queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。 队列式一种先进先出（First In First Out）的线性表，简称FIFO。允许插入的一端称为队尾，允许删除的一端称为队头。 ADT 队列(Queue) Data 同线性表。元素具有相同的类型，相邻元素具有前驱和后继关系。 Operation InitQueue(*Q): 初始化操作，建立一个空队列Q。 DestroyQueue(*Q): 若队列Q存在，则销毁它。 ClearQueue(*Q): 将队列Q清空。 QueueEmpty(Q): 若队列Q为空，返回true，否则返回false。 GetHead(Q, *e): 若队列Q存在且非空，用e返回队列Q的队头元素。 EnQueue(*Q, e): 若队列存在，插入新元素e到队列Q中并成为队尾元素。 DeQueue(*Q, *e): 删除队列Q中队头元素，并用e返回其值。 QueueLength(Q): 返回队列Q的元素个数。 endADT 1.1. 循环队列 所以解决假溢出的办法就是后面满了，就再重头开始，也就是头尾相接的循环。 我们把队列的这种头尾相接的顺序存储结构称为循环队列。 1.2. 队列顺序存储的不足 1.3. 队列的链式存储结构及实现 队列的链式存储结构，其实就是线性表的单链表，只不过它只能尾进头出而已，我们把它简称为链队列。 typedef int QElemType; /* QElemType类型根据实际情况而定，这里假设为int */ typedef struct QNode /* 节点结构 */ { QElemType data; struct QNode *next; }QNode, *QueuePtr; typedef struct /* 队列的链表结构 */ { QueuePtr front, rear; /* 队头，队尾指针 */ }LinkQueue; 1.3.1. 队列的链式存储结构 入队 出队 操作 2. 总结 顺序队列 循环队列 链队列 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/string.html":{"url":"algorithm/string.html","title":"string","keywords":"","body":"1. string1.1. 串的比较1.2. 串的抽象数据类型1.3. 串的存储结构1.3.1. 串的顺序存储结构1.3.2. 串的链式存储结构1.4. 朴素的模式匹配算法1.5. KMP模式匹配算法1.6. 总结回顾2. 参考资料2.1. books Title Date Modified Category string 2019-07-01 12:00 2019-07-08 12:00 algorithm 1. string 串（string）是由零个或多个字符组成的有限序列，又名叫字符串。 1.1. 串的比较 事实上，串的比较是通过组成串的字符之间的编码来进行的，而字符的编码指的是字符在对应字符集中的符号。 计算机中的常用字符是使用标准的ASCii编码，更准确一点，由7位二进制数表示一个字符，总共可以表示128个字符。 后来发现一些特殊符号的出现，128个不够用，于是扩展ASCii码由8位二进制数表示一个字符，总共可以表示256个字符，这已经足够满足以英文为主的语言和特殊符号进行输入，存储，输出等操作的字符需要了。 可是，全世界估计要有成百上千种语言与文字，显然这256个字符是不够的，因此后来就有了Unicode编码，比较常用的是由16位的二进制数表示一个字符，这样总共就可以表示216个字符，约是65万多个字符，足够表示世界上所有语言的所有字符了。当然，为了和ASCii码兼容，Unicode的前256个字符与ASCii码完全相同。 所以如果我们要在C语言中比较两个串是否相等，必须是它们串的长度以及它们各个对应位置的字符都相等时，才算是相等。即给定两个串：s=“a1,a2,a3…an”,t=“b1,b2…bm”, 当且仅当n=m,且a1=b1,a2=b2,…an=bm时，我们认为s=t。 那么对于两个串不相等时，如何判定它们的大小呢。我们这样定义： 给定两个串：s=“a1,a2…an”, t=“b1,b2…bm”, 当满足以下条件之一时，s n 存在某个k 1.2. 串的抽象数据类型 ADT 串（string） Data 串中元素仅由一个字符组成，相邻元素具有前驱和后继关系。 Operation StrAssign(T, *chars): 生成一个其值等于字符串常量chars的串T。 StrCopy(T, S): 串S存在，由串S复制得串T。 ClearString(S): 串S存在，将串清空。 StringEmpty(S): 若串S为空，返回true，否则返回false。 StrLength(S): 返回串S的元素个数，即串的长度。 StrCompare(S, T): 若S>T, 返回值>0, 若S=T, 返回0，若S1.3. 串的存储结构 1.3.1. 串的顺序存储结构 串的顺序存储结构是用一组地址连续的存储单元来存储串中的字符序列的。按照预定义的大小，为每个定义的串变量分配一个固定长度的存储区。一般是用定长数组来定义。 1.3.2. 串的链式存储结构 对于串的链式存储结构，与线性表是相似的，但由于串结构的特殊性，结构中的每个元素数据是一个字符，如果也简单的应用链表存储串值，一个节点对应一个字符，就会存在很大的空间浪费。因此，一个节点可以存放一个字符，也可以考虑存放多个字符，最后一个节点若是未被沾满时，可以用”#”或其他非串值字符补全。 当然，这里一个节点存多少个字符才合适就变得很重要，这会直接影响着串处理的效率，需要根据实际情况作出选择。 但串的链式存储结构除了在连接串与传操作时有一定方便之外，总的来说不如顺序存储灵活，性能也不如顺序存储结构好。 1.4. 朴素的模式匹配算法 子串的定位操作通常称作串的模式匹配。应该算是串中最重要的操作之一。 简单地说，就是对主串的每一个字符作为子串开头，与要匹配的字符串进行匹配。对主串做大循环，每个字符开头做T的长度的小循环，直到匹配成功或全部遍历完成为止。 最好的情况O(1), 最坏的情况，O((n-m+1)*m) 太低效。 1.5. KMP模式匹配算法 模式匹配算法，可以大大避免重复遍历的情况，我们把它称之为克努特-莫里斯-普拉特算法，简称KMP算法。 KMP是对朴素匹配算法的优化, O(n+m) TODO 1.6. 总结回顾 这一章节我们重点讲了“串”这样的数据结构，串（string）是由零个或多个字符组成的有限序列，又名叫字符串。 本质上，它是一种线性表的扩展，但相对于线性表关注一个个元素来说，我们对串这种结构更多的是关注它子串的应用问题，如查找，替换等操作。 现在的高级语言都有针对串的函数可以调用。我们在使用这些函数的时候，同时也应该要理解它当中的原理，以便于在碰到复杂的问题时，可以更加灵活的使用，比如KMP模式匹配算法的学习，就是更有效地去理解index函数当中的实现细节。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/tree.html":{"url":"algorithm/tree.html","title":"tree","keywords":"","body":"1. tree1.1. 树的定义1.1.1. 节点分类1.1.2. 节点间关系1.1.3. 树的其他相关概念1.2. 树的抽象数据类型1.3. 树的存储结构1.3.1. 双亲表示法1.3.2. 孩子表示法1.3.3. 孩子兄弟表示法1.4. 二叉树的定义1.4.1. 二叉树的特点1.4.2. 特殊二叉树1.4.3. 二叉树的性质1.4.4. 二叉树的存储结构1.4.5. 遍历二叉树1.4.6. 线索二叉树1.4.7. 树，森林与二叉树的转换1.4.8. 赫夫曼树及其应用1.5. 总结回顾2. 参考资料2.1. books Title Date Modified Category tree 2019-07-01 12:00 2019-07-08 12:00 algorithm 1. tree 1.1. 树的定义 树(Tree)是n(n>=0)个节点的有限集。n=0时称为空树， 在任意一棵非空树中： 有且仅有一个特定的称为根（Root）的节点； 当n>1时，其余节点可分为m(m>0)个互不相交的有限集T1,T2,…Tn，其中每一个集合本身又是一棵树，并且称为根的子树（SubTree）。 树的定义其实就是我们在讲解栈时提到的递归的方法。也就是在树的定义之中还用到了树的概念，这是一种比较新的定义方法。 1.1.1. 节点分类 树的节点包含一个数据元素及若干指向其子树的分支。 节点拥有的子树数称为节点的度（Degree）。度为0的节点称为叶节点（Leaf）或终端节点；度不为0的节点称为非终端节点或分支节点。除根节点之外，分支节点也称为内部节点。树的度是树内各节点的度的最大值。 1.1.2. 节点间关系 节点的子树的根称为该节点的孩子（Child），相应的，该节点称为孩子的双亲（Parent）。 同一个双亲的孩子之间互称兄弟（Sibling）。 节点的祖先是从根到该节点所经分支上的所有节点。 以某节点为根的子树中的任一节点都称为该节点的子孙。 1.1.3. 树的其他相关概念 如果将树中节点的各子树看成从左至右是有次序的，不能互换的，则称该树为有序树，否则称为无序树。 森林（Forest）是m(m>=0)棵互不相交的树的集合。 1.2. 树的抽象数据类型 ADT 树（tree） Data 树是由一个根节点和若干棵子树构成。树中节点具有相同数据类型及层次关系。 Operation InitTree(*T): 构造空树T。 DestroyTree(*T): 销毁树T。 CreateTree(*T, definition): 按definition中给出树的定义来构造树。 ClearTree(*T): 若树T存在，则将树T清为空树。 TreeEmpty(T): 若T为空树，返回true，否则返回false。 TreeDepth(T): 返回T的深度。 Root(T): 返回T的根节点。 Value(T, cur_e): cur_e是树T中一个节点，返回此节点的值。 Assign(T, cur_e, value): 给树T的节点cur_e赋值为value。 Parent(T, cur_e): 若cur_e是树T的非根节点，则返回它的双亲，否则返回空。 LeftChild(T, cur_e): 若cur_e是树T的非叶节点，则返回它的右兄弟，否则返回空。 RightSibling(T, cur_e): 若cur_e有右兄弟，则返回它的右兄弟，否则返回空。 InsertChild(*T, *p, i, c): 其中p指向树T的某个节点，i为所指节点p的度加上1，非空树c与T不相交，操作结果为插入c为树T中p指节点的第i棵子树。 DeleteChild(*T, *p, i): 其中p指向树T的某个节点，i为所指节点p的度，操作结果为删除T中p所指节点的第i棵子树。 endADT 1.3. 树的存储结构 三种不同的表示方法： 双亲表示法 孩子表示法 孩子兄弟表示法 1.3.1. 双亲表示法 我们假设以一组连续空间存储树的节点，同时在每个节点中，附设一个指示器指示其双亲节点到链表中的位置。 其中data是数据域，存储节点的数据信息。而parent是指针域，存储该节点的双亲在数组中的下标。 /* 树的双亲表示法节点结构定义 */ #define MAX_TREE_SIZE 100 typedef int TElemType; /* 树节点的数据类型，目前暂定为整型 */ typedef struct PTNode /* 节点结构 */ { TElemType data; /* 节点数据 */ int parent; /* 双亲位置 */ }PTNode; typedef struct /* 树结构 */ { PTNode nodes[MAX_TREE_SIZE]; /* 节点数组 */ int r, n; /* 根的位置和节点数 */ } PTree; 存储结构的设计是一个非常灵活的过程。一个存储结构设计的是否合理，取决于基于该存储结构的运算是否适合，是否方便，时间复杂度好不好等。 1.3.2. 孩子表示法 每个节点有多个指针域，其中每个指针指向一棵子树的根节点，我们把这种方法叫做多重链表表示法。 1.3.3. 孩子兄弟表示法 任意一棵树，它的节点的第一个孩子如果存在就是唯一的，它的右兄弟如果存在也是唯一的。因此，我们设置两个指针，分别指向该节点的第一个孩子和此节点的右兄弟。 1.4. 二叉树的定义 二叉树（Binary Tree）是n(n>=0)个节点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根节点和两棵互不相交的，分别称为根节点的左子树和右子树的二叉树组成。 1.4.1. 二叉树的特点 二叉树的特点有： 每个节点最多有两棵子树，所以二叉树中不存在度大于2的节点。注意不是只有两棵子树，而是最多有。没有子树或者有一棵子树都是可以的。 左子树和右子树是有顺序的，次序不能任意颠倒。 即使树中某节点只有一棵子树，也要区分它是左子树还是右子树。 二叉树具有五种基本形态： 空二叉树 只有一个根结点 根节点只有左子树 根节点只有右子树 根节点既有左子树又有右子树 1.4.2. 特殊二叉树 斜树 所有的节点都只有左子树的二叉树叫左斜树。所有节点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。 满二叉树 在一棵二叉树中，如果所有分支节点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 满二叉树的特点有： 叶子只能出现在最下一层。出现在其他层就不可能达成平衡 非叶子节点的度一定是2.否则就是“缺胳膊少腿”了。 在同样深度的二叉树中，满二叉树的节点个数最多，叶子数最多。 完全二叉树 对一棵具有n个节点的二叉树按层序编号，如果编号为i（1 这是一种有些理解难度的特殊二叉树。 首先从字面上要区分，“完全”和“满”的差异，满二叉树一定是一棵完全二叉树，但完全二叉树不一定是满的。 完全二叉树的特点： 叶子节点只能出现在最下两层 最下层的叶子一定集中在左部连续位置 倒数二层，若有叶子节点，一定都在右部连续位置 如果节点度为1，则该节点只有左孩子，则不存在只有右子树的情况 同样节点数的二叉树，完全二叉树的深度最小。 1.4.3. 二叉树的性质 性质1：在二叉树的第i层上至多有2^(i-1)个节点(i>=1) 性质2：深度为k的二叉树至多有2^k-1个节点(k>=1) 性质3：对任何一棵二叉树T，如果其终端节点数为n0, 度为2的节点数为n2,则n0=n2+1。 性质4：具有n个节点的完全二叉树的深度为[log2n] +1（[x]表示不大于x的最大整数） 性质5：如果对一棵有n个节点的完全二叉树（其深度为[logxn]+1）的节点按层序编号（从第1层到第[log2n]+1层，每层从左到右），对任一节点i(11，则其双亲是节点[i/2]。 2）如果2i>n，则节点i无左孩子（节点i为叶子节点）；否则其左孩子是节点2i。 3）如果2i+1>n, 则节点i无右孩子；否则其右孩子是节点2i+1。 1.4.4. 二叉树的存储结构 二叉树顺序存储结构 二叉链表 二叉树每个节点最多有两个孩子，所以为它设计一个数据域和两个指针域是比较自然的想法，我们称这样的链表叫做二叉链表。 /* 二叉树的二叉链表节点结构定义 */ typedef struct BiTNode /* 节点结构 */ { TElemType data; /* 节点数据 */ struct BiTNode *lchild, *rchild; /* 左右孩子指针 */ } BiTNode, *BiTree; 1.4.5. 遍历二叉树 二叉树的遍历（traversing binary tree）是指从根节点触发，按照某种次序依次访问二叉树中所有节点，使得每个节点被访问一次且仅被访问一次。 两个关键词：访问 ，次序。 二叉树遍历方法 前序遍历 规则是若二叉树为空，则空操作返回，否则先访问根节点，然后前序遍历左子树，再前序遍历右子树。 中序遍历 规则是若树为空，则空操作返回，否则从根节点开始（注意并不是县访问根节点），中序遍历根节点的左子树，然后是访问根节点，最后中序遍历右子树。 后序遍历 规则是若树为空，则空操作返回，否则从左到右先叶子后节点的方式遍历访问左右子树，最后是访问根节点。 层序遍历 规则是若树为空，则空操作返回，否则从树的第一层，也就是根节点开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对节点逐个访问。 推导遍历结果 已知前序和后序遍历，是不能确定一棵二叉树的。 1.4.6. 线索二叉树 1.4.7. 树，森林与二叉树的转换 1.4.8. 赫夫曼树及其应用 1.5. 总结回顾 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/graph.html":{"url":"algorithm/graph.html","title":"graph","keywords":"","body":"1. graph1.1. 图的定义2. 参考资料2.1. books Title Date Modified Category graph 2019-07-01 12:00 2019-07-01 12:00 algorithm 1. graph 1.1. 图的定义 图（Graph）是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：G（V.E），其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/searching/":{"url":"algorithm/searching/","title":"searching","keywords":"","body":"1. searching1.1. 查找概论1.2. 查找方法2. 总结回顾3. 参考资料3.1. books Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. searching 查找（Searching）就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。 1.1. 查找概论 查找表（Search Table）是由同一类型的数据元素（或记录）构成的集合。 关键字（Key）是数据元素中某个数据项的值，又称为键值，用它可以标识一个数据元素。 若此关键字可以唯一的标识一个记录，则称此关键字为主关键字（Primary Key）。 对于那些可以识别多个数据元素（或记录）的关键字，我们称为次关键字（Secondary Key）。 查找（Searching）就是根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。 查找表按照操作方式来分有两大种：静态查找表和动态查找表。 静态查找表（Static Search Table）：只作查找操作的查找表。它的主要操作有： 查询某个“特定的”数据元素是否在查找表中 检索某个“特定的”数据元素和各种属性。 动态查找表（Dynamic Search Table）：在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素。显然动态查找表的操作就是两个： 查找时插入数据元素 查找时删除数据元素 为了提高查找的效率，我们需要专门为查找操作设置数据结构，这种面向查找操作的数据结构称为查找结构。 1.2. 查找方法 顺序表查找 有序表查找 线性索引查找 二叉排序树查找 散列表查找 2. 总结回顾 首先，介绍了，查找表，记录，关键字，主关键字，静态查找表，动态查找表，等，这些概念。 然后，对于顺序表查找来说，尽管很土（简单），但它却是后面很多查找的基础， 注意设置“哨兵”的技巧，可以使得本已经很难提升的简单算法里还是提高了性能。 有序查找 折半查找， 插值查找， 斐波那契查找。 线性索引查找， 稠密索引， 分块索引， 倒排索引。 二叉排序树，是动态查找最重要的数据结构。 平衡二叉树（AVL树） B树（2-3树），2-3-4树，B+树。 散列表 3. 参考资料 3.1. books 《大话数据结构》 "},"algorithm/searching/sequential_search.html":{"url":"algorithm/searching/sequential_search.html","title":"顺序表查找","keywords":"","body":"1.1. 顺序表查找 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 顺序表查找 顺序查找（Sequential Search）又叫线性查找，是最基本的查找技术，它的查找过程是：从表中第一个（或最后一个）记录开始，逐个进行记录的关键字和给定值比较，若某个记录的关键字和给定值相等，则查找成功，找到所查的记录；如果直到最后一个（或第一个）记录，其关键字和给定值比较都不等时，则表中没有所查的记录，查找不成功。 对于这种顺序查找算法来说， 查找成功最好的情况就是第一个位置就找到了，算法时间复杂度为O(1), 最坏的情况是在最后一位置才找到，需要n次比较，时间复杂度为O(n)， 当查找不成功时，需要n+1次比较，时间复杂度为O(n)。 我们之前推导过，关键字在任何一位置的概率是相同的，所以平均查找次数为(n+1)/2, 所以最终时间复杂度还是O(n)。 "},"algorithm/searching/sorted_search.html":{"url":"algorithm/searching/sorted_search.html","title":"有序表查找","keywords":"","body":"1.1. 有序表查找1.1.1. 折半查找1.1.2. 插值查找1.1.3. 斐波那契查找 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 有序表查找 1.1.1. 折半查找 折半查找（Binary Search）技术，又称为二分查找。 它的前提是线性表中的记录必须是关键码有序（通常从小到大有序），线性表必须采用顺序存储。 折半查找的基本思想是：在有序表中，取中间记录作为比较对象，若给定值与中间记录的关键字相等，则查找成功；若给定值小于中间记录的关键字，则在中间记录的左半区继续查找；若给定值大于中间记录的关键字，则在中间记录的右半区继续查找。不断重复上述过程，直到查找成功，或所有查找区域无记录，查找失败为止。 最坏情况是查找到关键字或查找失败的次数为[log2n]+1. 最好情况1次。 因此最终我们折半算法的时间复杂度为O(logn), 它显然远远好于顺序查找的O(n)时间复杂度了。 折半查找的前提条件是需要有序表顺序存储，对于静态查找表，一次排序后不再变化，这样的算法已经比较好了。但对于需要频繁执行插入或删除操作的数据集来说，维护有序的排序会带来不小的工作量，那就不建议使用。 1.1.2. 插值查找 插值查找（Interpolation Search）是根据要查找的关键字key与查找表中最大最小记录的关键字比较后的查找方法，其核心就在于插值的计算公式 (key - a[low]) / (a[high] - a[low]) 1.1.3. 斐波那契查找 "},"algorithm/searching/index_search.html":{"url":"algorithm/searching/index_search.html","title":"线性索引查找","keywords":"","body":"1.1. 线性索引查找1.1.1. 稠密索引1.1.2. 分块索引1.1.3. 倒排索引 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 线性索引查找 数据结构的最终目的是提高数据的处理速度，索引是为了加快查找速度而设计的一种数据结构。 索引就是把一个关键字与它对应的记录相关联的过程，一个索引由若干个索引项构成，每个索引项至少应包含关键字和其对应的记录在存储器中的位置等信息。 索引技术是组织大型数据库以及磁盘文件的一种重要技术。 索引按照结构可以分为线性索引，树形索引和多级索引。 我们这里就只介绍线性索引技术。 所谓线性索引就是将索引项集合组织为线性结构，也称为索引表。 我们重点介绍三种线性索引：稠密索引，分块索引和倒排索引。 1.1.1. 稠密索引 稠密索引是指在线性索引中，将数据集中的每个记录对应一个索引项，如图8-5-2所示。 对于稠密索引这个索引表来说，索引项一定是按照关键码有序的排列。 索引项有序也就意味着，我们要查找关键字时，可以用到折半，插值，斐波那契等有序查找算法，大大提高了效率。 这显然是稠密索引优点，但是如果数据集非常大，比如上亿，那也就意味着索引也得同样的数据集长度规模，对于内存有限的计算机来说，可能就需要反复去访问磁盘，查找性能反而大大下降了。 1.1.2. 分块索引 稠密索引因为索引项与数据集的记录个数相同，所以空间代价很大。为了减少索引项个数，我们可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数。 分块有序，是把数据集的记录分成了若干块，并且这些块需要满足两个条件： 块内无序，即每一块内的记录不要求有序。 块间有序，例如第二块所有记录的关键字均要大于第一块中所有记录的关键字。 对于分块有序的数据集，将每块对应一个索引项，这种索引方法叫做分块索引。 如图8-5-4所示，我们定义的分块索引的索引项结构分三个数据项： 最大关键码， 存储了块中的记录个数，以便于循环时使用 用于指向块首数据元素的指针。 在分块索引表中查找，就是分两步进行： 在分块索引表中查找关键字所在的块。由于分块索引表是块间有序的，因此很容易利用折半，插值等算法得到结果。 根据块首指针找到相应的块，并在块中顺序查找关键码。因为块中可以是无序的，因此只能顺序查找。 分析一下分块索引的平均查找长度。 可见，分块索引的效率比之顺序查找的O(n)是高了不少，不过显然它与折半查找的O(logn)相比还有不少的差距。因此在确定所在块的过程中，由于块间有序，所以可以应用折半，插值等手段来提高效率。 总的来说，分块索引在兼顾了对细分快不需要有序的情况下，大大增加了整体查找的速度，所以普遍被用于数据库表查找等技术的应用当中。 1.1.3. 倒排索引 在这里这张单词表就是索引表，索引项的通用结构是： 次关键码， 记录号表 其中记录号表存储具有相同次关键字的所有记录的记录号（可以是指向记录的指针或是该记录的主关键字）。这样的索引方法就是倒排索引（inverted index）。 "},"algorithm/searching/binary_sort_tree_search.html":{"url":"algorithm/searching/binary_sort_tree_search.html","title":"二叉排序树查找","keywords":"","body":"1.1. 二叉排序树1.1.1. 二叉排序树查找操作1.1.2. 二叉排序树插入操作1.1.3. 二叉排序树删除操作1.1.4. 二叉排序树总结1.2. 平衡二叉树（AVL树）1.3. 多路查找树（B树） Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 二叉排序树 有没有一种既可以使得插入和删除效率不错，又可以比较高效率的实现查找的算法呢？ 也就是说，若我们现在需要对集合{62,88,58,47,35,73,51,99,37,93}做查找，在我们打算创建此集合时就考虑用二叉树结构，而且是排好序的二叉树来创建。 这样我们就得到了一棵二叉树，并且当我们对它进行中序遍历时，就可以得到一个有序的序列{35,37,47,51,58,62,73,88,93,99}, 所以我们通常称它为二叉排序树。 二叉排序树（Binary Sort Tree），又称为二叉查找树。它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有节点的值均小于它的根结构的值 若它的右子树不空，则右子树上所有节点的值均大于它的根节点的值 它的左，右子树也分别为二叉排序树 1.1.1. 二叉排序树查找操作 1.1.2. 二叉排序树插入操作 1.1.3. 二叉排序树删除操作 1.1.4. 二叉排序树总结 总之，二叉排序树是以链接的方式存储，保持了链接存储结构在执行插入或删除操作时不用移动元素的优点，只要找到合适的插入和删除位置后，仅需修改链接指针即可。插入删除的时间性能比较好。 而对于二叉排序树的查找，走的就是从根节点到要查找的节点的路径，其比较次数等于给定值的节点在二叉排序树中的层数。 极端情况，最少为1次，即根节点就是要找的节点，最多也不会超过树的深度。 也就是说，二叉排序树的查找性能取决于二叉排序树的形状。 可问题就在于，二叉排序树的形状是不确定的。 也就是说，我们希望二叉排序树是比较平衡的，即其深度与完全二叉树相同，均为[log2n]+1,那么查找的时间复杂度也就为O(logn)，近似于折半查找，事实上，图8-6-18的左图也不够平衡，明显的左重右轻。 不平衡的最坏情况就是像图8-6-18右图的斜树，查找时间复杂度为O(n), 这等同于顺序查找。 因此，如果我们希望对一个集合按二叉排序树查找，最好是把它构建成一颗平衡的二叉排序树。 这样我们就引申出另一个问题，如何让二叉排序树平衡的问题。 1.2. 平衡二叉树（AVL树） 1.3. 多路查找树（B树） "},"algorithm/searching/hash_search.html":{"url":"algorithm/searching/hash_search.html","title":"散列表查找","keywords":"","body":"1.1. 散列表查找（哈希表）概述 Title Date Modified Category searching 2019-07-09 12:00 2019-07-09 12:00 algorithm 1.1. 散列表查找（哈希表）概述 "},"algorithm/sort/":{"url":"algorithm/sort/","title":"sort","keywords":"","body":"1. sort1.1. 排序的稳定性1.2. 内排序与外排序1.3. 排序用到的结构与函数1.4. 七种排序算法1.5. 总结回顾2. 参考资料2.1. books Title Date Modified Category sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. sort 我们在排序问题中，通常将数据元素称为记录。显然我们输入的是一个记录集合，输出的也是一个记录集合，所以说，可以将排序看成是线性表的一种操作。 排序的依据是关键字之间的大小关系，那么，对同一个记录集合，针对不同的关键字进行排序，可以得到不同序列。 1.1. 排序的稳定性 也正是由于排序不仅是针对主关键字，那么对于次关键字，因为待排序的记录序列中可能存在两个或两个以上的关键字相等的记录，排序结果可能会存在不唯一的情况，我们给出了稳定与不稳定排序的定义。 假设ki=kj（1 1.2. 内排序与外排序 根据在排序过程中待排序的记录是否全部被放置在内存中，排序分为：内排序和外排序。 内排序是在排序整个过程中，待排序的所有记录全部被放置在内存中。 外排序是由于排序的记录个数太多，不能同时放置在内存，整个排序过程需要在内外存之间多次交换数据才能进行。 对于内排序来说，排序算法的性能主要是受3个方面影响： 时间性能 辅助空间 算法复杂性 根据排序过程中借助的主要操作，我们把内排序分为： 插入排序， 交换排序， 选择排序， 归并排序。 本章一共要讲解七种排序的算法，按照算法的复杂度分为两大类， 冒泡排序，简单选择排序，直接插入排序属于简单算法。 希尔排序，堆排序，归并排序，快速排序属于改进算法。 1.3. 排序用到的结构与函数 为了讲清楚排序算法的代码，我先提供一个用于排序用的顺序表结构，此结构也将用于之后我们要讲的所有排序算法。 #define MAXSIZE 10 /* 用于要排序数组个数最大值，可根据需要修改 */ typedef struct { int r[MAXSIZE+1]; /* 用于存储要排序数组，r[0]用作哨兵或临时变量 */ int length; /* 用于记录顺序表的长度 */ }SqList; 另外，由于排序最最常用到的操作是数组两元素的交换，我们将它写成函数，在之后的讲解中会大量的用到。 /* 交换L中数组r的下标为i和j的值 */ void swap(SqList *L, int i, int j) { int temp = L->r[i]; L->r[i] = L->r[j]; L->r[j] = temp; } 1.4. 七种排序算法 冒泡排序（Bubble Sort） 简单选择排序（Simple Selection Sort） 直接插入排序（Straight Insertion Sort） 希尔排序（Shell Sort） 堆排序（Heap Sort） 归并排序（Merging Sort） 快速排序（Quick Sort） 1.5. 总结回顾 首先，我们讲了排序的定义，并提到了排序的稳定性， 排序稳定对于某些特殊需求来说是至关重要的，因此在排序算法中，我们需要关注此算法的稳定性如何。 我们根据将排序记录是否全部被放置在内存中，将排序分为 内排序 与 外排序 两种。 外排序需要在内外存之间多次交换数据才能进行。 我们本章主要讲的是内排序的算法。 根据排序过程中借助的主要操作，我们将内排序分为： 插入排序 交换排序 选择排序 归并排序。 之后介绍的7种排序法，就分别是各种分类的代表算法， 事实上，目前还没有十全十美的排序算法，有优点就会有缺点，即使是快速排序法，也只是在整体性能上优越，它也存在排序不稳定，需要大量辅助空间，对少量数据排序无优势等不足。 因此我们就来从多个角度来剖析一下提到的各种排序的长与短。 我们将7种算法的各种指标进行对比。 从算法的简单性来看，我们将7种算法分为两类： 简单算法：冒泡，简单选择，直接插入 改进算法：希尔，堆，归并，快速 从平均情况来看，显然最后3种改进算法要胜过希尔排序，并远远胜过前3种简单算法。 从最好情况看，反而冒泡和直接插入排序要更胜一筹，也就是说，如果你的待排序序列总是基本有序，反而不应该考虑4种复杂的改进算法。 从最坏情况看，堆排序与归并排序又强过快速排序以及其他简单排序。 从空间复杂度来说，归并排序，快速排序，对空间有要求，反而堆排序等对空间要求是O(1)。 从稳定性来看，归并排序最好，对于非常在乎排序稳定性的应用中，归并排序是个好算法。 从待排序记录的个数上来说，待排序的个数n越小，采用简单排序方法越合适。反之，n越大，采用改进排序方法越合适。 3种简单排序算法的移动次数比较，此时简单选择排序就变得非常有优势，原因在于，它通过大量比较后选择明确记录进行移动，有的放矢。因此对于数据量不是很大而记录的关键字信息量较大的排序要求，简单排序算法是占优的。 总之，从综合各项指标来说，经过优化的快速排序是性能最好的排序算法，但是不同的场合我们也应该考虑使用不同的算法来应对它。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/bubble_sort.html":{"url":"algorithm/sort/bubble_sort.html","title":"冒泡排序（Bubble Sort）","keywords":"","body":"1. bubble sort1.1. 最简单排序实现1.2. 冒泡排序算法1.3. 冒泡排序优化1.4. 冒泡排序复杂度分析2. 参考资料2.1. books Title Date Modified Category bubble sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. bubble sort 冒泡排序（Bubble Sort）是一种交换排序，它的基本思想是：两两比较相邻记录的关键字，如果反序则交换，直到没有反序的记录为止。 1.1. 最简单排序实现 冒泡的实现在细节上可以有很多种变化，我们将分别就3种不同的冒泡实现代码，来讲解冒泡排序的思想。这里，我们就先来看看比较容易理解的一段。 /* 对顺序表L作交换排序（冒泡排序初级版） */ void BubbleSort0(SqList *L) { int i, j; for (i = 1; i length; i++) { for (j = i + 1; j length; j++) { if (L->r[i] > L->r[j]) { swap(L, i, j); /* 交换L->r[i] 与 L->r[j]的值 */ } } } } 这段代码严格意义上说，不算是标准的冒泡排序算法，因为它不满足“两两比较相邻记录”的冒泡排序思想，它更应该是最最简单的交换排序而已。 它的思路就是让每一个关键字，都和它后面的每一个关键字比较，如果大则交换，这样第一位置的关键字在一次循环后一定变成最小值。 它应该算是最最容易写出的排序代码了，不过这个简单易懂的代码，却是有缺陷的。观察后发现，在排序好1和2的位置后，对其余关键字的排序没有什么帮助（数字3反而还被换到了最后一位）。也就是说，这个算法的效率是非常低的。 1.2. 冒泡排序算法 我们来看看正宗的冒泡算法，有没有什么改进的地方。 /* 对顺序表L作冒泡排序 */ void BubbleSort(SqList *L) { int i, j; for (i = 1; i length; i++) { for (j = L->length-1; j >= i; j--) /* 注意j是从后往前循环 */ { if (L->r[j] > L->r[j+1]) /* 若前者大于后者（注意这里与上一算法差异） */ { swap(L, j, j+1); /* 交换L->r[j] 与 L->r[j+1] 的值 */ } } } } 图中较小的数字如同气泡般慢慢浮到上面，因此就将此算法命名为冒泡算法。 1.3. 冒泡排序优化 这样的冒泡程序是否还可以优化呢？答案是肯定的。 增加一个标记变量flag来实现这一算法的改进。 void BubbleSort2(SqList *L) { int i, j; Status flag = TRUE; /* flag用来作为标记 */ for (i = 1; i length && flag; i++) /* 若flag为false则退出循环 */ { flag = FALSE; /* 初始化为false */ for (j = L->length - 1; j >= i; j--) { if (L->r[j] > L->r[j+1]) { swap(L, j, j+1); /* 交换L->r[j] 与 L->r[j+1] 的值 */ flag = TRUE; /* 如果有数据交换，则flag为true */ } } } } 1.4. 冒泡排序复杂度分析 时间复杂度。 最好的情况，也就是要排序的表本身就是有序的，那么我们比较次数，根据最后改进的代码，可以推断出就是n-1次的比较，没有数据交换，时间复杂度为O(n)。 最坏的情况，即待排序表是逆序的情况，此时需要比较1+2+3+…+(n-1) = n(n-1)/2 次，并作等数量级的记录移动。因此，总的时间复杂度为O(n^2)。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/select_sort.html":{"url":"algorithm/sort/select_sort.html","title":"简单选择排序（Simple Selection Sort）","keywords":"","body":"1. select sort1.1. 简单选择排序复杂度分析2. 参考资料2.1. books Title Date Modified Category select sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. select sort 简单选择排序法（Simple Selection Sort）就是通过n-1次关键字间的比较，从n-i+1个记录中选出关键字最小的记录，并和第i(1 /* 对顺序表L作简单选择排序 */ void SelectSort(SqList *L) { int i, j, min; for (i = 1; i length; i++) { min = i; /* 将当前下标定义为最小值下标 */ for (j = i + 1; j length; j++) /* 循环之后的数据 */ { if (L->r[min] > L->r[j]) /* 如果有小于当前最小值的关键字 */ { min = j; /* 将此关键字的下标赋值给min */ } } if (i != min) /* 若min不等于i，说明找到最小值，交换 */ { swap(L, i, min); /* 交换L->r[i] 与 L->r[min]的值 */ } } } 1.1. 简单选择排序复杂度分析 从简单选择排序的过程来看，它最大的特点就是交换移动数据次数相当少，这样也就节约了相应的时间。 分析它的时间复杂度发现， 无论最好最差的情况，其比较次数都是一样的多，第i趟排序需要进行n-i次关键字的比较，此时需要比较n-1 + n-2 + …+ 1 = n(n-1)/2 次。 而对于交换次数而言，当最好的时候，交换为0次，最差的时候，也就是初始降序时，交换次数为n-1次， 基于最终的排序时间是比较与交换的次数总和，因此，总的时间复杂度依然是O(n^2)。 应该说，尽管与冒泡排序同为O(n^2)，但简单选择排序的性能上还是要略优于冒泡排序。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/insert_sort.html":{"url":"algorithm/sort/insert_sort.html","title":"直接插入排序（Straight Insertion Sort）","keywords":"","body":"1. insert sort1.1. 直接插入排序复杂度分析2. 参考资料2.1. books Title Date Modified Category insert sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. insert sort 直接插入排序（Straight Insertion Sort）的基本操作是将一个记录插入到已经排好序的有序表中，从而得到一个新的，记录数增1的有序表。 /* 对顺序表L作直接插入排序 */ void InsertSort(SqList *L) { int i, j; for (i = 2; i length; i++) { if (L->r[i] r[i - 1]) /* 需将L->r[i]插入有序子表 */ { L->r[0] = L->r[i]; /* 设置哨兵 */ for (j = i-1; L->r[j] > L->r[0]; j--) { L->r[j+1] = L->r[j]; /* 记录后移 */ } L->r[j+1] = L->r[0]; /* 插入到正确位置 */ } } } 1.1. 直接插入排序复杂度分析 从空间上来看，它只需要一个记录的辅助空间，因此关键是看它的时间复杂度。 当最好的情况，O(n)。 最坏的情况. 平均情况n^2/4。 直接插入排序法的时间复杂度为O(n^2). 同样的O(n^2)时间复杂度，直接插入排序法比冒泡和简单选择排序的性能要好一些。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/shell_sort.html":{"url":"algorithm/sort/shell_sort.html","title":"希尔排序（Shell Sort）","keywords":"","body":"1. shell sort1.1. 希尔排序复杂度分析2. 参考资料2.1. books Title Date Modified Category shell sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. shell sort 希尔排序（Shell Sort）。希尔排序是D.L.Shell于1959年提出来的一种排序算法，在这之前排序算法的时间复杂度基本都是O(n^2)的，希尔排序算法是突破这个时间复杂度的第一批算法之一。 所谓的 基本有序，就是小的关键字基本在前面，大的基本在后面，不大不小的基本在中间，像{2,1,3,6,4,7,5,8,9}这样可以称为基本有序了。 将相距某个“增量”的记录组成一个子序列，这样才能保证在子序列内分别进行直接插入排序后得到的结果是基本有序而不是局部有序。 /* 对顺序表L作希尔排序 */ void ShellSort(SQList *L) { int i, j; int increment = L->length; do { increment = increment / 3 + 1; /* 增量序列 */ for (i = increment + 1; i length; i++) { if (L->r[i] r[i - increment]) { /* 需将L->r[i] 插入有序增量子表 */ L->r[0] = L->r[i]; /* 暂存在L->r[0] */ for (j = i - increment; j > 0 && L->r[0] r[j + increment] = L->r[j]; /* 记录后移，查找插入位置 */ } L->r[j + increment] = L->r[0]; /* 插入 */ } } } while (increment > 1); } 1.1. 希尔排序复杂度分析 希尔排序的关键并不是随便分组后各自排序，而是将相隔某个“增量”的记录组成一个子序列，实现跳跃式的移动，使得排序的效率提高。 增量序列的最后一个增量值必须等于1才行。 不管怎么说，希尔排序算法的发明，使得我们终于突破了慢速排序的时代（超越了时间复杂度为O(n^2)），之后，相应的更为高效的排序算法也就相继出现了。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/heap_sort.html":{"url":"algorithm/sort/heap_sort.html","title":"堆排序（Heap Sort）","keywords":"","body":"1. heap sort1.1. 堆1.2. 堆排序算法1.3. 堆排序复杂度分析2. 参考资料2.1. books Title Date Modified Category heap sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. heap sort 1.1. 堆 堆是具有下列性质的完全二叉树： 每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆（例如图9-7-2左图所示）； 或者每个节点的值都小于或等于其左右孩子节点的值，称为小顶堆（例如图9-7-2右图所示）。 如果将图9-7-2的大顶堆和小顶堆用层序遍历存入数组，则一定满足上面的关系表达，如图9-7-3所示。 我们现在讲这个堆结构，其目的就是为了堆排序用的。 1.2. 堆排序算法 堆排序（Heap Sort）就是利用堆（假设利用大顶堆）进行排序的方法。 它的基本思想是， 将待排序的序列构造成一个大顶堆。此时，整个序列的最大值就是堆顶的根节点。将它移走（其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值），然后将剩余的n-1个序列重新构造成一个堆，这样就会得到n个元素中的次小值。如此反复执行，便能得到一个有序序列了。 相信大家有些明白堆排序的基本思想了，不过要实现它还需要解决两个问题： 如何由一个无序序列构建成一个堆？ 如何在输出堆顶元素后，调整剩余元素成为一个新的堆？ 要解释清楚它们，让我们来看代码。 /* 对顺序表L进行堆排序 */ void HeapSort(SqList *L) { int i; for (i = L->length / 2; i > 0; i--) /* 把L中的r构建成一个大顶堆 */ { HeapAdjust(L, i, L->length); } for (i = L->length; i > 1; i--) { swap(L, 1, i); /* 将堆顶记录和当前未经排序子序列的最后一个记录交换 */ HeapAdjust(L, 1, i-1); /* 将L->r[1...i-1]重新调整为大顶堆 */ } } 从代码中也可以看出，整个排序过程分为两个for循环。 第一个循环要完成的就是将现在的待排序序列构建成一个大顶堆。 第二个循环要完成的就是逐步将每个最大值的根节点与末尾元素交换，并且再调整其成为大顶堆。 既然已经弄清楚i的变化是在调整哪些元素了，现在我们来看关键的HeapAdjust（堆调整）函数是如何实现的。 /* 已知L->r[s..m]中记录的关键字除L->r[s]之外均满足堆的定义 */ /* 本函数调整L->r[s]的关键字，使L->r[s..m]成为一个大顶堆 */ void HeapAdjust(SqList *L, int s, int m) { int twmp, j; temp = L->r[s]; for (j = 2 * s; j r[j] r[j+1]) { ++j; /* j为关键字中较大的记录的下标 */ } if (temp >= L->r[j]) { break; /* rc应插入在位置s上 */ } L->r[s] = L->r[j]; s = j; } L->r[s] = temp; /* 插入 */ } 1.3. 堆排序复杂度分析 整个构建堆的时间复杂度为O(n)。 在正式排序时，第i次取堆顶记录重建堆需要用O(logi)的时间（完全二叉树的某个节点到根节点的距离为[log2i] + 1）, 并且需要取n-1次堆顶记录，因此，重建堆的时间复杂度为O(nlogn)。 所以总体来说，堆排序的时间复杂度为O(nlogn)。由于堆排序对原始记录的排序状态并不敏感，因此它无论是最好，最坏和平均时间复杂度均为O(nlogn)。这在性能上要远远好于冒泡，简单选择，直接插入的O(n^2)的时间复杂度了。 空间复杂度上，它只有一个用来交换的暂存单元，也非常不错。不过由于记录的比较与交换是跳跃式进行，因此堆排序也是一种不稳定的排序方法。 另外，由于初始构建堆所需的比较次数较多，因此，它并不适合待排序序列个数较少的情况。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/merging_sort.html":{"url":"algorithm/sort/merging_sort.html","title":"归并排序（Merging Sort）","keywords":"","body":"1. merging sort2. 参考资料2.1. books Title Date Modified Category merging sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. merging sort 归并排序（Merging Sort）就是利用归并的思想实现的排序方法。 它的原理是 假设初始序列含有n个记录，则可以看成是n个有序的子序列，每个子序列的长度为1，然后两两归并，得到[n/2]（[x]表示不小于x的最小整数）个长度为2或1的有序子序列；再两两归并，…, 如此重复，直至得到一个长度为n的有序序列为止，这种排序方法称为2路归并排序。 2. 参考资料 2.1. books 《大话数据结构》 "},"algorithm/sort/quick_sort.html":{"url":"algorithm/sort/quick_sort.html","title":"快速排序（Quick Sort）","keywords":"","body":"1. quick sort2. 参考资料2.1. books Title Date Modified Category quick sort 2019-07-09 12:00 2019-07-09 12:00 algorithm 1. quick sort 快速排序（Quick Sort）的基本思想是：通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序的目的。 2. 参考资料 2.1. books 《大话数据结构》 "},"compiler/":{"url":"compiler/","title":"compiler","keywords":"","body":" Title Date Modified Category compiler 2019-06-06 12:00 2019-05-29 12:00 compiler "},"compiler/compiler.html":{"url":"compiler/compiler.html","title":"编程语言泛讲","keywords":"","body":"1. 编程语言的分类1.1. 解释型与编译型之分1.1.1. 解释型1.1.2. 编译型1.2. 动态类型与静态类型之分1.2.1. 动态1.2.2. 静态1.3. 强类型与弱类型之分1.3.1. 强类型1.3.2. 弱类型2. 编译器前端与编译器后端2.1. 编译器前端(Front End)2.2. 编译器后端(Back End)3. 编程语言的开发方法3.1. 工具生成3.2. 手工构造4. 编程语言的开发过程4.1. 编程语言的设计4.1.1. bnf, ebnf定义文法4.1.2. 地铁图描述文法4.1.3. 少许理论知识4.2. 词法分析4.3. 语法分析4.4. 抽象语法树4.5. 语义分析4.6. 符号管理4.7. 生成中间代码4.8. 生成汇编代码4.9. 二进制格式4.10. 二进制生成，汇编器4.11. 可执行文件生成，链接器4.12. 错误处理4.13. 优化5. CPU架构6. 虚拟机的设计6.1. 字节码文件的解析6.2. 运行时数据区6.2.1. 栈(stack)的设计6.2.2. 堆(heap)的设计6.2.3. 局部变量6.2.4. 全局变量6.3. 汇编指令与机器码的设计6.4. 解释器的设计6.5. GC垃圾回收7. JIT8. 编程语言分类漫谈9. 编程语言开发示例demo10. 参考资料10.1. books Title Date Modified Category compiler 2019-06-06 12:00 2019-05-29 12:00 compiler 禁止转载 一些图文 出自参考书籍中的截图，如有侵权，请联系删除 1. 编程语言的分类 1.1. 解释型与编译型之分 编程语言可分为解释型和编译型。 1.1.1. 解释型 源代码转换为某种中间状态，如语法树，语法树直接执行 源代码，词法分析，生成token串，语法分析，生成分析树，语法分析树，或语法树，抽象语法树，执行 纯粹的解释型，读一句，解释执行一句，执行到有语法错误的时候才会报错 字节码，解释器运行字节码, 也可称为虚拟机 将抽象语法树转换成字节码，字节码可在虚拟机里执行 也有编译的一个过程 1.1.2. 编译型 编译过程 词法分析, 生成token串，语法分析，生成抽象语法树，生成中间代码，生成各个CPU架构的汇编代码，生成各个平台的二进制， 二进制：真实CPU架构下的二进制，或虚拟机下的二进制（操作码或字节码） 链接过程 链接器，链接成可执行文件 1.2. 动态类型与静态类型之分 1.2.1. 动态 1.2.2. 静态 1.3. 强类型与弱类型之分 1.3.1. 强类型 1.3.2. 弱类型 2. 编译器前端与编译器后端 2.1. 编译器前端(Front End) 从源代码到抽象语法树的过程 2.2. 编译器后端(Back End) 从抽象语法树到二进制的过程 3. 编程语言的开发方法 工具型 手工型 3.1. 工具生成 用一些工具，定义一些文法，通过工具输入文法，自动生成编译器代码。 或者 用正则表达式解析源代码 yacc,lex Javacc 3.2. 手工构造 自顶向下的分析，编写代码 4. 编程语言的开发过程 首先进行编程语言的设计，然后是词法分析，语法分析，语义分析，生成抽象语法树，生成中间代码，生成操作码， 4.1. 编程语言的设计 编程语言的设计，有两种文法表示 4.1.1. bnf, ebnf定义文法 BNF（巴科斯范式，Backus Normal Form） EBNF(扩展巴克斯范式，Extend BNF) 示例： 4.1.2. 地铁图描述文法 4.1.3. 少许理论知识 消除左递归（LL（1）） LL(1) LALR(1) 理解 i++ + ++i 怎么执行的 TODO 4.2. 词法分析 将源代码分割成若干个记号（token）的过程。 首先定义token(记号)，用ebnf文法定义词法 每个token有相应的有限自动机 顺序读取源代码文件每个字符，用token的有限自动机来选择生成不同的token 4.3. 语法分析 即从记号构建分析树（parse tree）的过程。分析树也叫作语法树（syntax tree）或抽象语法树（abstract syntax tree，AST）。 用ebnf定义文法，根据文法写不同的解析代码 4.4. 抽象语法树 终结符与非终结符 可直接编写eval方法，执行每个节点 4.5. 语义分析 检查AST中，是否有语义错误，比如不能除0等 4.6. 符号管理 需要将各个级别的变量，保存到环境变量中，并标记好级别， 在eval的时候，如果生成变量，就new Var，并记录到环境变量中， 如果计算用到了变量，就从环境变量中取出Var用于计算 如果推出当前级别的空间，就释放当前级别的空间内的变量,作用域管理 4.7. 生成中间代码 符号表，语义分析，中间代码优化等。 4.8. 生成汇编代码 了解不同CPU架构的汇编语言，或自定义虚拟机的汇编语法 汇编代码优化 4.9. 二进制格式 4.10. 二进制生成，汇编器 了解各个平台的可执行文件结构，格式，编写汇编器，生成二进制 4.11. 可执行文件生成，链接器 链接成可执行文件 4.12. 错误处理 伴随着每个过程，都需要有错误处理，和友好的错误提示 4.13. 优化 中间代码优化，汇编代码优化，等，每一部分都有优化部分 5. CPU架构 intel x86 ARM Power TODO 6. 虚拟机的设计 模拟真实CPU架构 定义栈空间，定义堆空间，定义寄存器，等数据结构 6.1. 字节码文件的解析 读取文件，读取一个个指令，巨大的switch case结构 6.2. 运行时数据区 6.2.1. 栈(stack)的设计 栈帧 6.2.2. 堆(heap)的设计 6.2.3. 局部变量 6.2.4. 全局变量 6.3. 汇编指令与机器码的设计 6.4. 解释器的设计 6.5. GC垃圾回收 7. JIT java，.NET Framework都具备在运行的同时将字节码转换为机器码的功能，这叫做JIT，Just-In-Time编译技术。 8. 编程语言分类漫谈 JVM虚拟机，Java，Groovy，Scala，Clojure，Jython，JRuby等。 CPython Pypy go js 9. 编程语言开发示例demo py.calc解释型语言 10. 参考资料 10.1. books 《Lua设计与实现》 《Lua 源码欣赏》 《Go 1.5 源码剖析》 《Python源码剖析--深度探索动态语言核心技术》 《编译器构造（Java语言版）》 《自己动手写Java虚拟机》 《揭秘Java虚拟机-JVM设计原理与实现》 《自制编程语言》 《两周自制脚本语言》 《自制编译器》 《自己动手构造编译系统 编译、汇编与链接》 《自己动手写编译器、链接器》 《C编译器剖析》 《可变目标C编译器：设计与实现》 《深入分析GCC》 《高级编译器设计与实现》 《编译系统透视 图解编译原理》 《编译原理》 《现代编译原理：c语言描述》 《程序是怎样跑起来的》 《计算的本质：深入剖析程序和计算机》 "},"compiler/ollvm.html":{"url":"compiler/ollvm.html","title":"ollvm","keywords":"","body":"1. 做的事情2. 名词介绍2.1. gcc2.2. llvm2.3. clang2.4. ollvm3. llvm相关架构与原理4. ollvm扩展内容5. demo6. 攻与防7. github8. 参考书籍9. links Title Date Modified Category compiler 2019-06-06 12:00 2019-05-29 12:00 compiler 1. 做的事情 之前已经做的东西，资源加密，符号混淆 本次做的事情，代码膨胀，变形 2. 名词介绍 2.1. gcc GNU编译器套件（GNU Compiler Collection）包括C、C++、Objective-C、Fortran、Java、Ada和Go语言的前端，也包括了这些语言的库（如libstdc++、libgcj等等）。GCC的初衷是为GNU操作系统专门编写的一款编译器。GNU系统是彻底的自由软件。此处，“自由”的含义是它尊重用户的自由。 2.2. llvm LLVM是构架编译器(compiler)的框架系统，以C++编写而成，用于优化以任意程序语言编写的程序的编译时间(compile-time)、链接时间(link-time)、运行时间(run-time)以及空闲时间(idle-time)，对开发者保持开放，并兼容已有脚本。 2.3. clang Clang是一个C语言、C++、Objective-C语言的轻量级编译器。源代码发布于BSD协议下。Clang将支持其普通lambda表达式、返回类型的简化处理以及更好的处理constexpr关键字。 2.4. ollvm OLLVM（Obfuscator-LLVM）是瑞士西北应用科技大学安全实验室于2010年6月份发起的一个项目，这个项目的目标是提供一个LLVM编译套件的开源分支，能够通过代码混淆和防篡改，增加对逆向工程的难度，提供更高的软件安全性。目前，OLLVM已经支持LLVM-4.0.1版本。OLLVM的混淆操作就是在中间表示IR层，通过编写Pass来混淆IR，然后后端依据IR来生成的目标代码也就被混淆了。得益于LLVM的设计，OLLVM适用LLVM支持的所有语言（C, C++, Objective-C, Ada 和 Fortran）和目标平台（x86, x86-64, PowerPC, PowerPC-64, ARM, Thumb, SPARC, Alpha, CellSPU,MIPS, MSP430, SystemZ, 和 XCore） 3. llvm相关架构与原理 https://llvm.org/docs/ http://www.aosabook.org/en/llvm.html https://llvm.org/docs/WritingAnLLVMPass.html 4. ollvm扩展内容 https://github.com/obfuscator-llvm/obfuscator/wiki -fla 控制流扁平化的PASS参数 -sub指令替换的PASS参数 -bcf虚假控制流的PASS参数 https://blog.csdn.net/chrisnotfound/article/details/79026449 5. demo 用Armariris演示编译一个简单的C源码，试用各种参数。 对编译出的二进制进行分析，查看文件大小，用ida分析二进制，展示流图。 6. 攻与防 https://bbs.pediy.com/thread-217727.htm http://www.freebuf.com/articles/terminal/130142.html 7. github llvm ollvm Hikari Armariris mcsema 8. 参考书籍 《iOS应用逆向与安全》 《编译与反编译技术实战》 《LLVM Cookbook中文版》 9. links gcc clang LLVM和GCC的区别 "},"lang/":{"url":"lang/","title":"lang","keywords":"","body":" Title Date Modified Category lang 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/golang/":{"url":"lang/golang/","title":"Golang","keywords":"","body":" Title Date Modified Category golang 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/html/":{"url":"lang/html/","title":"HTML","keywords":"","body":" Title Date Modified Category html 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/js/":{"url":"lang/js/","title":"JS","keywords":"","body":" Title Date Modified Category js 2019-06-14 12:00 2019-06-14 12:00 lang "},"lang/python/":{"url":"lang/python/","title":"Python","keywords":"","body":" Title Date Modified Category python 2019-06-06 12:00 2019-05-29 12:00 lang "},"lang/c/":{"url":"lang/c/","title":"C","keywords":"","body":" Title Date Modified Category c 2019-07-09 12:00 2019-07-09 12:00 lang "},"lang/assembly/":{"url":"lang/assembly/","title":"Assembly","keywords":"","body":" Title Date Modified Category assembly 2019-07-09 12:00 2019-07-09 12:00 lang "},"unix-like/":{"url":"unix-like/","title":"Unix-like","keywords":"","body":" Title Date Modified Category linux 2019-06-06 12:00 2019-05-29 12:00 linux "},"network/":{"url":"network/","title":"network","keywords":"","body":" Title Date Modified Category network 2019-06-11 12:00 2019-06-11 12:00 network ip tcp http dns network "},"network/network.html":{"url":"network/network.html","title":"network","keywords":"","body":"1. 网络编程泛讲2. TCP/IP协议3. 网络编程基础API3.1. socket3.2. 字节序4. 高级API5. 服务器模型6. I/O模型7. 事件处理模式7.1. reactor7.2. proactor8. 并发模式9. IO复用10. 参考资料10.1. 参考书籍 Title Date Modified Category network 2019-05-29 12:00 2019-05-29 12:00 network 禁止转载 一些图文 出自参考书籍中的截图，如有侵权，请联系删除 1. 网络编程泛讲 2. TCP/IP协议 3. 网络编程基础API 3.1. socket 3.2. 字节序 4. 高级API 5. 服务器模型 6. I/O模型 7. 事件处理模式 7.1. reactor 7.2. proactor 8. 并发模式 9. IO复用 select，poll，epoll 10. 参考资料 10.1. 参考书籍 《Linux高性能服务器编程》 《后台开发 核心技术与应用实践》 《Linux多线程服务端编程：使用muduo C++网络库》 "},"network/ip.html":{"url":"network/ip.html","title":"IP","keywords":"","body":" Title Date Modified Category IP 2019-06-11 12:00 2019-06-11 12:00 network "},"network/tcp.html":{"url":"network/tcp.html","title":"TCP","keywords":"","body":" Title Date Modified Category TCP 2019-06-11 12:00 2019-06-11 12:00 network "},"network/http.html":{"url":"network/http.html","title":"HTTP","keywords":"","body":" Title Date Modified Category http 2019-06-11 12:00 2019-06-11 12:00 network "},"network/dns.html":{"url":"network/dns.html","title":"dns","keywords":"","body":" Title Date Modified Category dns 2019-06-12 12:00 2019-06-12 12:00 network "},"db/":{"url":"db/","title":"db","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db redis mongo hbase memcache "},"db/redis.html":{"url":"db/redis.html","title":"redis","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db "},"db/mongo.html":{"url":"db/mongo.html","title":"mongodb","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db "},"db/hbase.html":{"url":"db/hbase.html","title":"hbase","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db "},"db/memcache.html":{"url":"db/memcache.html","title":"memcache","keywords":"","body":" Title Date Modified Category db 2019-06-10 12:00 2019-06-10 12:00 db "},"distribution/":{"url":"distribution/","title":"Distribution","keywords":"","body":"1. 分布式1.1. CAP1.2. BASE1.3. RPC1.4. Actor2. 目录 Title Date Modified Category distribution 2019-06-10 12:00 2019-06-10 12:00 micros 1. 分布式 1.1. CAP 1.2. BASE 1.3. RPC 1.4. Actor 2. 目录 HACluster cache mq Kafka byzantine cap paxos raft registry consul etcd Zookeeper "},"distribution/hacluster.html":{"url":"distribution/hacluster.html","title":"HACluster","keywords":"","body":"1. HACluster1.1. 高可用衡量标准1.2. 常见高可用方案1.3. 虚拟服务1.3.1. DNS轮询1.3.2. 客户端调度1.3.3. 应用层负载调度1.3.4. IP层负载调度1.4. 工具2. 参考资料2.1. books1. HACluster 高可用集群（High Availability Cluster，HACluster）一般至少由两台以上服务器组成，这一组服务器作为一个整体向用户提供可靠的网络服务，其中的单台服务器就叫作节点（Node）。 高可用集群可以通过多种技术手段实现，而服务器集群是实现高可用最流行的方案之一。 集群负载在高可用集群中起着核心的控制作用，通过负载均衡软件实现故障检查和业务切换的自动化。 1.1. 高可用衡量标准 高可用（High Available，HA）集群通过系统的可靠性（reliability）和可维护性（maintainability）来衡量。 通常使用平均无故障时间（MTTF）来衡量系统的可靠性，用平均维修时间（MTTR）来衡量系统的可维护性。于是可用性被定义为：HA=MTTF/(MTTF+MTTR)*100%。 按照这个概念，具体的HA衡量标准如下： 99%为一年宕机时间不超过4天 99.9%为一年宕机时间不超过10小时 99.99%为一年宕机时间不超过1小时 99.999%为一年宕机时间不超过6分钟 1.2. 常见高可用方案 共享存储 故障转移 负载均衡 分布集群 1.3. 虚拟服务 在所有的已知的可伸缩网络服务结构中，它们都需要一个或者多个前端的负载调度器，通过调度器的调度实现虚拟服务。 在大部分网络服务中，客户端与服务端之间都有一层或者多层代理程序。这些代理程序便是一套完整的虚拟服务实现方案。这些方案可以在不同的层次上实现多台服务器的负载均衡。 目前，用集群解决网络服务性能问题的方法可分为以下四类： DNS轮询， 客户端调度， 应用层负载调度 和IP层负载调度。 1.3.1. DNS轮询 DNS轮询也称为RR-DNS(Round-Robin Domain Name System), DNS服务器会把域名轮流解析这组服务器的不同IP地址，从而将访问负载分到各台服务器上。这是它的基本工作原理，但实际上商用的DNS负载会更为复杂（成本更大），这里有以下三个明显的问题。 TTL问题 负载压力问题 系统扩展维护问题 鉴于以上这些问题，目前DNS轮询的方案一般只用于跨区域的负载调度场景，例如一定规模的集群中，通过DNS轮询使北方的用户访问北方的服务器，南方的用户访问南方的服务器，因为在跨区域的负载调度中，DNS轮询的成本最低。 1.3.2. 客户端调度 客户端调度的方式比较少见，也不具有普遍的适用性。 1.3.3. 应用层负载调度 应用层负载调度，又叫七层负载均衡，也叫反向代理负载均衡。 其结构基本上就是多台应用服务器通过高速的网络连接成一个集群系统，在前端有一个基于应用层的负载调度器。当用户访问请求到达调度器时，请求会提交给负载均衡调度器，它分析请求并根据各个应用服务器的负载情况，重写请求并发送到其中一台应用服务器，取得结果后，再返回给用户。 这种负载方案应用非常广泛， 当然他也存在一些问题。主要是系统处理开销较大，当请求到达负载均衡调度器，一直到处理结束，调度器需要进行四次从核心空间到用户空间或从用户空间到核心空间的上下文切换和内存复制；需要进行二次TCP连接，一次是从用户到调度器，另一次是从调度器到应用服务器；需要对请求进行分析和重写。这些处理都需要一定的CPU，内存和网络等资源。当服务规模扩增时，调度器本身可能会成为系统的瓶颈。 这种防范优点十分突出，自定义程度高，可以根据要求设计出满足各种场景的负载要求。 1.3.4. IP层负载调度 与应用层负载调度方案相比，IP层负载调度的可配置程度远不及前者，但是后者的效率确实是最高的，因此在很多企业中都愿意选择IP层负载调度方案。 1.4. 工具 Nginx HA LVS 2. 参考资料 2.1. books 《容器云运维实战：Docker与Kubernetes集群》 "},"distribution/cache.html":{"url":"distribution/cache.html","title":"Cache","keywords":"","body":"1. cache1.1. cache L1 L2 L31.2. 多核CPU与内存共享1.3. 缓存实现的几种方式1.4. redis1.5. Memcache Title Date Modified Category cache 2019-06-10 12:00 2019-06-11 12:00 distribution 1. cache 1.1. cache L1 L2 L3 1.2. 多核CPU与内存共享 1.3. 缓存实现的几种方式 1.4. redis 1.5. Memcache "},"distribution/mq/":{"url":"distribution/mq/","title":"MQ","keywords":"","body":" Title Date Modified Category mq 2019-06-11 12:00 2019-06-11 12:00 distribution Kafka "},"distribution/mq/kafka.html":{"url":"distribution/mq/kafka.html","title":"kafka","keywords":"","body":" Title Date Modified Category kafka 2019-06-11 12:00 2019-06-11 12:00 distribution "},"distribution/byzantine.html":{"url":"distribution/byzantine.html","title":"byzantine","keywords":"","body":" Title Date Modified Category 拜占庭将军问题 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/cap.html":{"url":"distribution/cap.html","title":"cap","keywords":"","body":" Title Date Modified Category CAP 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/paxos.html":{"url":"distribution/paxos.html","title":"paxos","keywords":"","body":""},"distribution/raft.html":{"url":"distribution/raft.html","title":"raft","keywords":"","body":""},"distribution/registry/":{"url":"distribution/registry/","title":"registry","keywords":"","body":" Title Date Modified Category 服务注册与发现 2019-06-12 12:00 2019-06-12 12:00 distribution consul etcd Zookeeper "},"distribution/registry/consul.html":{"url":"distribution/registry/consul.html","title":"consul","keywords":"","body":" Title Date Modified Category Consul 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/registry/etcd.html":{"url":"distribution/registry/etcd.html","title":"etcd","keywords":"","body":" Title Date Modified Category etcd 2019-06-12 12:00 2019-06-12 12:00 distribution "},"distribution/registry/zookeeper.html":{"url":"distribution/registry/zookeeper.html","title":"Zookeeper","keywords":"","body":" Title Date Modified Category ZooKeeper 2019-06-12 12:00 2019-06-12 12:00 distribution "},"micros/":{"url":"micros/","title":"micros","keywords":"","body":"1. MicroService架构探索 Title Date Modified Category micros 2019-05-29 12:00 2019-06-10 12:00 micros 禁止转载 本目录内文章，图片和文字资源大多来自于网络和参考书籍，如有侵权，请联系删除 1. MicroService架构探索 各位领导大家好，今天给大家汇报一下最近的一些关于微服务的研究。 MicroService Consul go-micro SpringCloud Docker Docker Compose Docker Swarm Mesos Kubernetes Helm DevOps OpenShift 3 Serverless Istio OpenShift 4 Rancher Chaos Engineering ELK EFK Monitoring Prometheus Zipkin 总结 Q & A "},"micros/microservice.html":{"url":"micros/microservice.html","title":"MicroService","keywords":"","body":"1. MicroService1.1. 概述1.1.1. 微服务设计的理念：1.1.2. 为什么要使用微服务1.1.3. 微服务特点，如下所述。1.1.4. 微服务带来的问题。1.2. todos demo1.3. 参考资料 Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. MicroService 1.1. 概述 微服务是一种软件架构模式，用来把大而重的应用程序切成许多可管理的、可管理的独立服务，各服务之间的通信并不受不同语言的协议影响，每个服务只管做好一件事情。 1.1.1. 微服务设计的理念： 各服务要小 - 单一的业务目标应该是要细粒度，就像Unix的”只做一件事并且要做好”理念。 组织文化要包含部署与测试的自动化，这个降低管理与操作的负担。 设计原则要包含失败与错误，就像抗脆弱的系统。 1.1.2. 为什么要使用微服务 随着组织的扩大，使用的技术和员工的数量都在增加，管理单一代码实现的服务，只会变得越来越复杂。 1.1.3. 微服务特点，如下所述。 在结构上，将原有的从技术角度拆分的组件，升级为从业务角度拆分的独立运行的服务，这些服务具备各自的实现平台，并且独占自有数据，在服务之间以智能端点和哑管道的方式通信。 在工程上，从产品而非项目的角度进行设计，强调迭代，自动化和面向故障的设计方法。 1.1.4. 微服务带来的问题。 微服务架构在很大程度上提高了应用的伸缩性，方便了部门或业务之间的协作，使技术岗位能够更好地引入新技术并提高自动化程度，最终达到减耗增效的目的，然而和所有新方法一样，微服务架构在解决老问题的同时，也带来了一些新问题，例如： 实例数量急剧增长，对部署和运维的自动化要求更高。 用网络调动代替内部API，对网络这一不可靠的基础设施依赖增强 调用链路变长，分布式跟踪称为必选项目 日志分散严重，跟踪和分析难度加大 服务分散，受攻击面积更大 在不同的服务之间存在协作关系，需要有更好的跨服务控制协调能力 自动伸缩，路由管理，故障控制，存储共享，等等。 1.2. todos demo TODO 1.3. 参考资料 "},"micros/consul.html":{"url":"micros/consul.html","title":"Consul","keywords":"","body":"1. Consul1.1. 概念1.1.1. 服务注册与发现1.1.2. Consul1.2. 演示1.2.1. install consul1.2.2. run the agent1.2.3. services1.2.4. Connect1.2.5. Consul Cluster1.2.6. Health Checks1.2.7. KV Data1.2.8. Web UI1.3. todos demo1.4. 参考资料1.4.1. GitHub1.4.2. Website Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Consul 1.1. 概念 1.1.1. 服务注册与发现 1.1.2. Consul 1.2. 演示 1.2.1. install consul $brew install consul verifying the installation $consul 1.2.2. run the agent starting the agent $consul agent -dev 为了简单，我们以开发模式启动consul agent。这个模式可以快速和容易的启动一个单节点的consul环境. 这个模式不适合用于生产环境，因为它不保存任何状态。 cluster members $consul members Node Address Status Type Build Protocol DC Segment avril.local 127.0.0.1:8301 alive server 1.3.0 2 dc1 在另一个terminal中执行consul members，你可以看到consul cluster的members，你可以看到，只有 one member（yourself）. 输出显示了我们自己的node，这address it is running on，its health state, its role in the cluster, and some version information. 额外的元数据信息可以通过-detailed flag看到. 这个命令的输出，基于gossip protocol, and is 最终一致的。也就是说，在任何节点在同一时间，看到的世界，by 你本地的agent 可能不完全匹配这状态在servers。一个强一致的系统的展示，可以用这HTTP API 去远程请求consul servers $curl localhost:8500/v1/catalog/nodes [ { \"ID\": \"9a8b671d-ffdb-6445-f436-9ad02cf7d219\", \"Node\": \"avril.local\", \"Address\": \"127.0.0.1\", \"Datacenter\": \"dc1\", \"TaggedAddresses\": { \"lan\": \"127.0.0.1\", \"wan\": \"127.0.0.1\" }, \"Meta\": { \"consul-network-segment\": \"\" }, \"CreateIndex\": 9, \"ModifyIndex\": 10 } ] 对于这个HTTP API额外的说一下，DNS interface可以被用来请求这个节点。提示：你必须确保你的DNS 发现 指向 consul agent's DNS server, which 运行在 8600默认端口上的。这DNS 入口的格式，（类似 \"avril.local.node.consul\"）可以被发现在一会 $dig @127.0.0.1 -p 8600 avril.local.node.cansul ; > DiG 9.10.6 > @127.0.0.1 -p 8600 avril.local.node.cansul ; (1 server found) ;; global options: +cmd ;; Got answer: ;; ->>HEADERstopping the agent 你可以ctrl-C去优雅的停止这个agent，当中断这个agent，你可以看到，它离开的cluster，and shut down。 为了优雅的leaving，consul 通知其他集群成员，这个节点离开了。如果你强行kill这个agent 进程，其他成员将发现这个node fail的。 当一个成员离开，它的服务和检查，将从catalog移除。当一个成员fails，它的健康仅仅标记为critical, 但它不会从catalog中移除。 cansul往往会重连 failed nodes，允许它从好的网络状态下恢复。然而离开的节点永远不会联系。 另外，如果一个agent 正在操作一个server，一个优雅的离开方式是重要的，去避免造成一些超出控制的影响. 1.2.3. services registering services 在前面的步骤里，我们运行了我们的第一个agent，查看了集群的成员，并且访问了这个节点。在本节guide，我们将注册我们第一个service，并且query这个service。 defining a service 一个服务，可以通过，提供一个服务定义文件，或者调用一个合适的HTTP API 一个服务定义，是最常用的方式去注册service，所以，我们用这种方式开启下一步。我们将基于上一步的agent 配置。 首先，创建一个目录用于consul configuration。consul loads 所有的配置文件，in the 配置目录，所以一个通用的形式，在unix系统上是定义这个目录like /etc/consul.d(the .d suffix implies \"this directory contaions a set of configuration files\"). $sudo mkdir /etc/consul.d 接下来，我们写一个服务定义文件，我们假装我们有一个服务named\"web\" 跑在80端口，另外，我们给它一个tag，我们可以用来额外的方式查询这个service. $ echo '{\"service\": {\"name\": \"web\", \"tags\": [\"rails\"], \"port\": 80}}' \\ | sudo tee /etc/consul.d/web.json 现在，重启agent，提供这个配置目录 $ consul agent -dev -config-dir=/etc/consul.d 你可以注意到他的输出，同步的这个web service。这意味着这个agent加载了这个服务配置，从配置文件里，并且成功注册了他在这服务catalog。 如果你想去注册multiple services，你可以创建multiple service配置文件在这配置目录里。 querying services Once the agent is started and the service is synced, we can query the service using either the DNS or HTTP API. DNS API 让我们首先请求我们的服务，用DNS API。for the DNS API, the DNS name for servics is NAME.service.consul. By default, all DNS names are always in the consul namespace, though this is configurable. The service subdomain tells Consul we're querying services, and the NAME is the name of the service. For the web service we registered, these conventions and settings yield a fully-qualified domain name of web.service.consul $ dig @127.0.0.1 -p 8600 web.service.consul 你可以看到，一个记录返回了这IP地址，of 这个节点，on which 这个服务存在的。一个记录可以仅仅包含IP地址。 你可以用这DNS API to retrieve the entrie address/port pair as a SRV record $ dig @127.0.0.1 -p 8600 web.service.consul SRV 这个服务记录，说，这个web service 运行在80端口，并且在节点。。上，并且额外的信息返回了，通过这DNS，with the 一个记录 for the node。 实际上，我们也可以通过DNS API去过滤服务用tags， $ dig @127.0.0.1 -p 8600 rails.web.service.consul HTTP API $ curl http://localhost:8500/v1/catalog/service/web [{\"Node\":\"Armons-MacBook-Air\",\"Address\":\"172.20.20.11\",\"ServiceID\":\"web\", \\ \"ServiceName\":\"web\",\"ServiceTags\":[\"rails\"],\"ServicePort\":80}] The catalog API gives all nodes hosting a given service. As we will see later with health checks you'll typically want to query just for healthy instances where the checks are passing. This is what DNS is doing under the hood. Here's a query to look for only healthy instances: $ curl 'http://localhost:8500/v1/health/service/web?passing' [{\"Node\":\"Armons-MacBook-Air\",\"Address\":\"172.20.20.11\",\"Service\":{ \\ \"ID\":\"web\", \"Service\":\"web\", \"Tags\":[\"rails\"],\"Port\":80}, \"Checks\": ...}] updating services 服务定义可以被更新，通过改变配置文件，和发送 a SIGHUP to the agent. 这可以让你更新services 没有任何停机或不可用。 这HTTP API可以被用来，add，remove，modify services dynamically。 1.2.4. Connect 1.2.5. Consul Cluster 1.2.6. Health Checks 1.2.7. KV Data 1.2.8. Web UI 1.3. todos demo TODO 1.4. 参考资料 1.4.1. GitHub https://github.com/hashicorp/consul 1.4.2. Website https://www.consul.io/ "},"micros/go-micro.html":{"url":"micros/go-micro.html","title":"go-micro","keywords":"","body":"1. go-micro1.1. 概述1.1.1. 特性1.2. todos demo1.2.1. 架构1.2.2. 演示1.3. 参考资料1.3.1. GitHub1.3.2. WebSite Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. go-micro 1.1. 概述 Micro是一套微服务构建工具库。对于微服务架构的应用，Micro提供平台层面、高度弹性的工具组件，让服务开发者们可以把复杂的分布式系统以简单的方式构建起来，并且尽可能让开发者使用最少的时间完成基础架构的构建。 1.1.1. 特性 网关 Web Dashboard 服务发现 负载均衡 同步通信 异步通信 消息编码 服务接口-Golang开发框架 组件可插拔 1.2. todos demo 1.2.1. 架构 1.2.2. 演示 TODO 1.3. 参考资料 1.3.1. GitHub https://github.com/micro 1.3.2. WebSite https://micro.mu/ https://micro.mu/docs/cn/index.html "},"micros/spring-cloud.html":{"url":"micros/spring-cloud.html","title":"SpringCloud","keywords":"","body":"1. SpringCloud1.1. 概念1.2. 参考资料 Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. SpringCloud 1.1. 概念 Spring Cloud最早在功能层面为微服务治理定义了一系列标准特性，例如智能路由，熔断机制，服务注册与发现等，并提供了对应的库和组件来实现这些标准特性。到目前为止，这些库和组件被广泛采用。 Spring Cloud缺点： 既博采众家之长，也导致了一些散乱的局面，即用户需要学习和熟悉各组件的”方言“并加以运维，这在客观上提高了应用门槛 需要在代码级别对诸多组件进行控制，包括Sidecar在内的组件都依赖Java的实现，这和微服务的多语言协作目标是背道而驰的 自身并没有对调度，资源，DevOps等提供相关支持，需要借助其他平台来完成，然而目前的容器编排事实标准是k8s，二者的部分功能存在重合或者冲突，这在一定程度上影响了Spring Cloud的长远发展。 1.2. 参考资料 "},"micros/docker.html":{"url":"micros/docker.html","title":"Docker","keywords":"","body":"1. Docker1.1. 概述1.1.1. Container1.1.2. Docker1.2. 使用1.3. Docker 与微服务1.4. Docker周边工具1.4.1. 运维工具1.4.2. 网络支持1.4.3. 监控与日志1.4.4. Docker持续集成1.4.5. 私有镜像仓库1.4.6. 公有云1.4.7. 集群管理面板1.5. 基于Docker的PaaS平台1.5.1. 操作系统1.5.2. Serverless1.6. 参考资料1.6.1. GitHub1.6.2. WebSite1.6.3. Books Title Date Modified Category docker 2019-05-29 12:00 2019-05-29 12:00 micros 1. Docker 1.1. 概述 1.1.1. Container 1.1.2. Docker 事实上的标准 docker，优势，可以构建一个隔离的，稳定的，安全地，高性能的容器运行环境。 1.2. 使用 docker help 1.3. Docker 与微服务 1.4. Docker周边工具 1.4.1. 运维工具 Ansible 1.4.2. 网络支持 Pipework Flannel Weave Net Calico 1.4.3. 监控与日志 cAdvisor 原生集群监控 Logspout 日志处理 Grafana 数据可视化 Heapster Prometheus EFK Filebeat ELK (ElasticSearch，Logstash，Kibana) Fluentd Graylog Cat Zipkin Pinpoint InfluxDB 1.4.4. Docker持续集成 Drone 轻量级CI工具 Travis CI 著名的CI/CD服务商 1.4.5. 私有镜像仓库 https://github.com/docker/distribution VMWare Harbor SUSE Portus 1.4.6. 公有云 GKE 1.4.7. 集群管理面板 Shipyard Portainer ** Panamax Seagull 1.5. 基于Docker的PaaS平台 Deis 轻量级PaaS平台 Tsuru 可扩展PaaS平台, 基于Swarm Flynn 模块化PaaS平台 openshift 1.5.1. 操作系统 CoreOS RancherOS Red hat Atomic VMWare Photon 1.5.2. Serverless Kubeless Function Trigger Fission OpenFaaS 1.6. 参考资料 1.6.1. GitHub https://github.com/docker 1.6.2. WebSite https://www.docker.com/ 1.6.3. Books 《Docker技术入门与实战（第3版）》 "},"micros/docker-compose.html":{"url":"micros/docker-compose.html","title":"Docker Compose","keywords":"","body":"1. Docker Compose1.1. 简介1.2. 使用1.3. todos demo1.3.1. demo1.3.2. 演示 Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Docker Compose 1.1. 简介 单机服务编排工具 1.2. 使用 docker-compose help 1.3. todos demo 1.3.1. demo https://github.com/mingz2013/demo-todos-go-micro https://github.com/mingz2013/demo-todos-vue 1.3.2. 演示 展示todos demo的代码架构，项目里面的文档 本地演示用docker-compose实现单机部署 展示todos demo的控制台 http://localhost:8082 展示todos demo的vue前端 http://localhost:8082/todos/#/todos 展示进程scale。 "},"micros/docker-swarm.html":{"url":"micros/docker-swarm.html","title":"Docker Swarm","keywords":"","body":"1. Docker Swarm1.1. Docker Machine1.2. Docker Compose1.3. Docker Swarm1.4. Docker Node1.5. Docker Service1.6. Docker Stack1.7. Docker Network1.8. todos demo1.8.1. 演示1.9. 参考资料1.9.1. Books Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Docker Swarm Docker Machine 创建 Docker 主机 Docker Swarm 配置集群节点 Docker Service 部署单个集群服务 Docker Stack 部署多个服务，以及 GUI 管理页面 docker-machine、docker swarm、docker node、docker service 和 docker stack 常用命令 1.1. Docker Machine Docker Machine是Docker官方编排项目之一，是一个简化Docker安装的命令行工具，可以帮助用户构建拥有Docker运行环境的虚拟机，并能够远程管理虚拟机及其里面的容器。 1.2. Docker Compose Docker Compose是Docker的一种编排服务，是一个用于在Docker上定义并运行复杂应用的工具，可以让用户在集群中部署分布式应用。通过Compose，用户可以很容易的用一个配置文件定义一个多容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker Compose解决了容器与容器之间如何管理编排的问题，适合开发和测试环境。 1.3. Docker Swarm Swarm是Docker公司在2014年12月初发布的一套较为简单的工具，用来管理Docker集群，它将一群Docker宿主机变成一个单一的，虚拟的主机，使用Swarm操作集群，会使用户感觉就像是在一台主机上进行操作。Swarm使用标准的Docker API接口作为其前端访问入口，换言之，各种形式的Docker Client都可以直接与Swarm通信。 1.4. Docker Node 1.5. Docker Service 1.6. Docker Stack stack 是构成特定环境中的 service 集合, 它是自动部署多个相互关联的服务的简便方法，而无需单独定义每个服务。 docker stack忽略构建命令，无法使用stack构建新镜像。 stack 是一组相互关联的服务，它是服务的上一层，这些服务共享依赖关系，并且可以一起编排和缩放。 单个 stack 能够定义和协调整个应用程序的功能，简单来说 stack 就是一组服务的集合。 1.7. Docker Network 1.8. todos demo https://github.com/mingz2013/demo-todos-go-micro 1.8.1. 演示 搭建单节点swarm集群 用栈部署todos demo 部署Portainer 用Portainer管理页面管理todos demo。 1.9. 参考资料 1.9.1. Books 《容器云运维实战：Docker与Kubernetes集群》 "},"micros/mesos.html":{"url":"micros/mesos.html","title":"Mesos","keywords":"","body":"1. Mesos Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Mesos Mesos项目是源自UC Berkeley的对集群资源进行抽象和管理的开源项目，类似于操作系统内核，使用它可以很容易的实现分布式应用的自动化调度。 同时，Mesos自身也很好的结合和主持了Docker等相关容器技术，基于Mesos已有的大量应用框架，可以实现用户应用的快速上线。 Twitter 宣布抛弃 Mesos 全面转向 Kubernetes "},"micros/k8s.html":{"url":"micros/k8s.html","title":"Kubernetes","keywords":"","body":"1. kubernetes1.1. 概念1.1.1. Helm1.2. 使用1.3. dashboard1.4. todos demo1.5. 参考资料1.5.1. GitHub1.5.2. WebSite1.5.3. Books Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. kubernetes 1.1. 概念 k8s业已称为容器编排领域事实上的标准 还要考虑集群管理，高可用，安全，持续集成等方方面面的问题。 这些关于容器集群管理的问题，其实就是容器编排的问题，即Kubernetes要解决的问题。 Kubernetes特性 自动装箱 自我修复 水平扩展 服务发现和负载均衡 自动发布和回滚 密钥和配置管理 存储编排 批量处理执行 1.1.1. Helm Kuberneres的安装包管理器，类似于yum，apt-get等 K8s类似于微服务层的操作系统，Helm类似于操作系统上的包管理器。 1.2. 使用 1.3. dashboard 1.4. todos demo TODO 1.5. 参考资料 1.5.1. GitHub https://github.com/kubernetes 1.5.2. WebSite https://kubernetes.io/ https://kubernetes.io/zh/docs/tutorials/ 1.5.3. Books 《每天5分钟玩转Kubernetes》 《Kubernetes进阶实战》 《基于Kubernetes的容器云平台实战》 "},"micros/helm.html":{"url":"micros/helm.html","title":"Helm","keywords":"","body":"1. Helm Title Date Modified Category Helm 2019-06-11 12:00 2019-06-11 12:00 micros 1. Helm Helm可大大简化应用管理的难度。 简单来说，Helm就是k8s的应用程序包管理器，类似于Linux操作系统上的yum或apt-get等，可用于实现帮助用户查找，分享及使用k8s应用程序，目前的版本由CNCF（Microsoft，Google，Bitnami和Helm社区）维护。它的核心打包功能组件称为chart，可以帮助用户创建，安装及升级复杂应用。 "},"micros/devops.html":{"url":"micros/devops.html","title":"DevOps","keywords":"","body":"1. DevOps Title Date Modified Category devops 2019-05-29 12:00 2019-05-29 12:00 micros 1. DevOps DevOps（Development & Operations）即开发运维一体化，可理解为软件研发的一种过程，方法，文化，运动或实践，主要是通过一条高度自动化的流水线来加强开发，测试，运维和其他部门之间的沟通和协作，加速产品和服务的交付。 "},"micros/openshift-3.html":{"url":"micros/openshift-3.html","title":"OpenShift 3","keywords":"","body":"1. OpenShift 31.1. 概念1.1.1. Red Hat1.1.2. OpenShift1.1.3. 混合云1.2. 演示1.3. todos demo1.4. 参考资料1.4.1. GitHub1.4.2. WebSite1.4.3. Books Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. OpenShift 3 1.1. 概念 1.1.1. Red Hat Red Hat就是开源软件商业模式的奠基人，而且是目前世界上最大的开源软件公司。 作为一个开源软件公司，red hat所有产品的企业版的源代码也是完全公开的。 Red Hat是Kubernetes, Istio的主要贡献者之一。 1.1.2. OpenShift OpenShift是一个开源容器云平台，是一个基于主流的容器技术Docker及Kubernetes构建的云平台。 通过OpenShift这个平台，企业可以快速在内部网络中构建出一个多租户的云平台，在这朵云上提供应用开发，测试，部署，运维的各项服务（如图1-2所示）。 OpenShift在一个平台上贯通开发，测试，部署，运维的流程，实现高度的自动化，满足应用持续集成及持续交付和部署的需求；满足企业及组织对容器管理，容器编排的需求。 通过OpenShift的灵活架构，企业可以以OpenShift作为核心，在其上搭建一个企业的DevOps引擎，推动企业的DevOps变革和转型。 容器引擎及容器编排组件是两项关键的技术，但还不能满足生产效率的要求。 OpenShift在Docker和k8s的基础上提供了各种功能，以满足业务应用，研发用户及运维用户在生产效率上的诉求。 应用开发框架及中间件 应用及服务目录 自动化流程及工具。 软件自定义网络 性能监控及日志管理 多用户接口 自动化集群部署及管理 OpenShift集成了原生的Kubernetes作为容器编排组件。OpenShift通过Kubernetes来管理容器集群中的机器节点及容器，为业务应用提供： 容器调度 弹性伸缩 异常自愈 持久化卷 服务发现 配置管理 K8s是一个容器编排工具，虽然提供了很多的功能，但只是一个工具。而OpenShift是一整套企业解决方案。 架构概览 核心组件 构建与部署自动化 CI/CD 企业部署 多环境单集群 多环境多集群 多数据中心 高可用 主控节点的高可用 度量与日志管理 度量采集 日志采集 1.1.3. 混合云 1.2. 演示 演示本地macos的OpenShift单节点集群 演示OpenShift的Web Dashboard 1.3. todos demo TODO 1.4. 参考资料 1.4.1. GitHub https://github.com/openshift 1.4.2. WebSite http://www.openshift.org https://www.okd.io/ 1.4.3. Books 《开源容器云OpenShift 构建基于Kubernetes的企业应用云》 "},"micros/serverless.html":{"url":"micros/serverless.html","title":"Serverless","keywords":"","body":"1. Serverless1.1. 概述1.2. 参考资料1.2.1. books Title Date Modified Category serverless 2019-06-11 12:00 2019-06-11 12:00 micros 1. Serverless 1.1. 概述 Serverless下包含的两个概念： 函数即服务，即Function as a Service，简称FaaS 后端即服务，即Backend as a Service，简称BaaS。 目前，Serverless平台主要分为三大类： 公有云上的功能即服务（Functions as a Service，FaaS）解决方案。 运行在共有和私有数据中心的Serverless框架，如Fission运行在Kubernetes上，Funktion运行在Kubernetes上，IBM OpenWhisk运行在Docker上。 提供agnostic应用接口或/和现有Serverless框架增值服务的包装框架，如Serverless.com支持AWS Lambda，Apex支持AWS Lambda。 Serverless适用场景: 应用负载变化显著的场景 基于事件驱动的算法服务化场景 基于事件驱动的数据分析服务化场景 基于事件驱动的数据服务化场景 低频请求场景 1.2. 参考资料 1.2.1. books 《基于Kubernetes的容器云平台实战》 "},"micros/istio.html":{"url":"micros/istio.html","title":"Istio","keywords":"","body":"1. Istio1.1. 概述1.1.1. Service Mesh1.1.2. Istio1.2. todos demo1.3. 参考资料1.3.1. GitHub1.3.2. WebSite1.3.3. Books Title Date Modified Category micros 2019-05-29 12:00 2019-05-29 12:00 micros 1. Istio 1.1. 概述 1.1.1. Service Mesh 要讨论服务网格（Service Mesh），就必须提到微服务（Microservices）。 为了解决微服务架构产生的一些问题，以k8s为代表的容器云系统出现了。这类容器云系统以容器技术为基础，在进程级别为微服务提供了一致的部署，调度，伸缩，监控，日志等功能。 然而，除了进程本身的问题，微服务之间的通信和联系更加复杂，其中的观测，控制和服务质量等都成为微服务方案的短板，因此随着k8s成为事实标准，Service mesh顺势登场。 自Service Mesh技术诞生以来，国内外出现了很多产品，下面选择其中几个重要的产品和事件，大概理理Service Mesh相关产品的发展情况。 Buoyant公司的CEO William，曾经给出对服务网格的定义：服务网格是一个独立的基础设施层，用来处理服务之间的通信。 现代的云原生应用是由各种复杂技术构建的服务组成的，服务网格负责在这些组成部分之间进行可靠的请求传递。 目前典型的服务网格通常提供了一组轻量级的网络代理，这些代理会在应用无感知的情况下，同应用并行部署，运行。 Service Mesh主要功能： 负载均衡 服务发现 熔断 动态路由 安全通信 多语言支持 多协议支持 指标和分布式追踪 重试和最后期限 总结一下，Service Mesh实现了四大关键功能： 实现对基础设施的抽象化 为应用请求提供可靠传递 每个业务节点部署轻量级代理 透明化，应用程序无感知。 Service Mesh类似于更高级的一层网络栈。 k8s就是微服务级别的操作系统。 Helm是k8s的包管理工具，类似于yum，apt-get。 Sidecar 1.1.2. Istio 事实上的标准 2017年5月，Google，IBM和Lyft宣布了Istio的诞生。Istio以Envoy为数据平面，通过Sidecar的方式让Envoy同业务容器一起运行，并劫持其通信，接受控制平面的统一管理，在此基础上为服务之间的通信提供了丰富的连接，控制，观察，安全等特性。 Istio一经发布，便立刻获得Red Hat，F5等大牌厂商的响应，虽然立足不稳，但各个合作方都展示了对社区，行业的强大影响力。于是，Istio很快就超越了Linkerd，成为Service Mesh的代表产品。 这里将Istio的特性总结如下。 连接：对网格内部的服务之间的调用所产生的流量进行智能管理，并以此为基础，为微服务的部署，测试和升级等操作提供有力保障。 安全：为网络内部的服务之间的调用提供认证，加密和鉴权支持，在不侵入代码的情况下，加固现有服务，提高其安全性。 策略：在控制面定制策略，并在服务中实施 观察：对服务之间的调用进行跟踪和测量，获取服务的状态信息。 1.2. todos demo TODO 1.3. 参考资料 1.3.1. GitHub https://github.com/istio 1.3.2. WebSite https://istio.io/ https://istio.io/zh/docs/ 1.3.3. Books 《深入浅出Istio：Service Mesh快速入门与实践》 《基于Kubernetes的容器云平台实战》 "},"micros/openshift-4.html":{"url":"micros/openshift-4.html","title":"OpenShift 4","keywords":"","body":"1. OpenShift 41.1. 概述1.2. todos demo1.3. 参考资料1.3.1. GitHub1.3.2. WebSite1.3.3. Books Title Date Modified Category openshift 4 2019-05-29 12:00 2019-05-29 12:00 micros 1. OpenShift 4 1.1. 概述 集成了Istio 目前处于测试版本状态。 只提供了Linux上的测试部署方案。 1.2. todos demo TODO 1.3. 参考资料 1.3.1. GitHub 1.3.2. WebSite 1.3.3. Books "},"micros/rancher.html":{"url":"micros/rancher.html","title":"Rancher","keywords":"","body":"1. Rancher1.1. 演示1.2. 参考资料1.2.1. github1.2.2. website Title Date Modified Category Rancher 2019-06-10 12:00 2019-06-10 12:00 micros 1. Rancher 1.1. 演示 演示Rancher安装 Rancher管理macos上单节点k8s集群 1.2. 参考资料 1.2.1. github https://github.com/rancher/rancher 1.2.2. website https://rancher.com/ https://www.cnrancher.com/ https://www.cnrancher.com/docs/rancher/v2.x/cn/overview/ "},"micros/chaos-engineering.html":{"url":"micros/chaos-engineering.html","title":"Chaos Engineering","keywords":"","body":"1. Chaos Engineering Title Date Modified Category chaos 2019-05-29 12:00 2019-05-29 12:00 micros 1. Chaos Engineering 混沌工程 "},"micros/elk.html":{"url":"micros/elk.html","title":"ELK","keywords":"","body":"1. ELK1.1. 将日志输出到Docker容器外1.2. 使用Docker容器日志1.3. syslog Linux日志系统1.4. Docker 日志架构1.5. ELK1.5.1. 日志存储系统：Elasticsearch1.5.2. 日志收集系统：Logstash1.5.3. 日志查询系统：Kibana1.5.4. ELK 集成日志中心2. 参考资料2.1. books Title Date Modified Category ELK 2019-06-11 12:00 2019-06-11 12:00 micros 1. ELK 1.1. 将日志输出到Docker容器外 docker run -v ~/logs:~/logs hello 1.2. 使用Docker容器日志 docker logs 查看DOcker当前所设置的日志驱动类型，它是json-file。 docker info | grep 'Logging Driver' 我们进入/var/lib/docker/containers/目录，就会看到一个名为-json.log的文件，它就是我们要寻找的JSON日志文件了。 原来如此，当我们通过docker logs命令所看到的日志，实际上就是解析这个JSON日志文件后的输出。 既然应用程序的日志可以写入JSON文件中，那么也能写入其他日志驱动中，json-file只是Docker日志驱动的一种默认选项，Docker已为我们提供了大量的日志驱动类型。 none：容器不输出任何日志 json-file: 容器输出的日志以JSON格式写入文件中 syslog：容器输出的日志写入宿主机的Syslog中 journald：容器输出的日志写入宿主机的Journald中 gelf：容器输出的日志以GELF（Graylog Extended Log Format）格式写入Graylog中 fluentd：容器输出的日志写入宿主机的Fluentd中 awslogs：容器输出的日志写入Amazon CloudWatch Logs中 splunk：容器输出的日志写入splunk中 etwlogs：容器输出的日志写入ETW（Event Tracing for Windows）中 gcplogs：容器输出的日志写入GCP（Google Cloud Platform）中 nats：容器输出的日志写入NATS服务器中 我们可以在docker run命令中通过--log-driver参数来设置具体的Docker日志驱动，也可以通过--log-opt参数来指定对应日志驱动的相关选项。 就拿默认的json-file来说，其实可以这样启动docker容器： docker run -d -p 80:80 --log-driver json-file --log-opt max-size=10m --log-opt max-file=3 --name nginx nginx 在以上众多日志驱动类型中，最为常用的是Syslog，因为Syslog是Linux的日志系统，很多日志分析工具都可以从Syslog中获取日志，比如流行的ELK日志中心，它包括以下三个组件。 日志存储：由Elasticsearch负责 日志收集：由Logstash负责 日志查询：由Kinana负责 在ELK的三个组件中， Logstash用于收集日志，Syslog中写入的日志可转发到Logstash中， 随后将日志存入Elasticsearch中， 最后可通过Kibana来查询日志。 1.3. syslog Linux日志系统 默认情况下，Linux操作系统已安装了Syslog软件包，但它叫Rsyslog。实际上，Rsyslog是Syslog标准的一种实现。除了Rsyslog这一种实现，还有一种叫Syslog-ng的第三方实现。 查看命令 rsyslogd -v 开启Rsyslog服务： 编辑配置文件 vi /etc/rsylog.conf 重启服务 systemctl restart rsyslog 查看端口 netstat -anpt | grep 514 启动一个nginx容器，用syslog日志驱动 docker run \\ -d \\ -p 80:80 \\ --log-driver syslog \\ --log-opt syslog-address=tcp://localhost:514 \\ --log-opt tag=\"{{.ImageName}}/{{.Name}}/{{.ID}}\" \\ --name nginx \\ nginx tail -f /var/log/messages 1.4. Docker 日志架构 Docker 容器（Docker Container） 中的应用程序（Application） 将 日志写入到标准输出设备（STDOUT），Docker守护进程（Docker Daemon）负责从STDOUT中获取日志，并将日志写入对应的日志驱动中， 目前，应用程序中的日志已经从Docker容器内部成功写入宿主机的Syslog中，接下来我们要做的是，将Syslog中的日志转发到ELK平台的Logstash中，从而建立我们所需要的“应用日志中心”， 1.5. ELK 从Elastic公司的官网上，我们就能快速了解该公司所提供的产品，用官方的说法，叫“开源Elastic栈（Open Source Elastic Stack）”。 从官网上可知，Elastic官方推出了6款开源产品。 Kibana：用于数据可视化 Elasticsearch：用于数据搜索，分析与存储 Logstash：用于数据收集，将数据存入Elasticsearch中 Beats：用于数据传输，将数据从磁盘上传输到Logstash中 X-Pack：提供一些扩展功能，包括安全，预警，监控，报表，图形化等 Elastic Cloud：提供Elastic栈的云服务，提供公有云与私有云解决方案 1.5.1. 日志存储系统：Elasticsearch Elasticsearch是一个可高度扩展的开源全文搜索与分析引擎，它可以帮助我们快速的存储，搜索与分析大规模的实时数据。Elasticsearch的底层基于开源搜索引擎Lucene，并在此基础上提供了一系列便于应用程序使用的REST API，并且还提供了先天性的集群能力，可自由水平扩展以支持日益增长的数据。 通过Docker容器启动Elasticsearch： docker run \\ --rm \\ -p 9200:9200 \\ --name elasticsearch \\ elasticsearch 1.5.2. 日志收集系统：Logstash Logstash是一款开源的数据收集引擎，它既提供了实时管道能力，也提供了灵活的插件机制，我们可以自由选择已有的插件，也能自行开发所需的插件。我们使用Logstash更多的时候都是在做参数配置，以实现我们所需的功能。 1.5.3. 日志查询系统：Kibana Kibana是一个开源的基于Elasticsearch的分析与可视化平台，我们既可用它来查看并搜索存储在Elasticsearch中的数据，也可用它来制作各式各样的图表，表格，地图等图形化数据。 1.5.4. ELK 集成日志中心 2. 参考资料 2.1. books 《架构探险：轻量级微服务架构（下册）》 "},"micros/efk.html":{"url":"micros/efk.html","title":"EFK","keywords":"","body":"1. EFK1.1. Elasticsearch1.2. 日志采集代理fluentd1.3. Kibana Title Date Modified Category ELK 2019-06-11 12:00 2019-06-11 12:00 micros 1. EFK 一种流行的开源解决方案是将fluentd作为节点级代理程序进行日志采集，并将之聚合存储于Elasticsearch进行日志分析，以及通过Kibana进行数据可视化。这种组合通常简称EFK。 1.1. Elasticsearch 1.2. 日志采集代理fluentd fluentd是一个开源的数据收集器，基于C和Ruby语言开发，它目前有数百种以Ruby Gem形式独立存在的可选插件，用于连接多种数据源和数据输出组件等，如fluent-plugin-elasticsearch插件用于实现将采集到的数据发送给Elasticsearch。 1.3. Kibana Kibana是Elasticsearch的数据分析及可视化平台，能够用来搜索，查看存储在Elasticsearch索引中的数据。 "},"micros/monitoring.html":{"url":"micros/monitoring.html","title":"Monitoring","keywords":"","body":"1. Monitoring1.1. 时序数据收集系统：cAdvisor1.2. 时序数据存储系统：InfluxDB1.3. 时序数据分析系统：Grafana1.4. 集成InfluxDB+cAdvisor+Grafana 系统监控平台2. 参考资料2.1. books Title Date Modified Category Monitoring 2019-06-11 12:00 2019-06-11 12:00 micros 1. Monitoring 下面我们要做的就是搭建一个微服务系统监控中心，该平台会不断收集每个微服务所在DOcker容器中随时间变化的数据（简称“时序数据”），包括CPU，内存，网络，磁盘等使用情况。 我们同样也需要使用一系列开源技术来搭建这款系统监控中心，该平台首先会从DOcker容器中收集相关时序数据，随后会将这些时序数据存入一个时序数据库中，最后通过一个Web应用程序以图表的方式来展示并分析这些时序数据。 可见，系统监控中心包括了三个系统，即时序数据收集系统，时序数据存储系统，时序数据分析系统，这三个系统需要天然无缝的整合在一起。 经过一番调研后决定使用cAdvisor实现时序数据收集，使用InflusDB实现时序数据存储系统，使用Grafana实现时序数据分析。 1.1. 时序数据收集系统：cAdvisor cAdvisor是Google推出的一款基于Go语言的开源产品，它用于分析DOcker容器在运行中的资源使用与性能特征。cAdvisor使用起来非常简单，我们可以通过启动Docker容器的方式来运行它，当它运行后即可监控当前宿主机中所有Docker容器的运行状况。 docker run \\ -d \\ -p 8080:8080 \\ -v /:/rootfs \\ -v /var/run:/var/run \\ -v /sys:/sys \\ -v /var/lib/docker:/var/lib/docker \\ --name=cadvisor \\ google/cadvisor cAdvisor提供了一个Web控制台，以便于我们通过图形化的方式来查看它所收集的时序数据，我们可在浏览器上通过8080端口来访问该控制台。 cAdvisor还提供了一套REST API，我们可通过浏览器，Postman客户端，应用程序来访问它的REST API。我们可利用cAdvisor所提供的REST API自行封装客户端API，这样更有利于程序开发，官方也提供了一个基于Go语言的客户端API。 cAdvisor虽然使用起来非常方便，通过它自带的Web控制台也能基本满足我们的监控需求，但仍然存在以下两个问题。 只能监控当前宿主机的运行状况，如何监控远程主机呢？ 只能看到当前一段时间内的时序数据，如何长期存储呢？ 1.2. 时序数据存储系统：InfluxDB InfluxDB是InfluxData公司的产品之一，它是一款开源产品，用于存储相应的时序数据。由于时序数据是随时间变化而产生的，每分每秒（甚至每毫秒）都会产生相应的数据，而且这个数据量还会不断积累，最终将形成一个庞大的数据集。InfluxDB天生就用来存储这些大数据，同时还能对外提供高效的数据查询功能。 当然，我们依旧使用docker run的方式启动InfluxDB容器。 docker run \\ -d \\ -p 8086:8086 \\ -v ~/influxdb:/var/lib/influxdb \\ --name influxdb \\ influxdb 进入容器内部，执行influx命令，来启动一个命令行客户端。 docker exec -it influxdb influx 1.3. 时序数据分析系统：Grafana Grafana是一款基于Web的开源时序数据分析软件，它的功能十分强大，界面非常专业且相当易用。它能无缝对接InfluxDB数据源，非常轻松愉快的就能将我们带入数据可视化的世界。 docker run \\ -d \\ -p 3000:3000 \\ -v ~/grafana:/var/lib/grafana \\ --name grafana \\ grafana/grafana 1.4. 集成InfluxDB+cAdvisor+Grafana 系统监控平台 InfluxDB，cAdvisor，Grafana集成在一起，它们三个系统的组合将构成一个完整的系统监控平台。 InfluxDB是存放时序数据的中心，cAdvisor将时序数据存入InfluxDB，Grafana从InfluxDB中获取时序数据。 启动InfluxDB容器 启动cAdvisor容器 启动Grafana容器 2. 参考资料 2.1. books 《架构探险：轻量级微服务架构（下册）》 "},"micros/prometheus.html":{"url":"micros/prometheus.html","title":"Prometheus","keywords":"","body":"1. Prometheus1.1. k8s上的集群监控方案1.2. Prometheus1.3. Prometheus Operator2. 参考资料2.1. books Title Date Modified Category Prometheus 2019-06-11 12:00 2019-06-11 12:00 micros 1. Prometheus k8s上的集群监控方案 1.1. k8s上的集群监控方案 Weave Scope可以展示集群和应用的完整视图。其出色的交互性让用户能够轻松对容器化应用进行实时监控和问题诊断。 Heaspter是k8s原生的集群监控方案。预定义的Dashboard能够从Cluster和Pods两个层次监控k8s。 Prometheus Operator可能是目前功能最全面的k8s开源监控方案。除了能监控Node和Pod，还支持集群的各种管理组件，比如API Server，Scheduler，Controller Manager等。 1.2. Prometheus 因为Prometheus Operator是基于Prometheus的，所以我们需要先了解一下Prometheus。 Prometheus是一个非常优秀的监控工具。准确的说应该是监控方案。Prometheus提供了数据搜集，存储，处理，可视化和告警一套完整的解决方案。Prometheus的架构如图14-31所示。 官网上的原始架构图比上面这张要复杂一些，为了避免注意力分散，这里只保留了最重要的组件。 Prometheus Server Exporter 可视化组件 Alertmanager 1.3. Prometheus Operator Prometheus Operator的目标是尽可能简化在K8s中部署和维护Prometheus的工作，其架构如图14-32所示。 图中每一个对象都是k8s中运行的资源。 Operator Prometheus Server Service ServiceMonitor Alertmanager 2. 参考资料 2.1. books 《每天5分钟玩转Kubernetes》 "},"micros/zipkin.html":{"url":"micros/zipkin.html","title":"Zipkin","keywords":"","body":"1. Zipkin1.1. 微服务监控方案1.2. Zipkin1.3. Span1.4. Trace1.5. Reporter2. 参考资料2.1. books Title Date Modified Category Zipkin 2019-06-11 12:00 2019-06-11 12:00 micros 1. Zipkin Zipkin是Twitter公司开源的一款调用追踪中心（也称为分布式追踪系统），它可以帮助我们收集分布式系统中每个组件所花费的调用时长，并通过图形化界面的方式来展现整个调用链依赖关系，还能展现调用每个组件所花费的时长。 1.1. 微服务监控方案 1.2. Zipkin Zipkin在系统设计上参考了Google Dapper，它是Google公司内部所使用的大规模分布式系统追踪基础设施。 可以毫不夸张的说，Zipkin是开源社区中调用追踪中心的首选方案，我们可从Zipkin官网上了解更多关于它的相关介绍与使用方法。 使用Zipkin之前，我们有必要学习它的几个核心概念。 1.3. Span 是调用一个组件所经历的一段过程，也就是说，从请求组件开始，直到组件响应为止，在这段过程中会花费一定的时间，这是一个时间跨度，所以我们形象的将其称为Span。 1.4. Trace Trace指的是从客户端发出请求，直到完成整个内部调用的全部过程，我们将这个过程称为一次追踪，Trace就是这次追踪过程。 1.5. Reporter 我们需要将Span与Trace所产生的追踪数据推送至Zipkin中，因此需要在相关的组件中安置一个客户端，它用于收集这些追踪数据并将它们报告给Zipkin，我们将这个客户端称为Reporter。 只有被Reporter装配的（Instrumented）组件才能通过Transport向Zipkin发送数据，随后通过COllector进行数据收集，并通过Storage进行数据存储（可将数据持久化到Database中）。 此后，可通过API（Query Service）来查询Storage中的数据，并通过一个UI（Web UI）来展示Trace与Span的调用链及其相关数据。 可以把Transport理解为一个数据传输方式，Zipkin提供了多种主要方式。最简单的情况下，可通过HTTP来传输数据，在并发量较高的情况下，可通过Kafka或Scribe来传输数据，可起到数据缓冲的作用，提高了整个调用追踪中心的吞吐率。 Kafka是一个Apache开源的一款分布式消息系统，Scribe是Facebook开源的一款日志收集系统。 下面，开始进入Zipkin的内部来学习它的系统架构。 Collector Storage Query Service Web UI 2. 参考资料 2.1. books 《架构探险：轻量级微服务架构（下册）》 "},"ops/":{"url":"ops/","title":"ops","keywords":"","body":" Title Date Modified Category ops 2019-06-11 12:00 2019-06-11 12:00 ops Ansible "},"ops/ansible.html":{"url":"ops/ansible.html","title":"ansible","keywords":"","body":"1. Ansible1.1. Ansible的特性与框架 Title Date Modified Category ansible 2019-06-11 12:00 2019-06-11 12:00 ops 1. Ansible Ansible就是一个简单的自动化运维工具。 现在，成熟的自动化运维工具已经有了不少，比如Ansible，Puppet，Cfengine，Chef，Func，Fabric。 Ansible是一款由Python编程语言开发，基于SSH远程通信的自动化运维工具， 1.1. Ansible的特性与框架 对于Ansible的特性主要有如下几个： 不需要在被管控主机上安装客户端 无服务端，使用时直接运行命令即可 基于模块工作，可使用任意语言开发模块 使用yaml语言定制编排剧本playbook 基于SSH远程通信协议 可实现多级指挥 支持sudo 基于python语言，管理维护简单 支持邮件，日志等多种功能。 "},"hack/":{"url":"hack/","title":"hack","keywords":"","body":" Title Date Modified Category js 2019-06-14 12:00 2019-06-14 12:00 hack JS代码加密 "},"hack/js代码加密.html":{"url":"hack/js代码加密.html","title":"JS代码加密","keywords":"","body":"1. js代码加密 Title Date Modified Category js 2019-06-14 12:00 2019-06-14 12:00 hack 1. js代码加密 这里的js代码加密指的是客户端js代码的加密，包括运行在浏览器中的js，和运行在v8等js引擎中的js。 js在客户端执行，很容易被破解，找到源码。所以js代码的加密也成了一个研究的课题。 加密方式总结： 破坏代码的可读性 也就是代码混淆，使之不可读，增加破解的成本 加逻辑炸弹 如指定运行的域名，非指定域名的情况下做一些破坏性操作等。 与服务器端强交互 与服务器端频繁交互，或将一些代码放到服务端动态加载。 WebAssembly 这是一个比较新的技术，目前用的很少，不过主流浏览器都有支持。 "},"tools/":{"url":"tools/","title":"Tools","keywords":"","body":" Title Date Modified Category tools 2019-06-11 12:00 2019-06-11 12:00 tools gitbook "},"tools/gitbook.html":{"url":"tools/gitbook.html","title":"gitbook","keywords":"","body":"1. Gitbook Title Date Modified Category gitbook 2019-06-11 12:00 2019-06-11 12:00 tools 1. Gitbook 流程图插件 https://github.com/knsv/mermaid "},"opengl/":{"url":"opengl/","title":"OpenGL","keywords":"","body":""},"cocos/":{"url":"cocos/","title":"Cocos","keywords":"","body":""},"unity/":{"url":"unity/","title":"Unity","keywords":"","body":""}}